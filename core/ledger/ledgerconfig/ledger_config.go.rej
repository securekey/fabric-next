diff a/core/ledger/ledgerconfig/ledger_config.go b/core/ledger/ledgerconfig/ledger_config.go	(rejected hunks)
@@ -36,6 +39,82 @@ const confEnableHistoryDatabase = "ledger.history.enableHistoryDatabase"
 const confMaxBatchSize = "ledger.state.couchDBConfig.maxBatchUpdateSize"
 const confAutoWarmIndexes = "ledger.state.couchDBConfig.autoWarmIndexes"
 const confWarmIndexesAfterNBlocks = "ledger.state.couchDBConfig.warmIndexesAfterNBlocks"
+const confBlockCacheSize = "ledger.blockchain.blockCacheSize"
+const confKVCacheSize = "ledger.blockchain.kvCacheSize"
+const confPvtDataCacheSize = "ledger.blockchain.pvtDataCacheSize"
+const confKVCacheBlocksToLive = "ledger.blockchain.kvCacheBlocksToLive"
+const confKVCacheNonDurableSize = "ledger.blockchain.kvCacheNonDurableSize"
+const confBlockStorage = "ledger.blockchain.blockStorage"
+const confPvtDataStorage = "ledger.blockchain.pvtDataStorage"
+const confHistoryStorage = "ledger.state.historyStorage"
+const confTransientStorage = "ledger.blockchain.transientStorage"
+const confConfigHistoryStorage = "ledger.blockchain.configHistoryStorage"
+const confRoles = "ledger.roles"
+const confValidationMinWaitTime = "ledger.blockchain.validation.minwaittime"
+const confValidationWaitTimePerTx = "ledger.blockchain.validation.waittimepertx"
+
+// TODO: couchDB config should be in a common section rather than being under state.
+const confCouchDBMaxIdleConns = "ledger.state.couchDBConfig.maxIdleConns"
+const confCouchDBMaxIdleConnsPerHost = "ledger.state.couchDBConfig.maxIdleConnsPerHost"
+const confCouchDBIdleConnTimeout = "ledger.state.couchDBConfig.idleConnTimeout"
+const confCouchDBKeepAliveTimeout = "ledger.state.couchDBConfig.keepAliveTimeout"
+
+const confCouchDBHTTPTraceEnabled = "ledger.state.couchDBConfig.httpTraceEnabled"
+
+const defaultValidationMinWaitTime = 50 * time.Millisecond
+const defaultValidationWaitTimePerTx = 5 * time.Millisecond
+
+// BlockStorageProvider holds the configuration names of the available storage providers
+type BlockStorageProvider int
+
+const (
+	// FilesystemLedgerStorage stores blocks in a raw file with a LevelDB index (default)
+	FilesystemLedgerStorage BlockStorageProvider = iota
+	// CouchDBLedgerStorage stores blocks in CouchDB
+	CouchDBLedgerStorage
+)
+
+// PvtDataStorageProvider holds the configuration names of the available storage providers
+type PvtDataStorageProvider int
+
+const (
+	// LevelDBPvtDataStorage stores private data in LevelDB (default)
+	LevelDBPvtDataStorage PvtDataStorageProvider = iota
+	// CouchDBPvtDataStorage stores private data in CouchDB
+	CouchDBPvtDataStorage
+)
+
+// HistoryStorageProvider holds the configuration names of the available history storage providers
+type HistoryStorageProvider int
+
+const (
+	// LevelDBHistoryStorage stores history in LevelDB (default)
+	LevelDBHistoryStorage HistoryStorageProvider = iota
+	// CouchDBHistoryStorage stores history in CouchDB
+	CouchDBHistoryStorage
+)
+
+// TransientStorageProvider holds the configuration names of the available transient storage providers
+type TransientStorageProvider int
+
+const (
+	// LevelDBPvtDataStorage stores transient data in LevelDB (default)
+	LevelDBTransientStorage TransientStorageProvider = iota
+	// CouchDBTransientStorage stores transient data in CouchDB
+	CouchDBTransientStorage
+	// MemoryTransientStorage stores transient data in Memory
+	MemoryTransientStorage
+)
+
+// ConfigHistoryStorageProvider holds the configuration names of the available config history storage providers
+type ConfigHistoryStorageProvider int
+
+const (
+	// LevelDBConfigHistoryStorage stores config history data in LevelDB (default)
+	LevelDBConfigHistoryStorage ConfigHistoryStorageProvider = iota
+	// CouchDBConfigHistoryStorage stores config history data in CouchDB
+	CouchDBConfigHistoryStorage
+)
 
 // GetRootPath returns the filesystem path.
 // All ledger related contents are expected to be stored under this path
@@ -114,6 +193,57 @@ func GetPvtdataStorePurgeInterval() uint64 {
 	return uint64(purgeInterval)
 }
 
+// GetPvtdataSkipPurgeForCollections returns the list of collections that will be expired but not purged
+func GetPvtdataSkipPurgeForCollections() []string {
+	skipPurgeForCollections := viper.GetString("ledger.pvtdataStore.skipPurgeForCollections")
+	return strings.Split(skipPurgeForCollections, ",")
+}
+
+
+// GetCouchDBMaxIdleConns returns the number of idle connections to hold in the connection pool for couchDB.
+func GetCouchDBMaxIdleConns() int {
+	// TODO: this probably be the default golang version (100)
+	const defaultMaxIdleConns = 1000
+	if !viper.IsSet(confCouchDBMaxIdleConns) {
+		return defaultMaxIdleConns
+	}
+
+	return viper.GetInt(confCouchDBMaxIdleConns)
+}
+
+// GetCouchDBMaxIdleConnsPerHost returns the number of idle connections to allow per host in the connection pool for couchDB.
+func GetCouchDBMaxIdleConnsPerHost() int {
+	// TODO: this probably be the default golang version (http.DefaultMaxIdleConnsPerHost)
+	const defaultMaxIdleConnsPerHost = 100
+	if !viper.IsSet(confCouchDBMaxIdleConnsPerHost) {
+		return defaultMaxIdleConnsPerHost
+	}
+
+	return viper.GetInt(confCouchDBMaxIdleConnsPerHost)
+}
+
+// GetCouchDBIdleConnTimeout returns the duration before closing an idle connection.
+func GetCouchDBIdleConnTimeout() time.Duration {
+	const defaultIdleConnTimeout = 90 * time.Second
+
+	if !viper.IsSet(confCouchDBIdleConnTimeout) {
+		return defaultIdleConnTimeout
+	}
+
+	return viper.GetDuration(confCouchDBIdleConnTimeout)
+}
+
+// GetCouchDBKeepAliveTimeout returns the duration for keep alive.
+func GetCouchDBKeepAliveTimeout() time.Duration {
+	const defaultKeepAliveTimeout = 30 * time.Second
+
+	if !viper.IsSet(confCouchDBKeepAliveTimeout) {
+		return defaultKeepAliveTimeout
+	}
+
+	return viper.GetDuration(confCouchDBKeepAliveTimeout)
+}
+
 //IsHistoryDBEnabled exposes the historyDatabase variable
 func IsHistoryDBEnabled() bool {
 	return viper.GetBool(confEnableHistoryDatabase)
@@ -151,3 +281,216 @@ func GetWarmIndexesAfterNBlocks() int {
 	}
 	return warmAfterNBlocks
 }
+
+// GetBlockStoreProvider returns the block storage provider specified in the configuration
+func GetBlockStoreProvider() BlockStorageProvider {
+	blockStorageConfig := viper.GetString(confBlockStorage)
+
+	switch blockStorageConfig {
+	case "CouchDB":
+		return CouchDBLedgerStorage
+	default:
+		fallthrough
+	case "filesystem":
+		return FilesystemLedgerStorage
+	}
+}
+
+// GetBlockCacheSize returns the number of blocks to keep the in the LRU cache
+func GetBlockCacheSize() int {
+	blockCacheSize := viper.GetInt(confBlockCacheSize)
+	if !viper.IsSet(confBlockCacheSize) {
+		blockCacheSize = 300
+	}
+	return blockCacheSize
+}
+
+// GetPvtDataCacheSize returns the number of pvt data per block to keep the in the LRU cache
+func GetPvtDataCacheSize() int {
+	pvtDataCacheSize := viper.GetInt(confPvtDataCacheSize)
+	if !viper.IsSet(confPvtDataCacheSize) {
+		pvtDataCacheSize = 10
+	}
+	return pvtDataCacheSize
+}
+
+func GetKVCacheSize() int {
+	kvCacheSize := viper.GetInt(confKVCacheSize)
+	if !viper.IsSet(confKVCacheSize) {
+		kvCacheSize = 64 * 1024
+	}
+	return kvCacheSize
+}
+
+func GetKVCacheBlocksToLive() uint64 {
+	if !viper.IsSet(confKVCacheBlocksToLive) {
+		return 120
+	}
+	return uint64(viper.GetInt(confKVCacheBlocksToLive))
+}
+
+func GetKVCacheNonDurableSize() int {
+	if !viper.IsSet(confKVCacheNonDurableSize) {
+		return 64 * 1024
+	}
+	return viper.GetInt(confKVCacheNonDurableSize)
+}
+
+// GetTransientStoreProvider returns the transient storage provider specified in the configuration
+func GetTransientStoreProvider() TransientStorageProvider {
+	transientStorageConfig := viper.GetString(confTransientStorage)
+
+	switch transientStorageConfig {
+	case "CouchDB":
+		return CouchDBTransientStorage
+	case "Memory":
+		return MemoryTransientStorage
+	default:
+		fallthrough
+	case "goleveldb":
+		return LevelDBTransientStorage
+	}
+}
+
+// GetConfigHistoryStoreProvider returns the config history storage provider specified in the configuration
+func GetConfigHistoryStoreProvider() ConfigHistoryStorageProvider {
+	configHistoryStorageConfig := viper.GetString(confConfigHistoryStorage)
+
+	switch configHistoryStorageConfig {
+	case "CouchDB":
+		return CouchDBConfigHistoryStorage
+	default:
+		fallthrough
+	case "goleveldb":
+		return LevelDBConfigHistoryStorage
+	}
+}
+
+// GetHistoryStoreProvider returns the history storage provider specified in the configuration
+func GetHistoryStoreProvider() HistoryStorageProvider {
+	historyStorageConfig := viper.GetString(confHistoryStorage)
+
+	switch historyStorageConfig {
+	case "CouchDB":
+		return CouchDBHistoryStorage
+	default:
+		fallthrough
+	case "goleveldb":
+		return LevelDBHistoryStorage
+	}
+}
+
+// GetPvtDataStoreProvider returns the private data storage provider specified in the configuration
+func GetPvtDataStoreProvider() PvtDataStorageProvider {
+	pvtDataStorageConfig := viper.GetString(confPvtDataStorage)
+
+	switch pvtDataStorageConfig {
+	case "CouchDB":
+		return CouchDBPvtDataStorage
+	default:
+		fallthrough
+	case "goleveldb":
+		return LevelDBPvtDataStorage
+	}
+}
+
+// Role is the role of the peer
+type Role string
+
+const (
+	// CommitterRole indicates that the peer commits data to the ledger
+	CommitterRole Role = "committer"
+	// EndorserRole indicates that the peer endorses transaction proposals
+	EndorserRole Role = "endorser"
+	// ValidatorRole indicates that the peer validates the block
+	ValidatorRole Role = "validator"
+)
+
+var initOnce sync.Once
+var roles map[Role]struct{}
+
+// HasRole returns true if the peer has the given role
+func HasRole(role Role) bool {
+	initOnce.Do(func() {
+		roles = getRoles()
+	})
+	_, ok := roles[role]
+	return ok
+}
+
+// IsCommitter returns true if the peer is a committer, otherwise the peer does not commit to the DB
+func IsCommitter() bool {
+	return HasRole(CommitterRole)
+}
+
+// IsEndorser returns true if the peer is an endorser
+func IsEndorser() bool {
+	return HasRole(EndorserRole)
+}
+
+// IsValidator returns true if the peer is a validator
+func IsValidator() bool {
+	return HasRole(ValidatorRole)
+}
+
+// Roles returns the roles for the peer
+func Roles() []Role {
+	var ret []Role
+	for role := range roles {
+		ret = append(ret, role)
+	}
+	return ret
+}
+
+// RolesAsString returns the roles for the peer
+func RolesAsString() []string {
+	var ret []string
+	for role := range roles {
+		ret = append(ret, string(role))
+	}
+	return ret
+}
+
+func getRoles() map[Role]struct{} {
+	exists := struct{}{}
+	strRoles := viper.GetString(confRoles)
+	if strRoles == "" {
+		// The peer has all roles by default
+		return map[Role]struct{}{
+			EndorserRole:  exists,
+			CommitterRole: exists,
+		}
+	}
+
+	roles := make(map[Role]struct{})
+	for _, r := range strings.Split(strRoles, ",") {
+		roles[Role(r)] = exists
+	}
+	return roles
+}
+
+// CouchDBHTTPTraceEnabled returns true if HTTP tracing is enabled for Couch DB
+func CouchDBHTTPTraceEnabled() bool {
+	return viper.GetBool(confCouchDBHTTPTraceEnabled)
+}
+
+// GetValidationWaitTimePerTx is used by the committer in distributed validation and is the time
+// per transaction to wait for validation responses from other validators.
+// For example, if there are 20 transactions to validate and ValidationWaitTimePerTx=100ms
+// then the committer will wait 20*50ms for responses from other validators.
+func GetValidationWaitTimePerTx() time.Duration {
+	if viper.IsSet(confValidationWaitTimePerTx) {
+		return viper.GetDuration(confValidationWaitTimePerTx)
+	}
+	return defaultValidationWaitTimePerTx
+}
+
+// GetValidationMinWaitTime is used by the committer in distributed validation and is the minimum
+// time to wait for Tx validation responses from other validators.
+func GetValidationMinWaitTime() time.Duration {
+	timeout := viper.GetDuration(confValidationMinWaitTime)
+	if timeout == 0 {
+		return defaultValidationMinWaitTime
+	}
+	return timeout
+}
