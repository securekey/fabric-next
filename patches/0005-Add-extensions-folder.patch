From ab9d8ec7c6879619fb446ed5b2f41a163e56c328 Mon Sep 17 00:00:00 2001
From: Firas Qutishat <firas.qutishat@securekey.com>
Date: Fri, 31 May 2019 14:22:37 -0400
Subject: [PATCH] Add extensions folder

Signed-off-by: Firas Qutishat <firas.qutishat@securekey.com>
Change-Id: Iada6fc7d52a307728fcd9c3ef2a24171711f9e56
---
 Gopkg.lock                                    | 103 ++-
 Gopkg.toml                                    |  10 +-
 extensions/blkstorage/store.go                |  27 +
 extensions/blkstorage/store_test.go           |  22 +
 .../api/dissemination/dissemination.go        |  18 +
 extensions/collections/api/store/key.go       |  57 ++
 extensions/collections/api/store/provider.go  |  78 ++
 extensions/collections/api/support/support.go |  23 +
 .../dissemination/disseminationplan.go        |  72 ++
 .../dissemination/disseminationplan_test.go   | 101 +++
 extensions/collections/policy/validator.go    |  89 ++
 .../collections/policy/validator_test.go      | 271 ++++++
 .../pvtdatahandler/pvtdatahandler.go          |  17 +
 .../pvtdatahandler/pvtdatahandler_test.go     |  40 +
 extensions/collections/retriever/retriever.go |  25 +
 .../collections/retriever/retriever_test.go   |  33 +
 .../storeprovider/mocks/mocktdstore.go        | 119 +++
 .../storeprovider/storeprovider.go            |  16 +
 .../storeprovider/storeprovider_test.go       | 104 +++
 extensions/endorser/endorser.go               |  18 +
 extensions/endorser/endorser_test.go          |  22 +
 extensions/gossip/api/gossipapi.go            |  44 +
 .../gossip/blockpublisher/blockpublisher.go   |  16 +
 .../blockpublisher/blockpublisher_test.go     |  67 ++
 extensions/gossip/coordinator/coordinator.go  |  24 +
 .../gossip/coordinator/coordinator_test.go    |  50 ++
 extensions/gossip/dispatcher/dispatcher.go    |  37 +
 .../gossip/dispatcher/dispatcher_test.go      |  38 +
 extensions/gossip/mocks/blockpublisher.go     |  51 ++
 extensions/idstore/store.go                   |  17 +
 extensions/idstore/store_test.go              |  20 +
 extensions/mocks/mockdatastore.go             | 101 +++
 extensions/mocks/mockprovider.go              |  53 ++
 extensions/pvtdatastorage/store.go            |  17 +
 extensions/pvtdatastorage/store_test.go       |  33 +
 extensions/roles/ledger_roles_config.go       |  30 +
 extensions/roles/ledger_roles_config_test.go  |  29 +
 extensions/statedb/store.go                   |  16 +
 extensions/statedb/store_test.go              |  34 +
 extensions/testutil/ext_test_env.go           |  25 +
 extensions/transientstore/store.go            |  17 +
 extensions/transientstore/store_test.go       |  17 +
 vendor/github.com/bluele/gcache/LICENSE       |  21 +
 vendor/github.com/bluele/gcache/arc.go        | 452 ++++++++++
 vendor/github.com/bluele/gcache/cache.go      | 205 +++++
 vendor/github.com/bluele/gcache/clock.go      |  53 ++
 vendor/github.com/bluele/gcache/lfu.go        | 335 +++++++
 vendor/github.com/bluele/gcache/lru.go        | 301 +++++++
 vendor/github.com/bluele/gcache/simple.go     | 289 ++++++
 .../github.com/bluele/gcache/singleflight.go  |  82 ++
 vendor/github.com/bluele/gcache/stats.go      |  53 ++
 vendor/github.com/bluele/gcache/utils.go      |  15 +
 vendor/github.com/btcsuite/btcutil/LICENSE    |  16 +
 .../btcsuite/btcutil/base58/alphabet.go       |  49 +
 .../btcsuite/btcutil/base58/base58.go         |  75 ++
 .../btcsuite/btcutil/base58/base58check.go    |  52 ++
 .../github.com/btcsuite/btcutil/base58/doc.go |  29 +
 .../btcsuite/btcutil/base58/genalphabet.go    |  79 ++
 .../magiconair/properties/assert/assert.go    |  90 ++
 vendor/github.com/pkg/errors/errors.go        |  43 +-
 vendor/github.com/pkg/errors/stack.go         |  51 +-
 .../trustbloc/fabric-peer-ext/LICENSE         | 201 +++++
 .../cdbblkstorage/block_serialization.go      |  67 ++
 .../blkstorage/cdbblkstorage/blocks_itr.go    |  73 ++
 .../cdbblkstorage/cdb_blkstorage.go           | 368 ++++++++
 .../cdbblkstorage/cdb_blkstorage_provider.go  | 159 ++++
 .../cdbblkstorage/cdb_checkpoint.go           | 121 +++
 .../blkstorage/cdbblkstorage/couchdoc_conv.go | 377 ++++++++
 .../collections/offledger/api/offledger.go    |  56 ++
 .../pkg/collections/offledger/dcas/cas.go     |  41 +
 .../pkg/collections/offledger/dcas/dcas.go    |  53 ++
 .../dissemination/disseminationplan.go        |  99 ++
 .../offledger/dissemination/disseminator.go   | 126 +++
 .../offledger/mocks/mockprovider.go           |  40 +
 .../collections/offledger/policy/validator.go |  42 +
 .../offledger/retriever/olretriever.go        | 431 +++++++++
 .../offledger/storeprovider/olstore.go        | 316 +++++++
 .../storeprovider/olstoreprovider.go          | 108 +++
 .../offledger/storeprovider/store/api/api.go  |  61 ++
 .../storeprovider/store/cache/cache.go        | 159 ++++
 .../store/couchdbstore/dbstore.go             | 212 +++++
 .../store/couchdbstore/dbstore_provider.go    | 145 +++
 .../pvtdatahandler/pvtdatahandler.go          | 156 ++++
 .../collections/pvtdatastore/pvtdatastore.go  | 190 ++++
 .../pkg/collections/retriever/retriever.go    | 123 +++
 .../pkg/collections/retriever/test_exports.go |  25 +
 .../pkg/collections/storeprovider/store.go    |  86 ++
 .../storeprovider/storeprovider.go            |  92 ++
 .../collections/storeprovider/test_exports.go |  18 +
 .../transientdata/api/transientdata.go        |  52 ++
 .../dissemination/disseminationplan.go        |  92 ++
 .../dissemination/disseminator.go             | 135 +++
 .../transientdata/mocks/mockprovider.go       |  40 +
 .../transientdata/policy/validator.go         |  39 +
 .../retriever/transientdataretriever.go       | 384 ++++++++
 .../storeprovider/store/api/api.go            |  30 +
 .../storeprovider/store/cache/cache.go        | 150 ++++
 .../storeprovider/store/dbstore/dbstore.go    | 130 +++
 .../store/dbstore/dbstore_provider.go         |  41 +
 .../transientdata/storeprovider/tdstore.go    | 166 ++++
 .../storeprovider/tdstoreprovider.go          |  67 ++
 .../fabric-peer-ext/pkg/common/common.go      |  88 ++
 .../pkg/common/discovery/discovery.go         | 123 +++
 .../pkg/common/discovery/member.go            |  38 +
 .../pkg/common/discovery/peergroup.go         | 136 +++
 .../pkg/common/multirequest/multirequest.go   | 105 +++
 .../pkg/common/requestmgr/requestmgr.go       | 207 +++++
 .../pkg/common/support/collconfigretriever.go | 206 +++++
 .../pkg/common/support/support.go             |  66 ++
 .../fabric-peer-ext/pkg/config/config.go      | 141 +++
 .../fabric-peer-ext/pkg/endorser/endorser.go  | 112 +++
 .../gossip/blockpublisher/blockpublisher.go   | 514 +++++++++++
 .../pkg/gossip/dispatcher/dispatcher.go       | 268 ++++++
 .../pkg/idstore/couchdoc_conv.go              | 142 +++
 .../fabric-peer-ext/pkg/idstore/store_impl.go | 268 ++++++
 .../pkg/idstore/test_exports.go               |  59 ++
 .../pkg/mocks/mockaccesspolicy.go             |  61 ++
 .../pkg/mocks/mockblockbuilder.go             | 367 ++++++++
 .../pkg/mocks/mockblockhandler.go             |  91 ++
 .../pkg/mocks/mockblockpublisher.go           |  56 ++
 .../pkg/mocks/mockdataprovider.go             |  91 ++
 .../pkg/mocks/mockdatastore.go                | 101 +++
 .../pkg/mocks/mockgossipadapter.go            |  96 ++
 .../pkg/mocks/mockgossipmsg.go                | 130 +++
 .../fabric-peer-ext/pkg/mocks/mockledger.go   | 107 +++
 .../pkg/mocks/mockqueryexecutor.go            | 124 +++
 .../pkg/mocks/mockrwsetbuilder.go             | 345 +++++++
 .../fabric-peer-ext/pkg/mocks/mocksupport.go  |  61 ++
 .../fabric-peer-ext/pkg/mocks/mocktxsim.go    |  80 ++
 .../cachedpvtdatastore/store_impl.go          | 285 ++++++
 .../cachedpvtdatastore/test_exports.go        |  46 +
 .../cdbpvtdatastore/couchdb_conv.go           | 277 ++++++
 .../cdbpvtdatastore/store_impl.go             | 850 ++++++++++++++++++
 .../cdbpvtdatastore/test_exports.go           |  77 ++
 .../pkg/pvtdatastorage/common/collelgproc.go  | 139 +++
 .../pkg/pvtdatastorage/common/helper.go       | 235 +++++
 .../pkg/pvtdatastorage/common/kv_encoding.go  | 192 ++++
 .../pkg/pvtdatastorage/common/store.go        | 404 +++++++++
 .../pkg/pvtdatastorage/common/v11.go          |  78 ++
 .../pkg/pvtdatastorage/store_impl.go          | 206 +++++
 .../pkg/pvtdatastorage/test_exports.go        |  77 ++
 .../fabric-peer-ext/pkg/roles/roles.go        | 123 +++
 .../fabric-peer-ext/pkg/roles/test_exports.go |  14 +
 .../pkg/testutil/ext_test_env.go              |  91 ++
 .../common/common_store_helper.go             | 159 ++++
 .../pkg/transientstore/store.go               | 471 ++++++++++
 .../pkg/transientstore/store_helper.go        | 190 ++++
 .../pkg/transientstore/storeprovider.go       |  33 +
 148 files changed, 17630 insertions(+), 62 deletions(-)
 create mode 100644 extensions/blkstorage/store.go
 create mode 100644 extensions/blkstorage/store_test.go
 create mode 100644 extensions/collections/api/dissemination/dissemination.go
 create mode 100644 extensions/collections/api/store/key.go
 create mode 100644 extensions/collections/api/store/provider.go
 create mode 100644 extensions/collections/api/support/support.go
 create mode 100644 extensions/collections/dissemination/disseminationplan.go
 create mode 100644 extensions/collections/dissemination/disseminationplan_test.go
 create mode 100644 extensions/collections/policy/validator.go
 create mode 100644 extensions/collections/policy/validator_test.go
 create mode 100644 extensions/collections/pvtdatahandler/pvtdatahandler.go
 create mode 100644 extensions/collections/pvtdatahandler/pvtdatahandler_test.go
 create mode 100644 extensions/collections/retriever/retriever.go
 create mode 100644 extensions/collections/retriever/retriever_test.go
 create mode 100644 extensions/collections/storeprovider/mocks/mocktdstore.go
 create mode 100644 extensions/collections/storeprovider/storeprovider.go
 create mode 100644 extensions/collections/storeprovider/storeprovider_test.go
 create mode 100644 extensions/endorser/endorser.go
 create mode 100644 extensions/endorser/endorser_test.go
 create mode 100644 extensions/gossip/api/gossipapi.go
 create mode 100644 extensions/gossip/blockpublisher/blockpublisher.go
 create mode 100644 extensions/gossip/blockpublisher/blockpublisher_test.go
 create mode 100644 extensions/gossip/coordinator/coordinator.go
 create mode 100644 extensions/gossip/coordinator/coordinator_test.go
 create mode 100644 extensions/gossip/dispatcher/dispatcher.go
 create mode 100644 extensions/gossip/dispatcher/dispatcher_test.go
 create mode 100644 extensions/gossip/mocks/blockpublisher.go
 create mode 100644 extensions/idstore/store.go
 create mode 100644 extensions/idstore/store_test.go
 create mode 100644 extensions/mocks/mockdatastore.go
 create mode 100644 extensions/mocks/mockprovider.go
 create mode 100644 extensions/pvtdatastorage/store.go
 create mode 100644 extensions/pvtdatastorage/store_test.go
 create mode 100644 extensions/roles/ledger_roles_config.go
 create mode 100644 extensions/roles/ledger_roles_config_test.go
 create mode 100644 extensions/statedb/store.go
 create mode 100644 extensions/statedb/store_test.go
 create mode 100644 extensions/testutil/ext_test_env.go
 create mode 100644 extensions/transientstore/store.go
 create mode 100644 extensions/transientstore/store_test.go
 create mode 100644 vendor/github.com/bluele/gcache/LICENSE
 create mode 100644 vendor/github.com/bluele/gcache/arc.go
 create mode 100644 vendor/github.com/bluele/gcache/cache.go
 create mode 100644 vendor/github.com/bluele/gcache/clock.go
 create mode 100644 vendor/github.com/bluele/gcache/lfu.go
 create mode 100644 vendor/github.com/bluele/gcache/lru.go
 create mode 100644 vendor/github.com/bluele/gcache/simple.go
 create mode 100644 vendor/github.com/bluele/gcache/singleflight.go
 create mode 100644 vendor/github.com/bluele/gcache/stats.go
 create mode 100644 vendor/github.com/bluele/gcache/utils.go
 create mode 100644 vendor/github.com/btcsuite/btcutil/LICENSE
 create mode 100644 vendor/github.com/btcsuite/btcutil/base58/alphabet.go
 create mode 100644 vendor/github.com/btcsuite/btcutil/base58/base58.go
 create mode 100644 vendor/github.com/btcsuite/btcutil/base58/base58check.go
 create mode 100644 vendor/github.com/btcsuite/btcutil/base58/doc.go
 create mode 100644 vendor/github.com/btcsuite/btcutil/base58/genalphabet.go
 create mode 100644 vendor/github.com/magiconair/properties/assert/assert.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/LICENSE
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/block_serialization.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/blocks_itr.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage_provider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_checkpoint.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/couchdoc_conv.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api/offledger.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/cas.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/dcas.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminationplan.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminator.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/mocks/mockprovider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/policy/validator.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever/olretriever.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstore.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstoreprovider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api/api.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache/cache.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore_provider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatahandler/pvtdatahandler.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatastore/pvtdatastore.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/retriever.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/test_exports.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/store.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/storeprovider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/test_exports.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api/transientdata.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination/disseminationplan.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination/disseminator.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/mocks/mockprovider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/policy/validator.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/retriever/transientdataretriever.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/api/api.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/cache/cache.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore/dbstore.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore/dbstore_provider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/tdstore.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/tdstoreprovider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/common.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/discovery.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/member.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/peergroup.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/multirequest/multirequest.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/requestmgr/requestmgr.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/support/collconfigretriever.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/support/support.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/config/config.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/endorser/endorser.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher/blockpublisher.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/dispatcher/dispatcher.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/couchdoc_conv.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/store_impl.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/test_exports.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockaccesspolicy.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockbuilder.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockhandler.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockpublisher.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockdataprovider.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockdatastore.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockgossipadapter.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockgossipmsg.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockledger.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockqueryexecutor.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockrwsetbuilder.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mocksupport.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mocktxsim.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore/store_impl.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore/test_exports.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/couchdb_conv.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/store_impl.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/test_exports.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/collelgproc.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/helper.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/kv_encoding.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/store.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/v11.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/store_impl.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/test_exports.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/roles.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/test_exports.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/testutil/ext_test_env.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/common/common_store_helper.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/store.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/store_helper.go
 create mode 100644 vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/storeprovider.go

diff --git a/Gopkg.lock b/Gopkg.lock
index b10513ea..00ff4999 100644
--- a/Gopkg.lock
+++ b/Gopkg.lock
@@ -93,6 +93,21 @@
   pruneopts = "NUT"
   revision = "3a771d992973f24aa725d07868b467d1ddfceafb"
 
+[[projects]]
+  digest = "1:b870f4fc8ac5a04b3dbb6540e81a4c16da874e9f922dbe8762a90d9bcc294910"
+  name = "github.com/bluele/gcache"
+  packages = ["."]
+  pruneopts = "NUT"
+  revision = "79ae3b2d8680cbc7ad3dba9db66b8a648575221c"
+
+[[projects]]
+  branch = "master"
+  digest = "1:9af5b27cadd7fefde7d20dfc72470d39679337e972460a251c129062a70f8518"
+  name = "github.com/btcsuite/btcutil"
+  packages = ["base58"]
+  pruneopts = "NUT"
+  revision = "9e5f4b9a998d263e3ce9c56664a7816001ac8000"
+
 [[projects]]
   branch = "master"
   digest = "1:4a029051269e04c040c092eb4ddd92732f8f3a3921a8b43b82b30804e00f3357"
@@ -398,9 +413,12 @@
   version = "v0.1.0"
 
 [[projects]]
-  digest = "1:d244f8666a838fe6ad70ec8fe77f50ebc29fdc3331a2729ba5886bef8435d10d"
+  digest = "1:4244266b65ea535b8ebd109a327720821707b59f9a37bda738946d52ec69442d"
   name = "github.com/magiconair/properties"
-  packages = ["."]
+  packages = [
+    ".",
+    "assert",
+  ]
   pruneopts = "NUT"
   revision = "c2353362d570a7bfa228149c62842019201cfb71"
   version = "v1.8.0"
@@ -534,12 +552,12 @@
   version = "v2.0.6"
 
 [[projects]]
-  digest = "1:5cf3f025cbee5951a4ee961de067c8a89fc95a5adabead774f82822efabab121"
+  digest = "1:14715f705ff5dfe0ffd6571d7d201dd8e921030f8070321a79380d8ca4ec1a24"
   name = "github.com/pkg/errors"
   packages = ["."]
   pruneopts = "NUT"
-  revision = "645ef00459ed84a119197bfb8d8205042c6df63d"
-  version = "v0.8.0"
+  revision = "ba968bfe8b2f7e042a574c888954fccecfa385b4"
+  version = "v0.8.1"
 
 [[projects]]
   digest = "1:0028cb19b2e4c3112225cd871870f2d9cf49b9b4276531f03438a88e94be86fe"
@@ -710,6 +728,57 @@
   pruneopts = "NUT"
   revision = "bea94bb476ccecfbd31b12ed493a971bdb8c904b"
 
+[[projects]]
+  digest = "1:b2a59318676b45d2b2a461e290d1edde9dd878b247c2e2a1b1d8e322945e019f"
+  name = "github.com/trustbloc/fabric-peer-ext"
+  packages = [
+    "pkg/blkstorage/cdbblkstorage",
+    "pkg/collections/offledger/api",
+    "pkg/collections/offledger/dcas",
+    "pkg/collections/offledger/dissemination",
+    "pkg/collections/offledger/mocks",
+    "pkg/collections/offledger/policy",
+    "pkg/collections/offledger/retriever",
+    "pkg/collections/offledger/storeprovider",
+    "pkg/collections/offledger/storeprovider/store/api",
+    "pkg/collections/offledger/storeprovider/store/cache",
+    "pkg/collections/offledger/storeprovider/store/couchdbstore",
+    "pkg/collections/pvtdatahandler",
+    "pkg/collections/pvtdatastore",
+    "pkg/collections/retriever",
+    "pkg/collections/storeprovider",
+    "pkg/collections/transientdata/api",
+    "pkg/collections/transientdata/dissemination",
+    "pkg/collections/transientdata/mocks",
+    "pkg/collections/transientdata/policy",
+    "pkg/collections/transientdata/retriever",
+    "pkg/collections/transientdata/storeprovider",
+    "pkg/collections/transientdata/storeprovider/store/api",
+    "pkg/collections/transientdata/storeprovider/store/cache",
+    "pkg/collections/transientdata/storeprovider/store/dbstore",
+    "pkg/common",
+    "pkg/common/discovery",
+    "pkg/common/multirequest",
+    "pkg/common/requestmgr",
+    "pkg/common/support",
+    "pkg/config",
+    "pkg/endorser",
+    "pkg/gossip/blockpublisher",
+    "pkg/gossip/dispatcher",
+    "pkg/idstore",
+    "pkg/mocks",
+    "pkg/pvtdatastorage",
+    "pkg/pvtdatastorage/cachedpvtdatastore",
+    "pkg/pvtdatastorage/cdbpvtdatastore",
+    "pkg/pvtdatastorage/common",
+    "pkg/roles",
+    "pkg/testutil",
+    "pkg/transientstore",
+    "pkg/transientstore/common",
+  ]
+  pruneopts = "NUT"
+  revision = "9b2d0053a5e40e93141576b7210ef021fe881852"
+
 [[projects]]
   digest = "1:3f3f2b36f76d1187ccf6640dd5bdbce43fd3c1a2cc0d747abc1e0de374d13e63"
   name = "github.com/willf/bitset"
@@ -978,6 +1047,7 @@
     "github.com/hyperledger/fabric-amcl/amcl/FP256BN",
     "github.com/hyperledger/fabric-lib-go/healthz",
     "github.com/kr/pretty",
+    "github.com/magiconair/properties/assert",
     "github.com/miekg/pkcs11",
     "github.com/mitchellh/mapstructure",
     "github.com/onsi/ginkgo",
@@ -1007,6 +1077,29 @@
     "github.com/tedsuo/ifrit",
     "github.com/tedsuo/ifrit/ginkgomon",
     "github.com/tedsuo/ifrit/grouper",
+    "github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/mocks",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/policy",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatahandler",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatastore",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/mocks",
+    "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/policy",
+    "github.com/trustbloc/fabric-peer-ext/pkg/common",
+    "github.com/trustbloc/fabric-peer-ext/pkg/endorser",
+    "github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher",
+    "github.com/trustbloc/fabric-peer-ext/pkg/gossip/dispatcher",
+    "github.com/trustbloc/fabric-peer-ext/pkg/idstore",
+    "github.com/trustbloc/fabric-peer-ext/pkg/mocks",
+    "github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage",
+    "github.com/trustbloc/fabric-peer-ext/pkg/roles",
+    "github.com/trustbloc/fabric-peer-ext/pkg/testutil",
+    "github.com/trustbloc/fabric-peer-ext/pkg/transientstore",
     "github.com/willf/bitset",
     "go.etcd.io/etcd/etcdserver/api/snap",
     "go.etcd.io/etcd/pkg/fileutil",
diff --git a/Gopkg.toml b/Gopkg.toml
index 8ee86e9c..51da99d0 100644
--- a/Gopkg.toml
+++ b/Gopkg.toml
@@ -15,6 +15,14 @@ noverify = [
     "github.com/grpc-ecosystem/go-grpc-middleware"
 ]
 
+[[constraint]]
+  name = "github.com/trustbloc/fabric-peer-ext"
+  revision = "9b2d0053a5e40e93141576b7210ef021fe881852"
+
+[[override]]
+  name = "github.com/bluele/gcache"
+  revision = "79ae3b2d8680cbc7ad3dba9db66b8a648575221c"
+
 [[constraint]]
   name = "github.com/Knetic/govaluate"
   version = "3.0.0"
@@ -79,7 +87,7 @@ noverify = [
 
 [[constraint]]
   name = "github.com/pkg/errors"
-  version = "0.8.0"
+  version = "0.8.1"
 
 [[constraint]]
   name = "github.com/spf13/cobra"
diff --git a/extensions/blkstorage/store.go b/extensions/blkstorage/store.go
new file mode 100644
index 00000000..e0b602ac
--- /dev/null
+++ b/extensions/blkstorage/store.go
@@ -0,0 +1,27 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package blkstorage
+
+import (
+	"github.com/hyperledger/fabric/common/ledger/blkstorage"
+	"github.com/hyperledger/fabric/common/ledger/blkstorage/fsblkstorage"
+	"github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage"
+)
+
+//NewProvider returns couchdb blockstorage provider
+func NewProvider(conf *fsblkstorage.Conf, indexConfig *blkstorage.IndexConfig) blkstorage.BlockStoreProvider {
+	pvdr, err := cdbblkstorage.NewProvider(indexConfig)
+	if err != nil {
+		panic(err)
+	}
+	return pvdr
+}
+
+//NewConf is returns file system based blockstorage conf
+func NewConf(blockStorageDir string, maxBlockfileSize int) *fsblkstorage.Conf {
+	return fsblkstorage.NewConf(blockStorageDir, maxBlockfileSize)
+}
diff --git a/extensions/blkstorage/store_test.go b/extensions/blkstorage/store_test.go
new file mode 100644
index 00000000..eb29b217
--- /dev/null
+++ b/extensions/blkstorage/store_test.go
@@ -0,0 +1,22 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package blkstorage
+
+import (
+	"testing"
+
+	"github.com/hyperledger/fabric/common/ledger/blkstorage"
+	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
+	"github.com/hyperledger/fabric/extensions/testutil"
+	"github.com/stretchr/testify/require"
+)
+
+func TestNewProvider(t *testing.T) {
+	_, _, destroy := testutil.SetupExtTestEnv()
+	defer destroy()
+	require.NotEmpty(t, NewProvider(NewConf(ledgerconfig.GetBlockStorePath(), ledgerconfig.GetMaxBlockfileSize()), &blkstorage.IndexConfig{}))
+}
diff --git a/extensions/collections/api/dissemination/dissemination.go b/extensions/collections/api/dissemination/dissemination.go
new file mode 100644
index 00000000..6fe5b4c7
--- /dev/null
+++ b/extensions/collections/api/dissemination/dissemination.go
@@ -0,0 +1,18 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dissemination
+
+import (
+	"github.com/hyperledger/fabric/gossip/gossip"
+	"github.com/hyperledger/fabric/gossip/protoext"
+)
+
+// Plan contains the dissemination plan for extensions private data types
+type Plan struct {
+	Msg      *protoext.SignedGossipMessage
+	Criteria gossip.SendCriteria
+}
diff --git a/extensions/collections/api/store/key.go b/extensions/collections/api/store/key.go
new file mode 100644
index 00000000..68b4b17f
--- /dev/null
+++ b/extensions/collections/api/store/key.go
@@ -0,0 +1,57 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package store
+
+import (
+	"fmt"
+)
+
+// Key is a key for retrieving collection data
+type Key struct {
+	EndorsedAtTxID string
+	Namespace      string
+	Collection     string
+	Key            string
+}
+
+// NewKey returns a new collection key
+func NewKey(endorsedAtTxID string, ns string, coll string, key string) *Key {
+	return &Key{
+		EndorsedAtTxID: endorsedAtTxID,
+		Namespace:      ns,
+		Collection:     coll,
+		Key:            key,
+	}
+}
+
+// String returns the string representation of the key
+func (k *Key) String() string {
+	return fmt.Sprintf("%s:%s:%s-%s", k.Namespace, k.Collection, k.Key, k.EndorsedAtTxID)
+}
+
+// MultiKey is a key for retrieving collection data for multiple keys
+type MultiKey struct {
+	EndorsedAtTxID string
+	Namespace      string
+	Collection     string
+	Keys           []string
+}
+
+// NewMultiKey returns a new collection data multi-key
+func NewMultiKey(endorsedAtTxID string, ns string, coll string, keys ...string) *MultiKey {
+	return &MultiKey{
+		EndorsedAtTxID: endorsedAtTxID,
+		Namespace:      ns,
+		Collection:     coll,
+		Keys:           keys,
+	}
+}
+
+// String returns the string representation of the key
+func (k *MultiKey) String() string {
+	return fmt.Sprintf("%s:%s:%s-%s", k.Namespace, k.Collection, k.Keys, k.EndorsedAtTxID)
+}
diff --git a/extensions/collections/api/store/provider.go b/extensions/collections/api/store/provider.go
new file mode 100644
index 00000000..37635648
--- /dev/null
+++ b/extensions/collections/api/store/provider.go
@@ -0,0 +1,78 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package store
+
+import (
+	"context"
+	"time"
+
+	cb "github.com/hyperledger/fabric/protos/common"
+	proto "github.com/hyperledger/fabric/protos/transientstore"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common"
+)
+
+// ExpiringValue is holds the value and expiration time.
+type ExpiringValue struct {
+	Value  []byte
+	Expiry time.Time
+}
+
+// ExpiringValues expiring values
+type ExpiringValues []*ExpiringValue
+
+// Store manages the storage of private data collections.
+type Store interface {
+	// Persist stores the private write set of a transaction.
+	Persist(txid string, privateSimulationResultsWithConfig *proto.TxPvtReadWriteSetWithConfigInfo) error
+
+	// GetTransientData gets the value for the given transient data item
+	GetTransientData(key *Key) (*ExpiringValue, error)
+
+	// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+	GetTransientDataMultipleKeys(key *MultiKey) (ExpiringValues, error)
+
+	// GetData gets the value for the given item
+	GetData(key *Key) (*ExpiringValue, error)
+
+	// GetDataMultipleKeys gets the values for the multiple items in a single call
+	GetDataMultipleKeys(key *MultiKey) (ExpiringValues, error)
+
+	// PutData stores the key/value.
+	PutData(config *cb.StaticCollectionConfig, key *Key, value *ExpiringValue) error
+
+	// Close closes the store
+	Close()
+}
+
+// Retriever retrieves private data
+type Retriever interface {
+	// GetTransientData gets the value for the given transient data item
+	GetTransientData(ctxt context.Context, key *Key) (*ExpiringValue, error)
+
+	// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+	GetTransientDataMultipleKeys(ctxt context.Context, key *MultiKey) (ExpiringValues, error)
+
+	// GetData gets the value for the given data item
+	GetData(ctxt context.Context, key *Key) (*ExpiringValue, error)
+
+	// GetDataMultipleKeys gets the values for the multiple data items in a single call
+	GetDataMultipleKeys(ctxt context.Context, key *MultiKey) (ExpiringValues, error)
+}
+
+// Provider provides private data retrievers
+type Provider interface {
+	RetrieverForChannel(channel string) Retriever
+}
+
+// Values returns the ExpiringValues as Values
+func (ev ExpiringValues) Values() common.Values {
+	vals := make(common.Values, len(ev))
+	for i, v := range ev {
+		vals[i] = v
+	}
+	return vals
+}
diff --git a/extensions/collections/api/support/support.go b/extensions/collections/api/support/support.go
new file mode 100644
index 00000000..267ecf5c
--- /dev/null
+++ b/extensions/collections/api/support/support.go
@@ -0,0 +1,23 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package support
+
+import (
+	gossipapi "github.com/hyperledger/fabric/gossip/api"
+	"github.com/hyperledger/fabric/gossip/comm"
+	gcommon "github.com/hyperledger/fabric/gossip/common"
+	"github.com/hyperledger/fabric/gossip/discovery"
+	gproto "github.com/hyperledger/fabric/protos/gossip"
+)
+
+// GossipAdapter defines the Gossip functions that are required for collection data processing
+type GossipAdapter interface {
+	PeersOfChannel(gcommon.ChainID) []discovery.NetworkMember
+	SelfMembershipInfo() discovery.NetworkMember
+	IdentityInfo() gossipapi.PeerIdentitySet
+	Send(msg *gproto.GossipMessage, peers ...*comm.RemotePeer)
+}
diff --git a/extensions/collections/dissemination/disseminationplan.go b/extensions/collections/dissemination/disseminationplan.go
new file mode 100644
index 00000000..bcfc1e41
--- /dev/null
+++ b/extensions/collections/dissemination/disseminationplan.go
@@ -0,0 +1,72 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dissemination
+
+import (
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/extensions/collections/api/dissemination"
+	gossipapi "github.com/hyperledger/fabric/gossip/api"
+	"github.com/hyperledger/fabric/gossip/common"
+	"github.com/hyperledger/fabric/gossip/discovery"
+	"github.com/hyperledger/fabric/gossip/protoext"
+	cb "github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/pkg/errors"
+	oldissemination "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination"
+	tdissemination "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination"
+)
+
+type gossipAdapter interface {
+	PeersOfChannel(common.ChainID) []discovery.NetworkMember
+	SelfMembershipInfo() discovery.NetworkMember
+	IdentityInfo() gossipapi.PeerIdentitySet
+}
+
+var computeTransientDataDisseminationPlan = func(
+	channelID, ns string,
+	rwSet *rwset.CollectionPvtReadWriteSet,
+	colAP privdata.CollectionAccessPolicy,
+	pvtDataMsg *protoext.SignedGossipMessage,
+	gossipAdapter gossipAdapter) ([]*dissemination.Plan, bool, error) {
+	return tdissemination.ComputeDisseminationPlan(channelID, ns, rwSet, colAP, pvtDataMsg, gossipAdapter)
+}
+
+var computeOffLedgerDisseminationPlan = func(
+	channelID, ns string,
+	rwSet *rwset.CollectionPvtReadWriteSet,
+	collConfig *cb.StaticCollectionConfig,
+	colAP privdata.CollectionAccessPolicy,
+	pvtDataMsg *protoext.SignedGossipMessage,
+	gossipAdapter gossipAdapter) ([]*dissemination.Plan, bool, error) {
+	return oldissemination.ComputeDisseminationPlan(channelID, ns, rwSet, collConfig, colAP, pvtDataMsg, gossipAdapter)
+}
+
+// ComputeDisseminationPlan returns the dissemination plan for various collection types
+func ComputeDisseminationPlan(
+	channelID, ns string,
+	rwSet *rwset.CollectionPvtReadWriteSet,
+	colCP *cb.CollectionConfig,
+	colAP privdata.CollectionAccessPolicy,
+	pvtDataMsg *protoext.SignedGossipMessage,
+	gossipAdapter gossipAdapter) ([]*dissemination.Plan, bool, error) {
+
+	collConfig := colCP.GetStaticCollectionConfig()
+	if collConfig == nil {
+		return nil, false, errors.New("static collection config not defined")
+	}
+
+	switch collConfig.Type {
+	case cb.CollectionType_COL_TRANSIENT:
+		return computeTransientDataDisseminationPlan(channelID, ns, rwSet, colAP, pvtDataMsg, gossipAdapter)
+	case cb.CollectionType_COL_DCAS:
+		fallthrough
+	case cb.CollectionType_COL_OFFLEDGER:
+		return computeOffLedgerDisseminationPlan(channelID, ns, rwSet, collConfig, colAP, pvtDataMsg, gossipAdapter)
+	default:
+		return nil, false, errors.Errorf("unsupported collection type: [%s]", collConfig.Type)
+	}
+}
diff --git a/extensions/collections/dissemination/disseminationplan_test.go b/extensions/collections/dissemination/disseminationplan_test.go
new file mode 100644
index 00000000..fecdf757
--- /dev/null
+++ b/extensions/collections/dissemination/disseminationplan_test.go
@@ -0,0 +1,101 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dissemination
+
+import (
+	"testing"
+
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/extensions/collections/api/dissemination"
+	"github.com/hyperledger/fabric/gossip/protoext"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/stretchr/testify/assert"
+)
+
+func TestDisseminationPlan(t *testing.T) {
+	const (
+		channelID = "testchannel"
+		ns        = "ns1"
+	)
+
+	computeTransientDataDisseminationPlan = func(
+		channelID, ns string,
+		rwSet *rwset.CollectionPvtReadWriteSet,
+		colAP privdata.CollectionAccessPolicy,
+		pvtDataMsg *protoext.SignedGossipMessage,
+		gossipAdapter gossipAdapter) ([]*dissemination.Plan, bool, error) {
+		return nil, false, nil
+	}
+
+	computeOffLedgerDisseminationPlan = func(
+		channelID, ns string,
+		rwSet *rwset.CollectionPvtReadWriteSet,
+		colCP *common.StaticCollectionConfig,
+		colAP privdata.CollectionAccessPolicy,
+		pvtDataMsg *protoext.SignedGossipMessage,
+		gossipAdapter gossipAdapter) ([]*dissemination.Plan, bool, error) {
+		return nil, false, nil
+	}
+
+	t.Run("Empty config", func(t *testing.T) {
+		colConfig1 := &common.CollectionConfig{}
+		_, _, err := ComputeDisseminationPlan(
+			channelID, ns, nil, colConfig1, nil, nil, nil)
+		assert.EqualError(t, err, "static collection config not defined")
+	})
+
+	t.Run("Unknown config", func(t *testing.T) {
+		colConfig2 := &common.CollectionConfig{
+			Payload: &common.CollectionConfig_StaticCollectionConfig{
+				StaticCollectionConfig: &common.StaticCollectionConfig{},
+			},
+		}
+		_, _, err := ComputeDisseminationPlan(
+			channelID, ns, nil, colConfig2, nil, nil, nil)
+		assert.EqualError(t, err, "unsupported collection type: [COL_UNKNOWN]")
+	})
+
+	t.Run("Transient Data config", func(t *testing.T) {
+		transientConfig := &common.CollectionConfig{
+			Payload: &common.CollectionConfig_StaticCollectionConfig{
+				StaticCollectionConfig: &common.StaticCollectionConfig{
+					Type: common.CollectionType_COL_TRANSIENT,
+				},
+			},
+		}
+		_, _, err := ComputeDisseminationPlan(
+			channelID, ns, nil, transientConfig, nil, nil, nil)
+		assert.NoError(t, err)
+	})
+
+	t.Run("Off-Ledger config", func(t *testing.T) {
+		olConfig := &common.CollectionConfig{
+			Payload: &common.CollectionConfig_StaticCollectionConfig{
+				StaticCollectionConfig: &common.StaticCollectionConfig{
+					Type: common.CollectionType_COL_OFFLEDGER,
+				},
+			},
+		}
+		_, _, err := ComputeDisseminationPlan(
+			channelID, ns, nil, olConfig, nil, nil, nil)
+		assert.NoError(t, err)
+	})
+
+	t.Run("DCAS config", func(t *testing.T) {
+		dcasConfig := &common.CollectionConfig{
+			Payload: &common.CollectionConfig_StaticCollectionConfig{
+				StaticCollectionConfig: &common.StaticCollectionConfig{
+					Type: common.CollectionType_COL_DCAS,
+				},
+			},
+		}
+		_, _, err := ComputeDisseminationPlan(
+			channelID, ns, nil, dcasConfig, nil, nil, nil)
+		assert.NoError(t, err)
+	})
+}
diff --git a/extensions/collections/policy/validator.go b/extensions/collections/policy/validator.go
new file mode 100644
index 00000000..96b629c0
--- /dev/null
+++ b/extensions/collections/policy/validator.go
@@ -0,0 +1,89 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package policy
+
+import (
+	"fmt"
+
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/pkg/errors"
+	olpolicy "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/policy"
+	tdatapolicy "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/policy"
+)
+
+// Validator is a collection policy validator
+type Validator struct {
+}
+
+// NewValidator returns a new collection policy validator
+func NewValidator() *Validator {
+	return &Validator{}
+}
+
+// Validate validates various collection config types
+func (v *Validator) Validate(collConfig *common.CollectionConfig) error {
+	config := collConfig.GetStaticCollectionConfig()
+	if config == nil {
+		return errors.New("unknown collection configuration type")
+	}
+
+	switch config.Type {
+	case common.CollectionType_COL_TRANSIENT:
+		return tdatapolicy.ValidateConfig(config)
+	case common.CollectionType_COL_DCAS:
+		fallthrough
+	case common.CollectionType_COL_OFFLEDGER:
+		return olpolicy.ValidateConfig(config)
+	default:
+		// Nothing to do
+		return nil
+	}
+}
+
+// ValidateNewCollectionConfigsAgainstOld validates updated collection configs
+func (v *Validator) ValidateNewCollectionConfigsAgainstOld(newCollectionConfigs []*common.CollectionConfig, oldCollectionConfigs []*common.CollectionConfig,
+) error {
+	newCollectionsMap := make(map[string]*common.StaticCollectionConfig, len(newCollectionConfigs))
+	for _, newCollectionConfig := range newCollectionConfigs {
+		newCollection := newCollectionConfig.GetStaticCollectionConfig()
+		newCollectionsMap[newCollection.GetName()] = newCollection
+	}
+
+	for _, oldCollConfig := range oldCollectionConfigs {
+		oldColl := oldCollConfig.GetStaticCollectionConfig()
+		if oldColl == nil {
+			// This shouldn't happen since we've already gone through the basic validation
+			return errors.New("invalid collection")
+		}
+		newColl, ok := newCollectionsMap[oldColl.Name]
+		if !ok {
+			continue
+		}
+
+		newCollType := getCollType(newColl)
+		oldCollType := getCollType(oldColl)
+		if newCollType != oldCollType {
+			return fmt.Errorf("collection-name: %s -- attempt to change collection type from [%s] to [%s]", oldColl.Name, oldCollType, newCollType)
+		}
+	}
+	return nil
+}
+
+func getCollType(config *common.StaticCollectionConfig) common.CollectionType {
+	switch config.Type {
+	case common.CollectionType_COL_TRANSIENT:
+		return common.CollectionType_COL_TRANSIENT
+	case common.CollectionType_COL_OFFLEDGER:
+		return common.CollectionType_COL_OFFLEDGER
+	case common.CollectionType_COL_DCAS:
+		return common.CollectionType_COL_DCAS
+	case common.CollectionType_COL_PRIVATE:
+		fallthrough
+	default:
+		return common.CollectionType_COL_PRIVATE
+	}
+}
diff --git a/extensions/collections/policy/validator_test.go b/extensions/collections/policy/validator_test.go
new file mode 100644
index 00000000..6b1e4af8
--- /dev/null
+++ b/extensions/collections/policy/validator_test.go
@@ -0,0 +1,271 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package policy
+
+import (
+	"strings"
+	"testing"
+
+	"github.com/hyperledger/fabric/common/cauthdsl"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/stretchr/testify/assert"
+	"github.com/stretchr/testify/require"
+)
+
+func TestValidateTransientDataCollectionConfig(t *testing.T) {
+	coll1 := "mycollection"
+
+	var signers = [][]byte{[]byte("signer0"), []byte("signer1")}
+
+	v := NewValidator()
+
+	t.Run("No collection type -> success", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		collConfig := createStaticCollectionConfig(coll1, policyEnvelope, 1, 2, 1000)
+		err := v.Validate(collConfig)
+		assert.NoError(t, err)
+	})
+
+	t.Run("Private collection type -> success", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		collConfig := createPrivateCollectionConfig(coll1, policyEnvelope, 1, 2, 1000)
+		err := v.Validate(collConfig)
+		assert.NoError(t, err)
+	})
+
+	t.Run("Transient collection -> success", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createTransientCollectionConfig(coll1, policyEnvelope, 1, 2, "1m"))
+		assert.NoError(t, err)
+	})
+}
+
+func TestValidateOffLedgerCollectionConfig(t *testing.T) {
+	coll1 := "mycollection"
+
+	var signers = [][]byte{[]byte("signer0"), []byte("signer1")}
+
+	v := NewValidator()
+
+	t.Run("Off-Ledger collection -> success", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createOffLedgerCollectionConfig(coll1, policyEnvelope, 1, 2, "1m"))
+		assert.NoError(t, err)
+	})
+
+	t.Run("Off-Ledger req == 0 -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createOffLedgerCollectionConfig(coll1, policyEnvelope, 0, 2, "1m"))
+		require.Error(t, err)
+		expectedErr := "required peer count must be greater than 0"
+		assert.Truef(t, strings.Contains(err.Error(), expectedErr), "Expected error to contain '%s' but got '%s'", expectedErr, err)
+	})
+
+	t.Run("transient collection req > max -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createTransientCollectionConfig(coll1, policyEnvelope, 3, 2, "1m"))
+		require.Error(t, err)
+		expectedErr := "maximum peer count (2) must be greater than or equal to required peer count (3)"
+		assert.Truef(t, strings.Contains(err.Error(), expectedErr), "Expected error to contain '%s' but got '%s'", expectedErr, err)
+	})
+
+	t.Run("Off-Ledger no time-to-live -> success", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createOffLedgerCollectionConfig(coll1, policyEnvelope, 1, 2, ""))
+		require.NoError(t, err)
+	})
+
+	t.Run("Off-Ledger invalid time-to-live -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createOffLedgerCollectionConfig(coll1, policyEnvelope, 1, 2, "1k"))
+		require.Error(t, err)
+		expectedErr := "invalid time format for time to live"
+		assert.Truef(t, strings.Contains(err.Error(), expectedErr), "Expected error to contain '%s' but got '%s'", expectedErr, err)
+	})
+
+	t.Run("Off-Ledger with blocks-to-live -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		config := createTransientCollectionConfig(coll1, policyEnvelope, 1, 2, "1m")
+		config.GetStaticCollectionConfig().BlockToLive = 100
+		err := v.Validate(config)
+		require.Error(t, err)
+		expectedErr := "block-to-live not supported"
+		assert.Truef(t, strings.Contains(err.Error(), expectedErr), "Expected error to contain '%s' but got '%s'", expectedErr, err)
+	})
+}
+
+func TestValidateDCASCollectionConfig(t *testing.T) {
+	coll1 := "mycollection"
+
+	var signers = [][]byte{[]byte("signer0"), []byte("signer1")}
+
+	v := NewValidator()
+
+	t.Run("DCAS collection -> success", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createDCASCollectionConfig(coll1, policyEnvelope, 1, 2, "1m"))
+		assert.NoError(t, err)
+	})
+
+	t.Run("DCAS req == 0 -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createDCASCollectionConfig(coll1, policyEnvelope, 0, 2, "1m"))
+		require.Error(t, err)
+		expectedErr := "required peer count must be greater than 0"
+		assert.Truef(t, strings.Contains(err.Error(), expectedErr), "Expected error to contain '%s' but got '%s'", expectedErr, err)
+	})
+
+	t.Run("transient collection req > max -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createTransientCollectionConfig(coll1, policyEnvelope, 3, 2, "1m"))
+		require.Error(t, err)
+		expectedErr := "maximum peer count (2) must be greater than or equal to required peer count (3)"
+		assert.Truef(t, strings.Contains(err.Error(), expectedErr), "Expected error to contain '%s' but got '%s'", expectedErr, err)
+	})
+
+	t.Run("DCAS no time-to-live -> success", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createDCASCollectionConfig(coll1, policyEnvelope, 1, 2, ""))
+		require.NoError(t, err)
+	})
+
+	t.Run("DCAS invalid time-to-live -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		err := v.Validate(createDCASCollectionConfig(coll1, policyEnvelope, 1, 2, "1k"))
+		require.Error(t, err)
+		expectedErr := "invalid time format for time to live"
+		assert.Truef(t, strings.Contains(err.Error(), expectedErr), "Expected error to contain '%s' but got '%s'", expectedErr, err)
+	})
+
+	t.Run("DCAS with blocks-to-live -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		config := createTransientCollectionConfig(coll1, policyEnvelope, 1, 2, "1m")
+		config.GetStaticCollectionConfig().BlockToLive = 100
+		err := v.Validate(config)
+		require.Error(t, err)
+		expectedErr := "block-to-live not supported"
+		assert.Truef(t, strings.Contains(err.Error(), expectedErr), "Expected error to contain '%s' but got '%s'", expectedErr, err)
+	})
+}
+
+func TestValidateNewCollectionConfigAgainstOld(t *testing.T) {
+	coll1 := "mycollection"
+
+	var signers = [][]byte{[]byte("signer0"), []byte("signer1")}
+
+	v := NewValidator()
+
+	t.Run("updated -> success", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		oldCollConfig := createTransientCollectionConfig(coll1, policyEnvelope, 1, 2, "10m")
+		newCollConfig := createTransientCollectionConfig(coll1, policyEnvelope, 2, 3, "20m")
+		err := v.ValidateNewCollectionConfigsAgainstOld([]*common.CollectionConfig{newCollConfig}, []*common.CollectionConfig{oldCollConfig})
+		assert.NoError(t, err)
+	})
+
+	t.Run("private collection updated to transient -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		oldCollConfig := createStaticCollectionConfig(coll1, policyEnvelope, 1, 2, 1000)
+		newCollConfig := createTransientCollectionConfig(coll1, policyEnvelope, 1, 2, "10m")
+		err := v.ValidateNewCollectionConfigsAgainstOld([]*common.CollectionConfig{newCollConfig}, []*common.CollectionConfig{oldCollConfig})
+		assert.EqualError(t, err, "collection-name: mycollection -- attempt to change collection type from [COL_PRIVATE] to [COL_TRANSIENT]")
+	})
+
+	t.Run("private collection updated to off-ledger -> error", func(t *testing.T) {
+		policyEnvelope := cauthdsl.Envelope(cauthdsl.Or(cauthdsl.SignedBy(0), cauthdsl.SignedBy(1)), signers)
+		oldCollConfig := createStaticCollectionConfig(coll1, policyEnvelope, 1, 2, 1000)
+		newCollConfig := createOffLedgerCollectionConfig(coll1, policyEnvelope, 1, 2, "10m")
+		err := v.ValidateNewCollectionConfigsAgainstOld([]*common.CollectionConfig{newCollConfig}, []*common.CollectionConfig{oldCollConfig})
+		assert.EqualError(t, err, "collection-name: mycollection -- attempt to change collection type from [COL_PRIVATE] to [COL_OFFLEDGER]")
+	})
+}
+
+func createTransientCollectionConfig(collectionName string, signaturePolicyEnvelope *common.SignaturePolicyEnvelope,
+	requiredPeerCount int32, maximumPeerCount int32, ttl string) *common.CollectionConfig {
+	signaturePolicy := &common.CollectionPolicyConfig_SignaturePolicy{
+		SignaturePolicy: signaturePolicyEnvelope,
+	}
+
+	return &common.CollectionConfig{
+		Payload: &common.CollectionConfig_StaticCollectionConfig{
+			StaticCollectionConfig: &common.StaticCollectionConfig{
+				Name:              collectionName,
+				Type:              common.CollectionType_COL_TRANSIENT,
+				MemberOrgsPolicy:  &common.CollectionPolicyConfig{Payload: signaturePolicy},
+				RequiredPeerCount: requiredPeerCount,
+				MaximumPeerCount:  maximumPeerCount,
+				TimeToLive:        ttl,
+			},
+		},
+	}
+}
+
+func createPrivateCollectionConfig(collectionName string, signaturePolicyEnvelope *common.SignaturePolicyEnvelope,
+	requiredPeerCount int32, maximumPeerCount int32, blockToLive uint64) *common.CollectionConfig {
+	config := createStaticCollectionConfig(collectionName, signaturePolicyEnvelope, requiredPeerCount, maximumPeerCount, blockToLive)
+	config.GetStaticCollectionConfig().Type = common.CollectionType_COL_PRIVATE
+	return config
+}
+
+func createStaticCollectionConfig(collectionName string, signaturePolicyEnvelope *common.SignaturePolicyEnvelope,
+	requiredPeerCount int32, maximumPeerCount int32, blockToLive uint64) *common.CollectionConfig {
+	signaturePolicy := &common.CollectionPolicyConfig_SignaturePolicy{
+		SignaturePolicy: signaturePolicyEnvelope,
+	}
+
+	return &common.CollectionConfig{
+		Payload: &common.CollectionConfig_StaticCollectionConfig{
+			StaticCollectionConfig: &common.StaticCollectionConfig{
+				Name:              collectionName,
+				MemberOrgsPolicy:  &common.CollectionPolicyConfig{Payload: signaturePolicy},
+				RequiredPeerCount: requiredPeerCount,
+				MaximumPeerCount:  maximumPeerCount,
+				BlockToLive:       blockToLive,
+			},
+		},
+	}
+}
+
+func createOffLedgerCollectionConfig(collectionName string, signaturePolicyEnvelope *common.SignaturePolicyEnvelope,
+	requiredPeerCount int32, maximumPeerCount int32, ttl string) *common.CollectionConfig {
+	signaturePolicy := &common.CollectionPolicyConfig_SignaturePolicy{
+		SignaturePolicy: signaturePolicyEnvelope,
+	}
+
+	return &common.CollectionConfig{
+		Payload: &common.CollectionConfig_StaticCollectionConfig{
+			StaticCollectionConfig: &common.StaticCollectionConfig{
+				Name:              collectionName,
+				Type:              common.CollectionType_COL_OFFLEDGER,
+				MemberOrgsPolicy:  &common.CollectionPolicyConfig{Payload: signaturePolicy},
+				RequiredPeerCount: requiredPeerCount,
+				MaximumPeerCount:  maximumPeerCount,
+				TimeToLive:        ttl,
+			},
+		},
+	}
+}
+
+func createDCASCollectionConfig(collectionName string, signaturePolicyEnvelope *common.SignaturePolicyEnvelope,
+	requiredPeerCount int32, maximumPeerCount int32, ttl string) *common.CollectionConfig {
+	signaturePolicy := &common.CollectionPolicyConfig_SignaturePolicy{
+		SignaturePolicy: signaturePolicyEnvelope,
+	}
+
+	return &common.CollectionConfig{
+		Payload: &common.CollectionConfig_StaticCollectionConfig{
+			StaticCollectionConfig: &common.StaticCollectionConfig{
+				Name:              collectionName,
+				Type:              common.CollectionType_COL_DCAS,
+				MemberOrgsPolicy:  &common.CollectionPolicyConfig{Payload: signaturePolicy},
+				RequiredPeerCount: requiredPeerCount,
+				MaximumPeerCount:  maximumPeerCount,
+				TimeToLive:        ttl,
+			},
+		},
+	}
+}
diff --git a/extensions/collections/pvtdatahandler/pvtdatahandler.go b/extensions/collections/pvtdatahandler/pvtdatahandler.go
new file mode 100644
index 00000000..012f6883
--- /dev/null
+++ b/extensions/collections/pvtdatahandler/pvtdatahandler.go
@@ -0,0 +1,17 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatahandler
+
+import (
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	extpvtdatahandler "github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatahandler"
+)
+
+// New returns a new Handler
+func New(channelID string, collDataProvider storeapi.Provider) *extpvtdatahandler.Handler {
+	return extpvtdatahandler.New(channelID, collDataProvider)
+}
diff --git a/extensions/collections/pvtdatahandler/pvtdatahandler_test.go b/extensions/collections/pvtdatahandler/pvtdatahandler_test.go
new file mode 100644
index 00000000..3d033f16
--- /dev/null
+++ b/extensions/collections/pvtdatahandler/pvtdatahandler_test.go
@@ -0,0 +1,40 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatahandler
+
+import (
+	"testing"
+
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/stretchr/testify/assert"
+)
+
+func TestHandler_HandleGetPrivateData(t *testing.T) {
+	h := New("testchannel", nil)
+
+	config := &common.StaticCollectionConfig{
+		Name: "coll1",
+	}
+
+	value, handled, err := h.HandleGetPrivateData("tx1", "ns1", config, "key1")
+	assert.NoError(t, err)
+	assert.False(t, handled)
+	assert.Nil(t, value)
+}
+
+func TestHandler_HandleGetPrivateDataMultipleKeys(t *testing.T) {
+	h := New("testchannel", nil)
+
+	config := &common.StaticCollectionConfig{
+		Name: "coll1",
+	}
+
+	value, handled, err := h.HandleGetPrivateDataMultipleKeys("tx1", "ns1", config, []string{"key1", "key2"})
+	assert.NoError(t, err)
+	assert.False(t, handled)
+	assert.Nil(t, value)
+}
diff --git a/extensions/collections/retriever/retriever.go b/extensions/collections/retriever/retriever.go
new file mode 100644
index 00000000..7697e084
--- /dev/null
+++ b/extensions/collections/retriever/retriever.go
@@ -0,0 +1,25 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package retriever
+
+import (
+	"github.com/hyperledger/fabric/core/ledger"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	supportapi "github.com/hyperledger/fabric/extensions/collections/api/support"
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	extretriever "github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever"
+)
+
+// NewProvider returns a new private data Retriever provider
+func NewProvider(
+	storeProvider func(channelID string) storeapi.Store,
+	ledgerProvider func(channelID string) ledger.PeerLedger,
+	gossipProvider func() supportapi.GossipAdapter,
+	blockPublisherProvider func(channelID string) gossipapi.BlockPublisher) storeapi.Provider {
+
+	return extretriever.NewProvider(storeProvider, ledgerProvider, gossipProvider, blockPublisherProvider)
+}
diff --git a/extensions/collections/retriever/retriever_test.go b/extensions/collections/retriever/retriever_test.go
new file mode 100644
index 00000000..928883f5
--- /dev/null
+++ b/extensions/collections/retriever/retriever_test.go
@@ -0,0 +1,33 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package retriever
+
+import (
+	"testing"
+
+	supportapi "github.com/hyperledger/fabric/extensions/collections/api/support"
+	"github.com/stretchr/testify/require"
+	olapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api"
+	olmocks "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/mocks"
+	extretriever "github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever"
+	tdataapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+	tdatamocks "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/mocks"
+)
+
+func TestNewProvider(t *testing.T) {
+	extretriever.SetTransientDataProvider(func(storeProvider func(channelID string) tdataapi.Store, support extretriever.Support, gossipProvider func() supportapi.GossipAdapter) tdataapi.Provider {
+		return &tdatamocks.TransientDataProvider{}
+	})
+
+	extretriever.SetOffLedgerProvider(func(storeProvider func(channelID string) olapi.Store, support extretriever.Support, gossipProvider func() supportapi.GossipAdapter) olapi.Provider {
+		return &olmocks.Provider{}
+	})
+
+	p := NewProvider(nil, nil, nil, nil)
+	require.NotNil(t, p)
+	require.NotNil(t, p.RetrieverForChannel("testchannel"))
+}
diff --git a/extensions/collections/storeprovider/mocks/mocktdstore.go b/extensions/collections/storeprovider/mocks/mocktdstore.go
new file mode 100644
index 00000000..a2f0d9c3
--- /dev/null
+++ b/extensions/collections/storeprovider/mocks/mocktdstore.go
@@ -0,0 +1,119 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	proto "github.com/hyperledger/fabric/protos/transientstore"
+	tdapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+)
+
+// TransientDataStoreProvider implements a mock transient data store provider
+type TransientDataStoreProvider struct {
+	store *TransientDataStore
+	err   error
+}
+
+// NewTransientDataStoreProvider creates a new provider
+func NewTransientDataStoreProvider() *TransientDataStoreProvider {
+	return &TransientDataStoreProvider{
+		store: NewTransientDataStore(),
+	}
+}
+
+// Data stores key value
+func (p *TransientDataStoreProvider) Data(key *storeapi.Key, value *storeapi.ExpiringValue) *TransientDataStoreProvider {
+	p.store.Data(key, value)
+	return p
+}
+
+// Error stores the error
+func (p *TransientDataStoreProvider) Error(err error) *TransientDataStoreProvider {
+	p.err = err
+	return p
+}
+
+// StoreError stores the StoreError
+func (p *TransientDataStoreProvider) StoreError(err error) *TransientDataStoreProvider {
+	p.store.Error(err)
+	return p
+}
+
+// StoreForChannel returns the transient data store for the given channel
+func (p *TransientDataStoreProvider) StoreForChannel(channelID string) tdapi.Store {
+	return p.store
+}
+
+// OpenStore opens the transient data store for the given channel
+func (p *TransientDataStoreProvider) OpenStore(channelID string) (tdapi.Store, error) {
+	return p.store, p.err
+}
+
+// Close closes the transient data store for the given channel
+func (p *TransientDataStoreProvider) Close() {
+	p.store.Close()
+}
+
+// IsStoreClosed indicates whether the transient data store is closed
+func (p *TransientDataStoreProvider) IsStoreClosed() bool {
+	return p.store.closed
+}
+
+// TransientDataStore implements a mock transient data store
+type TransientDataStore struct {
+	transientData map[storeapi.Key]*storeapi.ExpiringValue
+	err           error
+	closed        bool
+}
+
+// NewTransientDataStore returns a mock transient data store
+func NewTransientDataStore() *TransientDataStore {
+	return &TransientDataStore{
+		transientData: make(map[storeapi.Key]*storeapi.ExpiringValue),
+	}
+}
+
+// Data sets the transient data for the given key
+func (m *TransientDataStore) Data(key *storeapi.Key, value *storeapi.ExpiringValue) *TransientDataStore {
+	m.transientData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}] = value
+	return m
+}
+
+// Error sets an err
+func (m *TransientDataStore) Error(err error) *TransientDataStore {
+	m.err = err
+	return m
+}
+
+// Persist stores the private write set of a transaction along with the collection config
+// in the transient store based on txid and the block height the private data was received at
+func (m *TransientDataStore) Persist(txid string, privateSimulationResultsWithConfig *proto.TxPvtReadWriteSetWithConfigInfo) error {
+	return m.err
+}
+
+// GetTransientData gets the value for the given transient data item
+func (m *TransientDataStore) GetTransientData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return m.transientData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}], m.err
+}
+
+// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+func (m *TransientDataStore) GetTransientDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	var values storeapi.ExpiringValues
+	for _, k := range key.Keys {
+		value, err := m.GetTransientData(&storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: k})
+		if err != nil {
+			return nil, err
+		}
+		values = append(values, value)
+	}
+	return values, m.err
+}
+
+// Close closes the store
+func (m *TransientDataStore) Close() {
+	m.closed = true
+}
diff --git a/extensions/collections/storeprovider/storeprovider.go b/extensions/collections/storeprovider/storeprovider.go
new file mode 100644
index 00000000..faac4e9c
--- /dev/null
+++ b/extensions/collections/storeprovider/storeprovider.go
@@ -0,0 +1,16 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	extstoreprovider "github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider"
+)
+
+// NewProviderFactory returns a new store provider factory
+func NewProviderFactory() *extstoreprovider.StoreProvider {
+	return extstoreprovider.New()
+}
diff --git a/extensions/collections/storeprovider/storeprovider_test.go b/extensions/collections/storeprovider/storeprovider_test.go
new file mode 100644
index 00000000..444e188d
--- /dev/null
+++ b/extensions/collections/storeprovider/storeprovider_test.go
@@ -0,0 +1,104 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	"testing"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	spmocks "github.com/hyperledger/fabric/extensions/collections/storeprovider/mocks"
+	"github.com/pkg/errors"
+	"github.com/stretchr/testify/assert"
+	"github.com/stretchr/testify/require"
+	extstoreprovider "github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider"
+	tdapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/mocks"
+)
+
+func TestStoreProvider(t *testing.T) {
+	tdataProvider := spmocks.NewTransientDataStoreProvider()
+
+	extstoreprovider.SetNewTransientDataProvider(func() tdapi.StoreProvider {
+		return tdataProvider
+	})
+
+	t.Run("OpenStore - success", func(t *testing.T) {
+		p := NewProviderFactory()
+		require.NotNil(t, p)
+
+		s, err := p.OpenStore("testchannel")
+		require.NoError(t, err)
+		require.NotNil(t, s)
+
+		s2 := p.StoreForChannel("testchannel")
+		require.Equal(t, s, s2)
+	})
+
+	t.Run("OpenStore - transient data error", func(t *testing.T) {
+		p := NewProviderFactory()
+		require.NotNil(t, p)
+
+		expectedErr := errors.New("transientdata error")
+		tdataProvider.Error(expectedErr)
+		defer tdataProvider.Error(nil)
+
+		s, err := p.OpenStore("testchannel")
+		assert.EqualError(t, err, expectedErr.Error())
+		require.Nil(t, s)
+	})
+}
+
+func TestStore_PutAndGetData(t *testing.T) {
+	const (
+		tx1   = "tx1"
+		ns1   = "ns1"
+		coll1 = "coll1"
+		key1  = "key1"
+		key2  = "key2"
+	)
+
+	k1 := storeapi.NewKey(tx1, ns1, coll1, key1)
+	k2 := storeapi.NewKey(tx1, ns1, coll1, key2)
+
+	v1 := &storeapi.ExpiringValue{Value: []byte("value1")}
+	v2 := &storeapi.ExpiringValue{Value: []byte("value1")}
+
+	tdataProvider := spmocks.NewTransientDataStoreProvider()
+
+	extstoreprovider.SetNewTransientDataProvider(func() tdapi.StoreProvider {
+		return tdataProvider.Data(k1, v1).Data(k2, v2)
+	})
+
+	p := NewProviderFactory()
+	require.NotNil(t, p)
+
+	s, err := p.OpenStore("testchannel")
+	require.NoError(t, err)
+	require.NotNil(t, s)
+
+	t.Run("GetTransientData", func(t *testing.T) {
+		value, err := s.GetTransientData(k1)
+		require.NoError(t, err)
+		require.NotNil(t, value)
+
+		values, err := s.GetTransientDataMultipleKeys(storeapi.NewMultiKey(tx1, ns1, coll1, key1, key2))
+		require.NoError(t, err)
+		assert.Equal(t, 2, len(values))
+	})
+
+	t.Run("Persist", func(t *testing.T) {
+		err := s.Persist(tx1, mocks.NewPvtReadWriteSetBuilder().Build())
+		assert.NoError(t, err)
+
+		expectedErr := errors.New("transient data error")
+		tdataProvider.StoreError(expectedErr)
+		err = s.Persist(tx1, mocks.NewPvtReadWriteSetBuilder().Build())
+		require.Error(t, err)
+		assert.Contains(t, err.Error(), expectedErr.Error())
+		tdataProvider.StoreError(nil)
+	})
+}
diff --git a/extensions/endorser/endorser.go b/extensions/endorser/endorser.go
new file mode 100644
index 00000000..79a72fb1
--- /dev/null
+++ b/extensions/endorser/endorser.go
@@ -0,0 +1,18 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package endorser
+
+import (
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	extendorser "github.com/trustbloc/fabric-peer-ext/pkg/endorser"
+)
+
+// FilterPubSimulationResults filters the public simulation results and returns the filtered results or error.
+func FilterPubSimulationResults(collConfigs map[string]*common.CollectionConfigPackage, pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error) {
+	return extendorser.FilterPubSimulationResults(collConfigs, pubSimulationResults)
+}
diff --git a/extensions/endorser/endorser_test.go b/extensions/endorser/endorser_test.go
new file mode 100644
index 00000000..c5a8741e
--- /dev/null
+++ b/extensions/endorser/endorser_test.go
@@ -0,0 +1,22 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package endorser
+
+import (
+	"testing"
+
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/stretchr/testify/assert"
+)
+
+func TestFilterPubSimulationResults(t *testing.T) {
+	pubSimulationResults := &rwset.TxReadWriteSet{}
+	p, err := FilterPubSimulationResults(map[string]*common.CollectionConfigPackage{}, pubSimulationResults)
+	assert.NoError(t, err)
+	assert.Equal(t, pubSimulationResults, p)
+}
diff --git a/extensions/gossip/api/gossipapi.go b/extensions/gossip/api/gossipapi.go
new file mode 100644
index 00000000..6b0b88f9
--- /dev/null
+++ b/extensions/gossip/api/gossipapi.go
@@ -0,0 +1,44 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package api
+
+import (
+	cb "github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	pb "github.com/hyperledger/fabric/protos/peer"
+)
+
+// ConfigUpdateHandler handles a config update
+type ConfigUpdateHandler func(blockNum uint64, configUpdate *cb.ConfigUpdate) error
+
+// WriteHandler handles a KV write
+type WriteHandler func(blockNum uint64, txID string, namespace string, kvWrite *kvrwset.KVWrite) error
+
+// ReadHandler handles a KV read
+type ReadHandler func(blockNum uint64, txID string, namespace string, kvRead *kvrwset.KVRead) error
+
+// ChaincodeEventHandler handles a chaincode event
+type ChaincodeEventHandler func(blockNum uint64, txID string, event *pb.ChaincodeEvent) error
+
+// ChaincodeUpgradeHandler handles chaincode upgrade events
+type ChaincodeUpgradeHandler func(blockNum uint64, txID string, chaincodeName string) error
+
+// BlockPublisher allows clients to add handlers for various block events
+type BlockPublisher interface {
+	// AddCCUpgradeHandler adds a handler for chaincode upgrades
+	AddCCUpgradeHandler(handler ChaincodeUpgradeHandler)
+	// AddConfigUpdateHandler adds a handler for config updates
+	AddConfigUpdateHandler(handler ConfigUpdateHandler)
+	// AddWriteHandler adds a handler for KV writes
+	AddWriteHandler(handler WriteHandler)
+	// AddReadHandler adds a handler for KV reads
+	AddReadHandler(handler ReadHandler)
+	// AddCCEventHandler adds a handler for chaincode events
+	AddCCEventHandler(handler ChaincodeEventHandler)
+	// Publish traverses the block and invokes all applicable handlers
+	Publish(block *cb.Block)
+}
diff --git a/extensions/gossip/blockpublisher/blockpublisher.go b/extensions/gossip/blockpublisher/blockpublisher.go
new file mode 100644
index 00000000..bd9315b1
--- /dev/null
+++ b/extensions/gossip/blockpublisher/blockpublisher.go
@@ -0,0 +1,16 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package blockpublisher
+
+import (
+	extblockpublisher "github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher"
+)
+
+// NewProvider returns a new block publisher provider
+func NewProvider() *extblockpublisher.Provider {
+	return extblockpublisher.NewProvider()
+}
diff --git a/extensions/gossip/blockpublisher/blockpublisher_test.go b/extensions/gossip/blockpublisher/blockpublisher_test.go
new file mode 100644
index 00000000..775451f4
--- /dev/null
+++ b/extensions/gossip/blockpublisher/blockpublisher_test.go
@@ -0,0 +1,67 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package blockpublisher
+
+import (
+	"testing"
+	"time"
+
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	pb "github.com/hyperledger/fabric/protos/peer"
+	"github.com/magiconair/properties/assert"
+	"github.com/stretchr/testify/require"
+	"github.com/trustbloc/fabric-peer-ext/pkg/mocks"
+)
+
+const (
+	channelID = "testchannel"
+	txID1     = "tx1"
+	ccID1     = "cc1"
+	key1      = "key1"
+	ccEvent1  = "ccevent1"
+)
+
+func TestProvider(t *testing.T) {
+	var (
+		value1 = []byte("value1")
+
+		v1 = &kvrwset.Version{
+			BlockNum: 1000,
+			TxNum:    0,
+		}
+	)
+
+	p := NewProvider()
+	require.NotNil(t, p)
+
+	publisher := p.ForChannel(channelID)
+	require.NotNil(t, publisher)
+
+	handler := mocks.NewMockBlockHandler()
+
+	publisher.AddWriteHandler(handler.HandleWrite)
+	publisher.AddReadHandler(handler.HandleRead)
+	publisher.AddCCEventHandler(handler.HandleChaincodeEvent)
+
+	b := mocks.NewBlockBuilder(channelID, 1100)
+	defer p.Close()
+
+	b.Transaction(txID1, pb.TxValidationCode_VALID).
+		ChaincodeAction(ccID1).
+		Write(key1, value1).
+		Read(key1, v1).
+		ChaincodeEvent(ccEvent1, []byte("ccpayload"))
+
+	publisher.Publish(b.Build())
+
+	// Wait a bit for the events to be published
+	time.Sleep(500 * time.Millisecond)
+
+	assert.Equal(t, handler.NumReads(), 1)
+	assert.Equal(t, handler.NumWrites(), 1)
+	assert.Equal(t, handler.NumCCEvents(), 1)
+}
diff --git a/extensions/gossip/coordinator/coordinator.go b/extensions/gossip/coordinator/coordinator.go
new file mode 100644
index 00000000..23573b2d
--- /dev/null
+++ b/extensions/gossip/coordinator/coordinator.go
@@ -0,0 +1,24 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package coordinator
+
+import (
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	"github.com/hyperledger/fabric/protos/transientstore"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatastore"
+)
+
+type transientStore interface {
+	// PersistWithConfig stores the private write set of a transaction along with the collection config
+	// in the transient store based on txid and the block height the private data was received at
+	PersistWithConfig(txid string, blockHeight uint64, privateSimulationResultsWithConfig *transientstore.TxPvtReadWriteSetWithConfigInfo) error
+}
+
+// New returns a new PvtDataStore
+func New(channelID string, transientStore transientStore, collDataStore storeapi.Store) *pvtdatastore.Store {
+	return pvtdatastore.New(channelID, transientStore, collDataStore)
+}
diff --git a/extensions/gossip/coordinator/coordinator_test.go b/extensions/gossip/coordinator/coordinator_test.go
new file mode 100644
index 00000000..1730f21e
--- /dev/null
+++ b/extensions/gossip/coordinator/coordinator_test.go
@@ -0,0 +1,50 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package coordinator
+
+import (
+	"testing"
+
+	"github.com/hyperledger/fabric/protos/transientstore"
+	"github.com/stretchr/testify/assert"
+	"github.com/stretchr/testify/require"
+	"github.com/trustbloc/fabric-peer-ext/pkg/mocks"
+)
+
+const (
+	channelID = "testchannel"
+
+	ns1 = "ns1"
+
+	coll1 = "coll1"
+	coll2 = "coll2"
+
+	policy1 = "OR('Org1MSP.member','Org2MSP.member')"
+)
+
+func TestCoordinator_StorePvtData(t *testing.T) {
+	tStore := &mockTransientStore{}
+	collStore := mocks.NewDataStore()
+
+	c := New(channelID, tStore, collStore)
+	require.NotNil(t, c)
+
+	b := mocks.NewPvtReadWriteSetBuilder()
+	nsBuilder := b.Namespace(ns1)
+	nsBuilder.Collection(coll1).StaticConfig(policy1, 2, 5, 1000)
+	nsBuilder.Collection(coll2).TransientConfig(policy1, 2, 5, "1m")
+
+	err := c.StorePvtData("tx1", b.Build(), 1000)
+	assert.NoError(t, err)
+}
+
+type mockTransientStore struct {
+}
+
+func (m *mockTransientStore) PersistWithConfig(txid string, blockHeight uint64, privateSimulationResultsWithConfig *transientstore.TxPvtReadWriteSetWithConfigInfo) error {
+	return nil
+}
diff --git a/extensions/gossip/dispatcher/dispatcher.go b/extensions/gossip/dispatcher/dispatcher.go
new file mode 100644
index 00000000..9ddb4ed5
--- /dev/null
+++ b/extensions/gossip/dispatcher/dispatcher.go
@@ -0,0 +1,37 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dispatcher
+
+import (
+	"github.com/hyperledger/fabric/core/ledger"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	gossip "github.com/hyperledger/fabric/gossip/api"
+	"github.com/hyperledger/fabric/gossip/common"
+	"github.com/hyperledger/fabric/gossip/discovery"
+	extdispatcher "github.com/trustbloc/fabric-peer-ext/pkg/gossip/dispatcher"
+)
+
+type gossipAdapter interface {
+	PeersOfChannel(common.ChainID) []discovery.NetworkMember
+	SelfMembershipInfo() discovery.NetworkMember
+	IdentityInfo() gossip.PeerIdentitySet
+}
+
+type blockPublisher interface {
+	AddCCUpgradeHandler(handler gossipapi.ChaincodeUpgradeHandler)
+}
+
+// New returns a new Gossip message dispatcher
+func New(
+	channelID string,
+	dataStore storeapi.Store,
+	gossipAdapter gossipAdapter,
+	ledger ledger.PeerLedger,
+	blockPublisher blockPublisher) *extdispatcher.Dispatcher {
+	return extdispatcher.New(channelID, dataStore, gossipAdapter, ledger, blockPublisher)
+}
diff --git a/extensions/gossip/dispatcher/dispatcher_test.go b/extensions/gossip/dispatcher/dispatcher_test.go
new file mode 100644
index 00000000..e93f7372
--- /dev/null
+++ b/extensions/gossip/dispatcher/dispatcher_test.go
@@ -0,0 +1,38 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dispatcher
+
+import (
+	"testing"
+
+	gproto "github.com/hyperledger/fabric/protos/gossip"
+	"github.com/stretchr/testify/assert"
+	"github.com/stretchr/testify/require"
+	"github.com/trustbloc/fabric-peer-ext/pkg/mocks"
+)
+
+func TestProvider(t *testing.T) {
+	const channelID = "testchannel"
+
+	dispatcher := New(
+		channelID,
+		&mocks.DataStore{},
+		mocks.NewMockGossipAdapter(),
+		&mocks.Ledger{QueryExecutor: mocks.NewQueryExecutor(nil)},
+		mocks.NewBlockPublisher(),
+	)
+
+	var response *gproto.GossipMessage
+	msg := &mocks.MockReceivedMessage{
+		Message: mocks.NewDataMsg(channelID),
+		RespondTo: func(msg *gproto.GossipMessage) {
+			response = msg
+		},
+	}
+	assert.False(t, dispatcher.Dispatch(msg))
+	require.Nil(t, response)
+}
diff --git a/extensions/gossip/mocks/blockpublisher.go b/extensions/gossip/mocks/blockpublisher.go
new file mode 100644
index 00000000..688bcdaa
--- /dev/null
+++ b/extensions/gossip/mocks/blockpublisher.go
@@ -0,0 +1,51 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"github.com/hyperledger/fabric/extensions/gossip/api"
+	cb "github.com/hyperledger/fabric/protos/common"
+)
+
+// BlockPublisher is a mock block publisher
+type BlockPublisher struct {
+}
+
+// NewBlockPublisher returns a new mock block publisher
+func NewBlockPublisher() *BlockPublisher {
+	return &BlockPublisher{}
+}
+
+// AddCCUpgradeHandler adds a handler for chaincode upgrades
+func (m *BlockPublisher) AddCCUpgradeHandler(handler api.ChaincodeUpgradeHandler) {
+	// Not implemented
+}
+
+// AddConfigUpdateHandler adds a handler for config updates
+func (m *BlockPublisher) AddConfigUpdateHandler(handler api.ConfigUpdateHandler) {
+	// Not implemented
+}
+
+// AddWriteHandler adds a handler for KV writes
+func (m *BlockPublisher) AddWriteHandler(handler api.WriteHandler) {
+	// Not implemented
+}
+
+// AddReadHandler adds a handler for KV reads
+func (m *BlockPublisher) AddReadHandler(handler api.ReadHandler) {
+	// Not implemented
+}
+
+// AddCCEventHandler adds a handler for chaincode events
+func (m *BlockPublisher) AddCCEventHandler(handler api.ChaincodeEventHandler) {
+	// Not implemented
+}
+
+// Publish traverses the block and invokes all applicable handlers
+func (m *BlockPublisher) Publish(block *cb.Block) {
+	// Not implemented
+}
diff --git a/extensions/idstore/store.go b/extensions/idstore/store.go
new file mode 100644
index 00000000..a9d5861d
--- /dev/null
+++ b/extensions/idstore/store.go
@@ -0,0 +1,17 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package idstore
+
+import (
+	"github.com/hyperledger/fabric/core/ledger/kvledger/idstore"
+	s "github.com/trustbloc/fabric-peer-ext/pkg/idstore"
+)
+
+// OpenIDStore open idstore
+func OpenIDStore(path string) idstore.IDStore {
+	return s.OpenIDStore(path)
+}
diff --git a/extensions/idstore/store_test.go b/extensions/idstore/store_test.go
new file mode 100644
index 00000000..a1c92945
--- /dev/null
+++ b/extensions/idstore/store_test.go
@@ -0,0 +1,20 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package idstore
+
+import (
+	"testing"
+
+	"github.com/hyperledger/fabric/extensions/testutil"
+	"github.com/stretchr/testify/require"
+)
+
+func TestOpenIDStore(t *testing.T) {
+	_, _, destroy := testutil.SetupExtTestEnv()
+	defer destroy()
+	require.NotEmpty(t, OpenIDStore(""))
+}
diff --git a/extensions/mocks/mockdatastore.go b/extensions/mocks/mockdatastore.go
new file mode 100644
index 00000000..7410c46d
--- /dev/null
+++ b/extensions/mocks/mockdatastore.go
@@ -0,0 +1,101 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	cb "github.com/hyperledger/fabric/protos/common"
+	proto "github.com/hyperledger/fabric/protos/transientstore"
+)
+
+// DataStore implements a mock data store
+type DataStore struct {
+	transientData map[storeapi.Key]*storeapi.ExpiringValue
+	olData        map[storeapi.Key]*storeapi.ExpiringValue
+	err           error
+}
+
+// NewDataStore returns a mock transient data store
+func NewDataStore() *DataStore {
+	return &DataStore{
+		transientData: make(map[storeapi.Key]*storeapi.ExpiringValue),
+		olData:        make(map[storeapi.Key]*storeapi.ExpiringValue),
+	}
+}
+
+// TransientData sets the transient data for the given key
+func (m *DataStore) TransientData(key *storeapi.Key, value *storeapi.ExpiringValue) *DataStore {
+	m.transientData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}] = value
+	return m
+}
+
+// Data sets the data for the given key
+func (m *DataStore) Data(key *storeapi.Key, value *storeapi.ExpiringValue) *DataStore {
+	m.olData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}] = value
+	return m
+}
+
+// Error sets an err
+func (m *DataStore) Error(err error) *DataStore {
+	m.err = err
+	return m
+}
+
+// Persist stores the private write set of a transaction along with the collection config
+// in the transient store based on txid and the block height the private data was received at
+func (m *DataStore) Persist(txid string, privateSimulationResultsWithConfig *proto.TxPvtReadWriteSetWithConfigInfo) error {
+	return m.err
+}
+
+// GetTransientData gets the value for the given transient data item
+func (m *DataStore) GetTransientData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return m.transientData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}], m.err
+}
+
+// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+func (m *DataStore) GetTransientDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	var values storeapi.ExpiringValues
+	for _, k := range key.Keys {
+		value, err := m.GetTransientData(&storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: k})
+		if err != nil {
+			return nil, err
+		}
+		values = append(values, value)
+	}
+	return values, m.err
+}
+
+// PutData stores the key/value
+func (m *DataStore) PutData(config *cb.StaticCollectionConfig, key *storeapi.Key, value *storeapi.ExpiringValue) error {
+	if m.err != nil {
+		return m.err
+	}
+	m.olData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}] = value
+	return nil
+}
+
+// GetData gets the value for the given DCAS item
+func (m *DataStore) GetData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return m.olData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}], m.err
+}
+
+// GetDataMultipleKeys gets the values for the multiple DCAS items in a single call
+func (m *DataStore) GetDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	var values storeapi.ExpiringValues
+	for _, k := range key.Keys {
+		value, err := m.GetData(&storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: k})
+		if err != nil {
+			return nil, err
+		}
+		values = append(values, value)
+	}
+	return values, m.err
+}
+
+// Close closes the store
+func (m *DataStore) Close() {
+}
diff --git a/extensions/mocks/mockprovider.go b/extensions/mocks/mockprovider.go
new file mode 100644
index 00000000..b33774bc
--- /dev/null
+++ b/extensions/mocks/mockprovider.go
@@ -0,0 +1,53 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"context"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+)
+
+// DataProvider is a mock data provider
+type DataProvider struct {
+}
+
+// RetrieverForChannel retrieve data for channel
+func (p *DataProvider) RetrieverForChannel(channel string) storeapi.Retriever {
+	return &dataRetriever{}
+}
+
+type dataRetriever struct {
+}
+
+// GetTransientData returns the transient data for the given context and key
+func (m *dataRetriever) GetTransientData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return &storeapi.ExpiringValue{Value: []byte(key.Key)}, nil
+}
+
+// GetTransientDataMultipleKeys returns the transient data with multiple keys for the given context and key
+func (m *dataRetriever) GetTransientDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	values := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		values[i] = &storeapi.ExpiringValue{Value: []byte(k)}
+	}
+	return values, nil
+}
+
+// GetData returns the data for the given context and key
+func (m *dataRetriever) GetData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return &storeapi.ExpiringValue{Value: []byte(key.Key)}, nil
+}
+
+// GetDataMultipleKeys returns the  data with multiple keys for the given context and key
+func (m *dataRetriever) GetDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	values := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		values[i] = &storeapi.ExpiringValue{Value: []byte(k)}
+	}
+	return values, nil
+}
diff --git a/extensions/pvtdatastorage/store.go b/extensions/pvtdatastorage/store.go
new file mode 100644
index 00000000..cb98cf71
--- /dev/null
+++ b/extensions/pvtdatastorage/store.go
@@ -0,0 +1,17 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatastorage
+
+import (
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	s "github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage"
+)
+
+// NewProvider instantiates a StoreProvider
+func NewProvider() pvtdatastorage.Provider {
+	return s.NewProvider()
+}
diff --git a/extensions/pvtdatastorage/store_test.go b/extensions/pvtdatastorage/store_test.go
new file mode 100644
index 00000000..9cc0411e
--- /dev/null
+++ b/extensions/pvtdatastorage/store_test.go
@@ -0,0 +1,33 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatastorage
+
+import (
+	"io/ioutil"
+	"os"
+	"testing"
+
+	"github.com/hyperledger/fabric/extensions/testutil"
+	"github.com/spf13/viper"
+	"github.com/stretchr/testify/require"
+)
+
+func TestNewProvider(t *testing.T) {
+	cleanup := setupPath(t)
+	defer cleanup()
+	_, _, destroy := testutil.SetupExtTestEnv()
+	defer destroy()
+	require.NotEmpty(t, NewProvider())
+}
+
+func setupPath(t *testing.T) (cleanup func()) {
+	tempDir, err := ioutil.TempDir("", "pvtdatastorage")
+	require.NoError(t, err)
+
+	viper.Set("peer.fileSystemPath", tempDir)
+	return func() { os.RemoveAll(tempDir) }
+}
diff --git a/extensions/roles/ledger_roles_config.go b/extensions/roles/ledger_roles_config.go
new file mode 100644
index 00000000..1acf7c6e
--- /dev/null
+++ b/extensions/roles/ledger_roles_config.go
@@ -0,0 +1,30 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package roles
+
+import "github.com/trustbloc/fabric-peer-ext/pkg/roles"
+
+// IsCommitter returns true if the peer is a committer, otherwise the peer does not commit to the DB
+func IsCommitter() bool {
+	return roles.IsCommitter()
+}
+
+// IsEndorser returns true if the peer is an endorser
+func IsEndorser() bool {
+	return roles.IsEndorser()
+}
+
+// IsValidator returns true if the peer is a validator
+func IsValidator() bool {
+	return roles.IsValidator()
+}
+
+// RolesAsString returns the roles for the peer
+// nolint - this is an exported function (Renaming function name will break in other projects)
+func RolesAsString() []string {
+	return roles.AsString()
+}
diff --git a/extensions/roles/ledger_roles_config_test.go b/extensions/roles/ledger_roles_config_test.go
new file mode 100644
index 00000000..7d11d02c
--- /dev/null
+++ b/extensions/roles/ledger_roles_config_test.go
@@ -0,0 +1,29 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package roles
+
+import (
+	"testing"
+
+	"github.com/stretchr/testify/require"
+)
+
+func TestIsCommitter(t *testing.T) {
+	require.True(t, IsCommitter())
+}
+
+func TestIsEndorser(t *testing.T) {
+	require.True(t, IsEndorser())
+}
+
+func TestIsValidator(t *testing.T) {
+	require.True(t, IsValidator())
+}
+
+func TestRolesAsString(t *testing.T) {
+	require.Empty(t, RolesAsString())
+}
diff --git a/extensions/statedb/store.go b/extensions/statedb/store.go
new file mode 100644
index 00000000..c7036307
--- /dev/null
+++ b/extensions/statedb/store.go
@@ -0,0 +1,16 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package privacyenabledstate
+
+import (
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/statedb"
+)
+
+// NewVersionedDBProvider instantiates VersionedDBProvider
+func NewVersionedDBProvider(vdbProvider statedb.VersionedDBProvider) statedb.VersionedDBProvider {
+	return vdbProvider
+}
diff --git a/extensions/statedb/store_test.go b/extensions/statedb/store_test.go
new file mode 100644
index 00000000..d5c1be60
--- /dev/null
+++ b/extensions/statedb/store_test.go
@@ -0,0 +1,34 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package privacyenabledstate
+
+import (
+	"io/ioutil"
+	"os"
+	"testing"
+
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/statedb/stateleveldb"
+	"github.com/spf13/viper"
+	"github.com/stretchr/testify/require"
+)
+
+func TestNewProvider(t *testing.T) {
+	cleanup := setupPath(t)
+	defer cleanup()
+
+	require.NotEmpty(t, NewVersionedDBProvider(stateleveldb.NewVersionedDBProvider()))
+
+	require.Empty(t, NewVersionedDBProvider(nil))
+}
+
+func setupPath(t *testing.T) (cleanup func()) {
+	tempDir, err := ioutil.TempDir("", "statedb")
+	require.NoError(t, err)
+
+	viper.Set("peer.fileSystemPath", tempDir)
+	return func() { os.RemoveAll(tempDir) }
+}
diff --git a/extensions/testutil/ext_test_env.go b/extensions/testutil/ext_test_env.go
new file mode 100644
index 00000000..deec5a55
--- /dev/null
+++ b/extensions/testutil/ext_test_env.go
@@ -0,0 +1,25 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package testutil
+
+import (
+	"testing"
+
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/statedb"
+	"github.com/trustbloc/fabric-peer-ext/pkg/testutil"
+)
+
+//SetupExtTestEnv creates new couchdb instance for test
+//returns couchdbd address, cleanup and stop function handle.
+func SetupExtTestEnv() (addr string, cleanup func(string), stop func()) {
+	return testutil.SetupExtTestEnv()
+}
+
+// GetExtStateDBProvider returns the implementation of the versionedDBProvider
+func GetExtStateDBProvider(t testing.TB, dbProvider statedb.VersionedDBProvider) statedb.VersionedDBProvider {
+	return nil
+}
diff --git a/extensions/transientstore/store.go b/extensions/transientstore/store.go
new file mode 100644
index 00000000..7a91bcb5
--- /dev/null
+++ b/extensions/transientstore/store.go
@@ -0,0 +1,17 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package transientstore
+
+import (
+	"github.com/hyperledger/fabric/core/transientstore"
+	ts "github.com/trustbloc/fabric-peer-ext/pkg/transientstore"
+)
+
+// NewStoreProvider return new store provider
+func NewStoreProvider() transientstore.StoreProvider {
+	return ts.NewStoreProvider()
+}
diff --git a/extensions/transientstore/store_test.go b/extensions/transientstore/store_test.go
new file mode 100644
index 00000000..be4683fc
--- /dev/null
+++ b/extensions/transientstore/store_test.go
@@ -0,0 +1,17 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package transientstore
+
+import (
+	"testing"
+
+	"github.com/stretchr/testify/require"
+)
+
+func TestNewStoreProvider(t *testing.T) {
+	require.Empty(t, NewStoreProvider())
+}
diff --git a/vendor/github.com/bluele/gcache/LICENSE b/vendor/github.com/bluele/gcache/LICENSE
new file mode 100644
index 00000000..d1e7b03e
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/LICENSE
@@ -0,0 +1,21 @@
+The MIT License (MIT)
+
+Copyright (c) 2017 Jun Kimura
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in
+all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+THE SOFTWARE.
diff --git a/vendor/github.com/bluele/gcache/arc.go b/vendor/github.com/bluele/gcache/arc.go
new file mode 100644
index 00000000..5215dca9
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/arc.go
@@ -0,0 +1,452 @@
+package gcache
+
+import (
+	"container/list"
+	"time"
+)
+
+// Constantly balances between LRU and LFU, to improve the combined result.
+type ARC struct {
+	baseCache
+	items map[interface{}]*arcItem
+
+	part int
+	t1   *arcList
+	t2   *arcList
+	b1   *arcList
+	b2   *arcList
+}
+
+func newARC(cb *CacheBuilder) *ARC {
+	c := &ARC{}
+	buildCache(&c.baseCache, cb)
+
+	c.init()
+	c.loadGroup.cache = c
+	return c
+}
+
+func (c *ARC) init() {
+	c.items = make(map[interface{}]*arcItem)
+	c.t1 = newARCList()
+	c.t2 = newARCList()
+	c.b1 = newARCList()
+	c.b2 = newARCList()
+}
+
+func (c *ARC) replace(key interface{}) {
+	if !c.isCacheFull() {
+		return
+	}
+	var old interface{}
+	if c.t1.Len() > 0 && ((c.b2.Has(key) && c.t1.Len() == c.part) || (c.t1.Len() > c.part)) {
+		old = c.t1.RemoveTail()
+		c.b1.PushFront(old)
+	} else if c.t2.Len() > 0 {
+		old = c.t2.RemoveTail()
+		c.b2.PushFront(old)
+	} else {
+		old = c.t1.RemoveTail()
+		c.b1.PushFront(old)
+	}
+	item, ok := c.items[old]
+	if ok {
+		delete(c.items, old)
+		if c.evictedFunc != nil {
+			c.evictedFunc(item.key, item.value)
+		}
+	}
+}
+
+func (c *ARC) Set(key, value interface{}) error {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	_, err := c.set(key, value)
+	return err
+}
+
+// Set a new key-value pair with an expiration time
+func (c *ARC) SetWithExpire(key, value interface{}, expiration time.Duration) error {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	item, err := c.set(key, value)
+	if err != nil {
+		return err
+	}
+
+	t := c.clock.Now().Add(expiration)
+	item.(*arcItem).expiration = &t
+	return nil
+}
+
+func (c *ARC) set(key, value interface{}) (interface{}, error) {
+	var err error
+	if c.serializeFunc != nil {
+		value, err = c.serializeFunc(key, value)
+		if err != nil {
+			return nil, err
+		}
+	}
+
+	item, ok := c.items[key]
+	if ok {
+		item.value = value
+	} else {
+		item = &arcItem{
+			clock: c.clock,
+			key:   key,
+			value: value,
+		}
+		c.items[key] = item
+	}
+
+	if c.expiration != nil {
+		t := c.clock.Now().Add(*c.expiration)
+		item.expiration = &t
+	}
+
+	defer func() {
+		if c.addedFunc != nil {
+			c.addedFunc(key, value)
+		}
+	}()
+
+	if c.t1.Has(key) || c.t2.Has(key) {
+		return item, nil
+	}
+
+	if elt := c.b1.Lookup(key); elt != nil {
+		c.setPart(minInt(c.size, c.part+maxInt(c.b2.Len()/c.b1.Len(), 1)))
+		c.replace(key)
+		c.b1.Remove(key, elt)
+		c.t2.PushFront(key)
+		return item, nil
+	}
+
+	if elt := c.b2.Lookup(key); elt != nil {
+		c.setPart(maxInt(0, c.part-maxInt(c.b1.Len()/c.b2.Len(), 1)))
+		c.replace(key)
+		c.b2.Remove(key, elt)
+		c.t2.PushFront(key)
+		return item, nil
+	}
+
+	if c.isCacheFull() && c.t1.Len()+c.b1.Len() == c.size {
+		if c.t1.Len() < c.size {
+			c.b1.RemoveTail()
+			c.replace(key)
+		} else {
+			pop := c.t1.RemoveTail()
+			item, ok := c.items[pop]
+			if ok {
+				delete(c.items, pop)
+				if c.evictedFunc != nil {
+					c.evictedFunc(item.key, item.value)
+				}
+			}
+		}
+	} else {
+		total := c.t1.Len() + c.b1.Len() + c.t2.Len() + c.b2.Len()
+		if total >= c.size {
+			if total == (2 * c.size) {
+				if c.b2.Len() > 0 {
+					c.b2.RemoveTail()
+				} else {
+					c.b1.RemoveTail()
+				}
+			}
+			c.replace(key)
+		}
+	}
+	c.t1.PushFront(key)
+	return item, nil
+}
+
+// Get a value from cache pool using key if it exists. If not exists and it has LoaderFunc, it will generate the value using you have specified LoaderFunc method returns value.
+func (c *ARC) Get(key interface{}) (interface{}, error) {
+	v, err := c.get(key, false)
+	if err == KeyNotFoundError {
+		return c.getWithLoader(key, true)
+	}
+	return v, err
+}
+
+// GetIFPresent gets a value from cache pool using key if it exists.
+// If it dose not exists key, returns KeyNotFoundError.
+// And send a request which refresh value for specified key if cache object has LoaderFunc.
+func (c *ARC) GetIFPresent(key interface{}) (interface{}, error) {
+	v, err := c.get(key, false)
+	if err == KeyNotFoundError {
+		return c.getWithLoader(key, false)
+	}
+	return v, err
+}
+
+func (c *ARC) get(key interface{}, onLoad bool) (interface{}, error) {
+	v, err := c.getValue(key, onLoad)
+	if err != nil {
+		return nil, err
+	}
+	if c.deserializeFunc != nil {
+		return c.deserializeFunc(key, v)
+	}
+	return v, nil
+}
+
+func (c *ARC) getValue(key interface{}, onLoad bool) (interface{}, error) {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	if elt := c.t1.Lookup(key); elt != nil {
+		c.t1.Remove(key, elt)
+		item := c.items[key]
+		if !item.IsExpired(nil) {
+			c.t2.PushFront(key)
+			if !onLoad {
+				c.stats.IncrHitCount()
+			}
+			return item.value, nil
+		} else {
+			delete(c.items, key)
+			c.b1.PushFront(key)
+			if c.evictedFunc != nil {
+				c.evictedFunc(item.key, item.value)
+			}
+		}
+	}
+	if elt := c.t2.Lookup(key); elt != nil {
+		item := c.items[key]
+		if !item.IsExpired(nil) {
+			c.t2.MoveToFront(elt)
+			if !onLoad {
+				c.stats.IncrHitCount()
+			}
+			return item.value, nil
+		} else {
+			delete(c.items, key)
+			c.t2.Remove(key, elt)
+			c.b2.PushFront(key)
+			if c.evictedFunc != nil {
+				c.evictedFunc(item.key, item.value)
+			}
+		}
+	}
+
+	if !onLoad {
+		c.stats.IncrMissCount()
+	}
+	return nil, KeyNotFoundError
+}
+
+func (c *ARC) getWithLoader(key interface{}, isWait bool) (interface{}, error) {
+	if c.loaderExpireFunc == nil {
+		return nil, KeyNotFoundError
+	}
+	value, _, err := c.load(key, func(v interface{}, expiration *time.Duration, e error) (interface{}, error) {
+		if e != nil {
+			return nil, e
+		}
+		c.mu.Lock()
+		defer c.mu.Unlock()
+		item, err := c.set(key, v)
+		if err != nil {
+			return nil, err
+		}
+		if expiration != nil {
+			t := c.clock.Now().Add(*expiration)
+			item.(*arcItem).expiration = &t
+		}
+		return v, nil
+	}, isWait)
+	if err != nil {
+		return nil, err
+	}
+	return value, nil
+}
+
+// Has checks if key exists in cache
+func (c *ARC) Has(key interface{}) bool {
+	c.mu.RLock()
+	defer c.mu.RUnlock()
+	now := time.Now()
+	return c.has(key, &now)
+}
+
+func (c *ARC) has(key interface{}, now *time.Time) bool {
+	item, ok := c.items[key]
+	if !ok {
+		return false
+	}
+	return !item.IsExpired(now)
+}
+
+// Remove removes the provided key from the cache.
+func (c *ARC) Remove(key interface{}) bool {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+
+	return c.remove(key)
+}
+
+func (c *ARC) remove(key interface{}) bool {
+	if elt := c.t1.Lookup(key); elt != nil {
+		c.t1.Remove(key, elt)
+		item := c.items[key]
+		delete(c.items, key)
+		c.b1.PushFront(key)
+		if c.evictedFunc != nil {
+			c.evictedFunc(key, item.value)
+		}
+		return true
+	}
+
+	if elt := c.t2.Lookup(key); elt != nil {
+		c.t2.Remove(key, elt)
+		item := c.items[key]
+		delete(c.items, key)
+		c.b2.PushFront(key)
+		if c.evictedFunc != nil {
+			c.evictedFunc(key, item.value)
+		}
+		return true
+	}
+
+	return false
+}
+
+func (c *ARC) keys() []interface{} {
+	c.mu.RLock()
+	defer c.mu.RUnlock()
+	keys := make([]interface{}, len(c.items))
+	var i = 0
+	for k := range c.items {
+		keys[i] = k
+		i++
+	}
+	return keys
+}
+
+// Keys returns a slice of the keys in the cache.
+func (c *ARC) Keys() []interface{} {
+	keys := []interface{}{}
+	for _, k := range c.keys() {
+		_, err := c.GetIFPresent(k)
+		if err == nil {
+			keys = append(keys, k)
+		}
+	}
+	return keys
+}
+
+// GetALL returns all key-value pairs in the cache.
+func (c *ARC) GetALL() map[interface{}]interface{} {
+	m := make(map[interface{}]interface{})
+	for _, k := range c.keys() {
+		v, err := c.GetIFPresent(k)
+		if err == nil {
+			m[k] = v
+		}
+	}
+	return m
+}
+
+// Len returns the number of items in the cache.
+func (c *ARC) Len() int {
+	return len(c.GetALL())
+}
+
+// Purge is used to completely clear the cache
+func (c *ARC) Purge() {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+
+	if c.purgeVisitorFunc != nil {
+		for _, item := range c.items {
+			c.purgeVisitorFunc(item.key, item.value)
+		}
+	}
+
+	c.init()
+}
+
+func (c *ARC) setPart(p int) {
+	if c.isCacheFull() {
+		c.part = p
+	}
+}
+
+func (c *ARC) isCacheFull() bool {
+	return (c.t1.Len() + c.t2.Len()) == c.size
+}
+
+// IsExpired returns boolean value whether this item is expired or not.
+func (it *arcItem) IsExpired(now *time.Time) bool {
+	if it.expiration == nil {
+		return false
+	}
+	if now == nil {
+		t := it.clock.Now()
+		now = &t
+	}
+	return it.expiration.Before(*now)
+}
+
+type arcList struct {
+	l    *list.List
+	keys map[interface{}]*list.Element
+}
+
+type arcItem struct {
+	clock      Clock
+	key        interface{}
+	value      interface{}
+	expiration *time.Time
+}
+
+func newARCList() *arcList {
+	return &arcList{
+		l:    list.New(),
+		keys: make(map[interface{}]*list.Element),
+	}
+}
+
+func (al *arcList) Has(key interface{}) bool {
+	_, ok := al.keys[key]
+	return ok
+}
+
+func (al *arcList) Lookup(key interface{}) *list.Element {
+	elt := al.keys[key]
+	return elt
+}
+
+func (al *arcList) MoveToFront(elt *list.Element) {
+	al.l.MoveToFront(elt)
+}
+
+func (al *arcList) PushFront(key interface{}) {
+	if elt, ok := al.keys[key]; ok {
+		al.l.MoveToFront(elt)
+		return
+	}
+	elt := al.l.PushFront(key)
+	al.keys[key] = elt
+}
+
+func (al *arcList) Remove(key interface{}, elt *list.Element) {
+	delete(al.keys, key)
+	al.l.Remove(elt)
+}
+
+func (al *arcList) RemoveTail() interface{} {
+	elt := al.l.Back()
+	al.l.Remove(elt)
+
+	key := elt.Value
+	delete(al.keys, key)
+
+	return key
+}
+
+func (al *arcList) Len() int {
+	return al.l.Len()
+}
diff --git a/vendor/github.com/bluele/gcache/cache.go b/vendor/github.com/bluele/gcache/cache.go
new file mode 100644
index 00000000..0ac85572
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/cache.go
@@ -0,0 +1,205 @@
+package gcache
+
+import (
+	"errors"
+	"fmt"
+	"sync"
+	"time"
+)
+
+const (
+	TYPE_SIMPLE = "simple"
+	TYPE_LRU    = "lru"
+	TYPE_LFU    = "lfu"
+	TYPE_ARC    = "arc"
+)
+
+var KeyNotFoundError = errors.New("Key not found.")
+
+type Cache interface {
+	Set(interface{}, interface{}) error
+	SetWithExpire(interface{}, interface{}, time.Duration) error
+	Get(interface{}) (interface{}, error)
+	GetIFPresent(interface{}) (interface{}, error)
+	GetALL() map[interface{}]interface{}
+	Has(interface{}) bool
+	get(interface{}, bool) (interface{}, error)
+	Remove(interface{}) bool
+	Purge()
+	Keys() []interface{}
+	Len() int
+
+	statsAccessor
+}
+
+type baseCache struct {
+	clock            Clock
+	size             int
+	loaderExpireFunc LoaderExpireFunc
+	evictedFunc      EvictedFunc
+	purgeVisitorFunc PurgeVisitorFunc
+	addedFunc        AddedFunc
+	deserializeFunc  DeserializeFunc
+	serializeFunc    SerializeFunc
+	expiration       *time.Duration
+	mu               sync.RWMutex
+	loadGroup        Group
+	*stats
+}
+
+type (
+	LoaderFunc       func(interface{}) (interface{}, error)
+	LoaderExpireFunc func(interface{}) (interface{}, *time.Duration, error)
+	EvictedFunc      func(interface{}, interface{})
+	PurgeVisitorFunc func(interface{}, interface{})
+	AddedFunc        func(interface{}, interface{})
+	DeserializeFunc  func(interface{}, interface{}) (interface{}, error)
+	SerializeFunc    func(interface{}, interface{}) (interface{}, error)
+)
+
+type CacheBuilder struct {
+	clock            Clock
+	tp               string
+	size             int
+	loaderExpireFunc LoaderExpireFunc
+	evictedFunc      EvictedFunc
+	purgeVisitorFunc PurgeVisitorFunc
+	addedFunc        AddedFunc
+	expiration       *time.Duration
+	deserializeFunc  DeserializeFunc
+	serializeFunc    SerializeFunc
+}
+
+func New(size int) *CacheBuilder {
+	return &CacheBuilder{
+		clock: NewRealClock(),
+		tp:    TYPE_SIMPLE,
+		size:  size,
+	}
+}
+
+func (cb *CacheBuilder) Clock(clock Clock) *CacheBuilder {
+	cb.clock = clock
+	return cb
+}
+
+// Set a loader function.
+// loaderFunc: create a new value with this function if cached value is expired.
+func (cb *CacheBuilder) LoaderFunc(loaderFunc LoaderFunc) *CacheBuilder {
+	cb.loaderExpireFunc = func(k interface{}) (interface{}, *time.Duration, error) {
+		v, err := loaderFunc(k)
+		return v, nil, err
+	}
+	return cb
+}
+
+// Set a loader function with expiration.
+// loaderExpireFunc: create a new value with this function if cached value is expired.
+// If nil returned instead of time.Duration from loaderExpireFunc than value will never expire.
+func (cb *CacheBuilder) LoaderExpireFunc(loaderExpireFunc LoaderExpireFunc) *CacheBuilder {
+	cb.loaderExpireFunc = loaderExpireFunc
+	return cb
+}
+
+func (cb *CacheBuilder) EvictType(tp string) *CacheBuilder {
+	cb.tp = tp
+	return cb
+}
+
+func (cb *CacheBuilder) Simple() *CacheBuilder {
+	return cb.EvictType(TYPE_SIMPLE)
+}
+
+func (cb *CacheBuilder) LRU() *CacheBuilder {
+	return cb.EvictType(TYPE_LRU)
+}
+
+func (cb *CacheBuilder) LFU() *CacheBuilder {
+	return cb.EvictType(TYPE_LFU)
+}
+
+func (cb *CacheBuilder) ARC() *CacheBuilder {
+	return cb.EvictType(TYPE_ARC)
+}
+
+func (cb *CacheBuilder) EvictedFunc(evictedFunc EvictedFunc) *CacheBuilder {
+	cb.evictedFunc = evictedFunc
+	return cb
+}
+
+func (cb *CacheBuilder) PurgeVisitorFunc(purgeVisitorFunc PurgeVisitorFunc) *CacheBuilder {
+	cb.purgeVisitorFunc = purgeVisitorFunc
+	return cb
+}
+
+func (cb *CacheBuilder) AddedFunc(addedFunc AddedFunc) *CacheBuilder {
+	cb.addedFunc = addedFunc
+	return cb
+}
+
+func (cb *CacheBuilder) DeserializeFunc(deserializeFunc DeserializeFunc) *CacheBuilder {
+	cb.deserializeFunc = deserializeFunc
+	return cb
+}
+
+func (cb *CacheBuilder) SerializeFunc(serializeFunc SerializeFunc) *CacheBuilder {
+	cb.serializeFunc = serializeFunc
+	return cb
+}
+
+func (cb *CacheBuilder) Expiration(expiration time.Duration) *CacheBuilder {
+	cb.expiration = &expiration
+	return cb
+}
+
+func (cb *CacheBuilder) Build() Cache {
+	if cb.size <= 0 && cb.tp != TYPE_SIMPLE {
+		panic("gcache: Cache size <= 0")
+	}
+
+	return cb.build()
+}
+
+func (cb *CacheBuilder) build() Cache {
+	switch cb.tp {
+	case TYPE_SIMPLE:
+		return newSimpleCache(cb)
+	case TYPE_LRU:
+		return newLRUCache(cb)
+	case TYPE_LFU:
+		return newLFUCache(cb)
+	case TYPE_ARC:
+		return newARC(cb)
+	default:
+		panic("gcache: Unknown type " + cb.tp)
+	}
+}
+
+func buildCache(c *baseCache, cb *CacheBuilder) {
+	c.clock = cb.clock
+	c.size = cb.size
+	c.loaderExpireFunc = cb.loaderExpireFunc
+	c.expiration = cb.expiration
+	c.addedFunc = cb.addedFunc
+	c.deserializeFunc = cb.deserializeFunc
+	c.serializeFunc = cb.serializeFunc
+	c.evictedFunc = cb.evictedFunc
+	c.purgeVisitorFunc = cb.purgeVisitorFunc
+	c.stats = &stats{}
+}
+
+// load a new value using by specified key.
+func (c *baseCache) load(key interface{}, cb func(interface{}, *time.Duration, error) (interface{}, error), isWait bool) (interface{}, bool, error) {
+	v, called, err := c.loadGroup.Do(key, func() (v interface{}, e error) {
+		defer func() {
+			if r := recover(); r != nil {
+				e = fmt.Errorf("Loader panics: %v", r)
+			}
+		}()
+		return cb(c.loaderExpireFunc(key))
+	}, isWait)
+	if err != nil {
+		return nil, called, err
+	}
+	return v, called, nil
+}
diff --git a/vendor/github.com/bluele/gcache/clock.go b/vendor/github.com/bluele/gcache/clock.go
new file mode 100644
index 00000000..3acc3f0d
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/clock.go
@@ -0,0 +1,53 @@
+package gcache
+
+import (
+	"sync"
+	"time"
+)
+
+type Clock interface {
+	Now() time.Time
+}
+
+type RealClock struct{}
+
+func NewRealClock() Clock {
+	return RealClock{}
+}
+
+func (rc RealClock) Now() time.Time {
+	t := time.Now()
+	return t
+}
+
+type FakeClock interface {
+	Clock
+
+	Advance(d time.Duration)
+}
+
+func NewFakeClock() FakeClock {
+	return &fakeclock{
+		// Taken from github.com/jonboulle/clockwork: use a fixture that does not fulfill Time.IsZero()
+		now: time.Date(1984, time.April, 4, 0, 0, 0, 0, time.UTC),
+	}
+}
+
+type fakeclock struct {
+	now time.Time
+
+	mutex sync.RWMutex
+}
+
+func (fc *fakeclock) Now() time.Time {
+	fc.mutex.RLock()
+	defer fc.mutex.RUnlock()
+	t := fc.now
+	return t
+}
+
+func (fc *fakeclock) Advance(d time.Duration) {
+	fc.mutex.Lock()
+	defer fc.mutex.Unlock()
+	fc.now = fc.now.Add(d)
+}
diff --git a/vendor/github.com/bluele/gcache/lfu.go b/vendor/github.com/bluele/gcache/lfu.go
new file mode 100644
index 00000000..915ac8cc
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/lfu.go
@@ -0,0 +1,335 @@
+package gcache
+
+import (
+	"container/list"
+	"time"
+)
+
+// Discards the least frequently used items first.
+type LFUCache struct {
+	baseCache
+	items    map[interface{}]*lfuItem
+	freqList *list.List // list for freqEntry
+}
+
+func newLFUCache(cb *CacheBuilder) *LFUCache {
+	c := &LFUCache{}
+	buildCache(&c.baseCache, cb)
+
+	c.init()
+	c.loadGroup.cache = c
+	return c
+}
+
+func (c *LFUCache) init() {
+	c.freqList = list.New()
+	c.items = make(map[interface{}]*lfuItem, c.size+1)
+	c.freqList.PushFront(&freqEntry{
+		freq:  0,
+		items: make(map[*lfuItem]struct{}),
+	})
+}
+
+// Set a new key-value pair
+func (c *LFUCache) Set(key, value interface{}) error {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	_, err := c.set(key, value)
+	return err
+}
+
+// Set a new key-value pair with an expiration time
+func (c *LFUCache) SetWithExpire(key, value interface{}, expiration time.Duration) error {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	item, err := c.set(key, value)
+	if err != nil {
+		return err
+	}
+
+	t := c.clock.Now().Add(expiration)
+	item.(*lfuItem).expiration = &t
+	return nil
+}
+
+func (c *LFUCache) set(key, value interface{}) (interface{}, error) {
+	var err error
+	if c.serializeFunc != nil {
+		value, err = c.serializeFunc(key, value)
+		if err != nil {
+			return nil, err
+		}
+	}
+
+	// Check for existing item
+	item, ok := c.items[key]
+	if ok {
+		item.value = value
+	} else {
+		// Verify size not exceeded
+		if len(c.items) >= c.size {
+			c.evict(1)
+		}
+		item = &lfuItem{
+			clock:       c.clock,
+			key:         key,
+			value:       value,
+			freqElement: nil,
+		}
+		el := c.freqList.Front()
+		fe := el.Value.(*freqEntry)
+		fe.items[item] = struct{}{}
+
+		item.freqElement = el
+		c.items[key] = item
+	}
+
+	if c.expiration != nil {
+		t := c.clock.Now().Add(*c.expiration)
+		item.expiration = &t
+	}
+
+	if c.addedFunc != nil {
+		c.addedFunc(key, value)
+	}
+
+	return item, nil
+}
+
+// Get a value from cache pool using key if it exists.
+// If it dose not exists key and has LoaderFunc,
+// generate a value using `LoaderFunc` method returns value.
+func (c *LFUCache) Get(key interface{}) (interface{}, error) {
+	v, err := c.get(key, false)
+	if err == KeyNotFoundError {
+		return c.getWithLoader(key, true)
+	}
+	return v, err
+}
+
+// GetIFPresent gets a value from cache pool using key if it exists.
+// If it dose not exists key, returns KeyNotFoundError.
+// And send a request which refresh value for specified key if cache object has LoaderFunc.
+func (c *LFUCache) GetIFPresent(key interface{}) (interface{}, error) {
+	v, err := c.get(key, false)
+	if err == KeyNotFoundError {
+		return c.getWithLoader(key, false)
+	}
+	return v, err
+}
+
+func (c *LFUCache) get(key interface{}, onLoad bool) (interface{}, error) {
+	v, err := c.getValue(key, onLoad)
+	if err != nil {
+		return nil, err
+	}
+	if c.deserializeFunc != nil {
+		return c.deserializeFunc(key, v)
+	}
+	return v, nil
+}
+
+func (c *LFUCache) getValue(key interface{}, onLoad bool) (interface{}, error) {
+	c.mu.Lock()
+	item, ok := c.items[key]
+	if ok {
+		if !item.IsExpired(nil) {
+			c.increment(item)
+			v := item.value
+			c.mu.Unlock()
+			if !onLoad {
+				c.stats.IncrHitCount()
+			}
+			return v, nil
+		}
+		c.removeItem(item)
+	}
+	c.mu.Unlock()
+	if !onLoad {
+		c.stats.IncrMissCount()
+	}
+	return nil, KeyNotFoundError
+}
+
+func (c *LFUCache) getWithLoader(key interface{}, isWait bool) (interface{}, error) {
+	if c.loaderExpireFunc == nil {
+		return nil, KeyNotFoundError
+	}
+	value, _, err := c.load(key, func(v interface{}, expiration *time.Duration, e error) (interface{}, error) {
+		if e != nil {
+			return nil, e
+		}
+		c.mu.Lock()
+		defer c.mu.Unlock()
+		item, err := c.set(key, v)
+		if err != nil {
+			return nil, err
+		}
+		if expiration != nil {
+			t := c.clock.Now().Add(*expiration)
+			item.(*lfuItem).expiration = &t
+		}
+		return v, nil
+	}, isWait)
+	if err != nil {
+		return nil, err
+	}
+	return value, nil
+}
+
+func (c *LFUCache) increment(item *lfuItem) {
+	currentFreqElement := item.freqElement
+	currentFreqEntry := currentFreqElement.Value.(*freqEntry)
+	nextFreq := currentFreqEntry.freq + 1
+	delete(currentFreqEntry.items, item)
+
+	nextFreqElement := currentFreqElement.Next()
+	if nextFreqElement == nil {
+		nextFreqElement = c.freqList.InsertAfter(&freqEntry{
+			freq:  nextFreq,
+			items: make(map[*lfuItem]struct{}),
+		}, currentFreqElement)
+	}
+	nextFreqElement.Value.(*freqEntry).items[item] = struct{}{}
+	item.freqElement = nextFreqElement
+}
+
+// evict removes the least frequence item from the cache.
+func (c *LFUCache) evict(count int) {
+	entry := c.freqList.Front()
+	for i := 0; i < count; {
+		if entry == nil {
+			return
+		} else {
+			for item, _ := range entry.Value.(*freqEntry).items {
+				if i >= count {
+					return
+				}
+				c.removeItem(item)
+				i++
+			}
+			entry = entry.Next()
+		}
+	}
+}
+
+// Has checks if key exists in cache
+func (c *LFUCache) Has(key interface{}) bool {
+	c.mu.RLock()
+	defer c.mu.RUnlock()
+	now := time.Now()
+	return c.has(key, &now)
+}
+
+func (c *LFUCache) has(key interface{}, now *time.Time) bool {
+	item, ok := c.items[key]
+	if !ok {
+		return false
+	}
+	return !item.IsExpired(now)
+}
+
+// Remove removes the provided key from the cache.
+func (c *LFUCache) Remove(key interface{}) bool {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+
+	return c.remove(key)
+}
+
+func (c *LFUCache) remove(key interface{}) bool {
+	if item, ok := c.items[key]; ok {
+		c.removeItem(item)
+		return true
+	}
+	return false
+}
+
+// removeElement is used to remove a given list element from the cache
+func (c *LFUCache) removeItem(item *lfuItem) {
+	delete(c.items, item.key)
+	delete(item.freqElement.Value.(*freqEntry).items, item)
+	if c.evictedFunc != nil {
+		c.evictedFunc(item.key, item.value)
+	}
+}
+
+func (c *LFUCache) keys() []interface{} {
+	c.mu.RLock()
+	defer c.mu.RUnlock()
+	keys := make([]interface{}, len(c.items))
+	var i = 0
+	for k := range c.items {
+		keys[i] = k
+		i++
+	}
+	return keys
+}
+
+// Keys returns a slice of the keys in the cache.
+func (c *LFUCache) Keys() []interface{} {
+	keys := []interface{}{}
+	for _, k := range c.keys() {
+		_, err := c.GetIFPresent(k)
+		if err == nil {
+			keys = append(keys, k)
+		}
+	}
+	return keys
+}
+
+// GetALL returns all key-value pairs in the cache.
+func (c *LFUCache) GetALL() map[interface{}]interface{} {
+	m := make(map[interface{}]interface{})
+	for _, k := range c.keys() {
+		v, err := c.GetIFPresent(k)
+		if err == nil {
+			m[k] = v
+		}
+	}
+	return m
+}
+
+// Len returns the number of items in the cache.
+func (c *LFUCache) Len() int {
+	return len(c.GetALL())
+}
+
+// Completely clear the cache
+func (c *LFUCache) Purge() {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+
+	if c.purgeVisitorFunc != nil {
+		for key, item := range c.items {
+			c.purgeVisitorFunc(key, item.value)
+		}
+	}
+
+	c.init()
+}
+
+type freqEntry struct {
+	freq  uint
+	items map[*lfuItem]struct{}
+}
+
+type lfuItem struct {
+	clock       Clock
+	key         interface{}
+	value       interface{}
+	freqElement *list.Element
+	expiration  *time.Time
+}
+
+// IsExpired returns boolean value whether this item is expired or not.
+func (it *lfuItem) IsExpired(now *time.Time) bool {
+	if it.expiration == nil {
+		return false
+	}
+	if now == nil {
+		t := it.clock.Now()
+		now = &t
+	}
+	return it.expiration.Before(*now)
+}
diff --git a/vendor/github.com/bluele/gcache/lru.go b/vendor/github.com/bluele/gcache/lru.go
new file mode 100644
index 00000000..10061b08
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/lru.go
@@ -0,0 +1,301 @@
+package gcache
+
+import (
+	"container/list"
+	"time"
+)
+
+// Discards the least recently used items first.
+type LRUCache struct {
+	baseCache
+	items     map[interface{}]*list.Element
+	evictList *list.List
+}
+
+func newLRUCache(cb *CacheBuilder) *LRUCache {
+	c := &LRUCache{}
+	buildCache(&c.baseCache, cb)
+
+	c.init()
+	c.loadGroup.cache = c
+	return c
+}
+
+func (c *LRUCache) init() {
+	c.evictList = list.New()
+	c.items = make(map[interface{}]*list.Element, c.size+1)
+}
+
+func (c *LRUCache) set(key, value interface{}) (interface{}, error) {
+	var err error
+	if c.serializeFunc != nil {
+		value, err = c.serializeFunc(key, value)
+		if err != nil {
+			return nil, err
+		}
+	}
+
+	// Check for existing item
+	var item *lruItem
+	if it, ok := c.items[key]; ok {
+		c.evictList.MoveToFront(it)
+		item = it.Value.(*lruItem)
+		item.value = value
+	} else {
+		// Verify size not exceeded
+		if c.evictList.Len() >= c.size {
+			c.evict(1)
+		}
+		item = &lruItem{
+			clock: c.clock,
+			key:   key,
+			value: value,
+		}
+		c.items[key] = c.evictList.PushFront(item)
+	}
+
+	if c.expiration != nil {
+		t := c.clock.Now().Add(*c.expiration)
+		item.expiration = &t
+	}
+
+	if c.addedFunc != nil {
+		c.addedFunc(key, value)
+	}
+
+	return item, nil
+}
+
+// set a new key-value pair
+func (c *LRUCache) Set(key, value interface{}) error {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	_, err := c.set(key, value)
+	return err
+}
+
+// Set a new key-value pair with an expiration time
+func (c *LRUCache) SetWithExpire(key, value interface{}, expiration time.Duration) error {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	item, err := c.set(key, value)
+	if err != nil {
+		return err
+	}
+
+	t := c.clock.Now().Add(expiration)
+	item.(*lruItem).expiration = &t
+	return nil
+}
+
+// Get a value from cache pool using key if it exists.
+// If it dose not exists key and has LoaderFunc,
+// generate a value using `LoaderFunc` method returns value.
+func (c *LRUCache) Get(key interface{}) (interface{}, error) {
+	v, err := c.get(key, false)
+	if err == KeyNotFoundError {
+		return c.getWithLoader(key, true)
+	}
+	return v, err
+}
+
+// GetIFPresent gets a value from cache pool using key if it exists.
+// If it dose not exists key, returns KeyNotFoundError.
+// And send a request which refresh value for specified key if cache object has LoaderFunc.
+func (c *LRUCache) GetIFPresent(key interface{}) (interface{}, error) {
+	v, err := c.get(key, false)
+	if err == KeyNotFoundError {
+		return c.getWithLoader(key, false)
+	}
+	return v, err
+}
+
+func (c *LRUCache) get(key interface{}, onLoad bool) (interface{}, error) {
+	v, err := c.getValue(key, onLoad)
+	if err != nil {
+		return nil, err
+	}
+	if c.deserializeFunc != nil {
+		return c.deserializeFunc(key, v)
+	}
+	return v, nil
+}
+
+func (c *LRUCache) getValue(key interface{}, onLoad bool) (interface{}, error) {
+	c.mu.Lock()
+	item, ok := c.items[key]
+	if ok {
+		it := item.Value.(*lruItem)
+		if !it.IsExpired(nil) {
+			c.evictList.MoveToFront(item)
+			v := it.value
+			c.mu.Unlock()
+			if !onLoad {
+				c.stats.IncrHitCount()
+			}
+			return v, nil
+		}
+		c.removeElement(item)
+	}
+	c.mu.Unlock()
+	if !onLoad {
+		c.stats.IncrMissCount()
+	}
+	return nil, KeyNotFoundError
+}
+
+func (c *LRUCache) getWithLoader(key interface{}, isWait bool) (interface{}, error) {
+	if c.loaderExpireFunc == nil {
+		return nil, KeyNotFoundError
+	}
+	value, _, err := c.load(key, func(v interface{}, expiration *time.Duration, e error) (interface{}, error) {
+		if e != nil {
+			return nil, e
+		}
+		c.mu.Lock()
+		defer c.mu.Unlock()
+		item, err := c.set(key, v)
+		if err != nil {
+			return nil, err
+		}
+		if expiration != nil {
+			t := c.clock.Now().Add(*expiration)
+			item.(*lruItem).expiration = &t
+		}
+		return v, nil
+	}, isWait)
+	if err != nil {
+		return nil, err
+	}
+	return value, nil
+}
+
+// evict removes the oldest item from the cache.
+func (c *LRUCache) evict(count int) {
+	for i := 0; i < count; i++ {
+		ent := c.evictList.Back()
+		if ent == nil {
+			return
+		} else {
+			c.removeElement(ent)
+		}
+	}
+}
+
+// Has checks if key exists in cache
+func (c *LRUCache) Has(key interface{}) bool {
+	c.mu.RLock()
+	defer c.mu.RUnlock()
+	now := time.Now()
+	return c.has(key, &now)
+}
+
+func (c *LRUCache) has(key interface{}, now *time.Time) bool {
+	item, ok := c.items[key]
+	if !ok {
+		return false
+	}
+	return !item.Value.(*lruItem).IsExpired(now)
+}
+
+// Remove removes the provided key from the cache.
+func (c *LRUCache) Remove(key interface{}) bool {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+
+	return c.remove(key)
+}
+
+func (c *LRUCache) remove(key interface{}) bool {
+	if ent, ok := c.items[key]; ok {
+		c.removeElement(ent)
+		return true
+	}
+	return false
+}
+
+func (c *LRUCache) removeElement(e *list.Element) {
+	c.evictList.Remove(e)
+	entry := e.Value.(*lruItem)
+	delete(c.items, entry.key)
+	if c.evictedFunc != nil {
+		entry := e.Value.(*lruItem)
+		c.evictedFunc(entry.key, entry.value)
+	}
+}
+
+func (c *LRUCache) keys() []interface{} {
+	c.mu.RLock()
+	defer c.mu.RUnlock()
+	keys := make([]interface{}, len(c.items))
+	var i = 0
+	for k := range c.items {
+		keys[i] = k
+		i++
+	}
+	return keys
+}
+
+// Keys returns a slice of the keys in the cache.
+func (c *LRUCache) Keys() []interface{} {
+	keys := []interface{}{}
+	for _, k := range c.keys() {
+		_, err := c.GetIFPresent(k)
+		if err == nil {
+			keys = append(keys, k)
+		}
+	}
+	return keys
+}
+
+// GetALL returns all key-value pairs in the cache.
+func (c *LRUCache) GetALL() map[interface{}]interface{} {
+	m := make(map[interface{}]interface{})
+	for _, k := range c.keys() {
+		v, err := c.GetIFPresent(k)
+		if err == nil {
+			m[k] = v
+		}
+	}
+	return m
+}
+
+// Len returns the number of items in the cache.
+func (c *LRUCache) Len() int {
+	return len(c.GetALL())
+}
+
+// Completely clear the cache
+func (c *LRUCache) Purge() {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+
+	if c.purgeVisitorFunc != nil {
+		for key, item := range c.items {
+			it := item.Value.(*lruItem)
+			v := it.value
+			c.purgeVisitorFunc(key, v)
+		}
+	}
+
+	c.init()
+}
+
+type lruItem struct {
+	clock      Clock
+	key        interface{}
+	value      interface{}
+	expiration *time.Time
+}
+
+// IsExpired returns boolean value whether this item is expired or not.
+func (it *lruItem) IsExpired(now *time.Time) bool {
+	if it.expiration == nil {
+		return false
+	}
+	if now == nil {
+		t := it.clock.Now()
+		now = &t
+	}
+	return it.expiration.Before(*now)
+}
diff --git a/vendor/github.com/bluele/gcache/simple.go b/vendor/github.com/bluele/gcache/simple.go
new file mode 100644
index 00000000..befc0368
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/simple.go
@@ -0,0 +1,289 @@
+package gcache
+
+import "time"
+
+// SimpleCache has no clear priority for evict cache. It depends on key-value map order.
+type SimpleCache struct {
+	baseCache
+	items map[interface{}]*simpleItem
+}
+
+func newSimpleCache(cb *CacheBuilder) *SimpleCache {
+	c := &SimpleCache{}
+	buildCache(&c.baseCache, cb)
+
+	c.init()
+	c.loadGroup.cache = c
+	return c
+}
+
+func (c *SimpleCache) init() {
+	if c.size <= 0 {
+		c.items = make(map[interface{}]*simpleItem)
+	} else {
+		c.items = make(map[interface{}]*simpleItem, c.size)
+	}
+}
+
+// Set a new key-value pair
+func (c *SimpleCache) Set(key, value interface{}) error {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	_, err := c.set(key, value)
+	return err
+}
+
+// Set a new key-value pair with an expiration time
+func (c *SimpleCache) SetWithExpire(key, value interface{}, expiration time.Duration) error {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+	item, err := c.set(key, value)
+	if err != nil {
+		return err
+	}
+
+	t := c.clock.Now().Add(expiration)
+	item.(*simpleItem).expiration = &t
+	return nil
+}
+
+func (c *SimpleCache) set(key, value interface{}) (interface{}, error) {
+	var err error
+	if c.serializeFunc != nil {
+		value, err = c.serializeFunc(key, value)
+		if err != nil {
+			return nil, err
+		}
+	}
+
+	// Check for existing item
+	item, ok := c.items[key]
+	if ok {
+		item.value = value
+	} else {
+		// Verify size not exceeded
+		if (len(c.items) >= c.size) && c.size > 0 {
+			c.evict(1)
+		}
+		item = &simpleItem{
+			clock: c.clock,
+			value: value,
+		}
+		c.items[key] = item
+	}
+
+	if c.expiration != nil {
+		t := c.clock.Now().Add(*c.expiration)
+		item.expiration = &t
+	}
+
+	if c.addedFunc != nil {
+		c.addedFunc(key, value)
+	}
+
+	return item, nil
+}
+
+// Get a value from cache pool using key if it exists.
+// If it dose not exists key and has LoaderFunc,
+// generate a value using `LoaderFunc` method returns value.
+func (c *SimpleCache) Get(key interface{}) (interface{}, error) {
+	v, err := c.get(key, false)
+	if err == KeyNotFoundError {
+		return c.getWithLoader(key, true)
+	}
+	return v, err
+}
+
+// GetIFPresent gets a value from cache pool using key if it exists.
+// If it dose not exists key, returns KeyNotFoundError.
+// And send a request which refresh value for specified key if cache object has LoaderFunc.
+func (c *SimpleCache) GetIFPresent(key interface{}) (interface{}, error) {
+	v, err := c.get(key, false)
+	if err == KeyNotFoundError {
+		return c.getWithLoader(key, false)
+	}
+	return v, nil
+}
+
+func (c *SimpleCache) get(key interface{}, onLoad bool) (interface{}, error) {
+	v, err := c.getValue(key, onLoad)
+	if err != nil {
+		return nil, err
+	}
+	if c.deserializeFunc != nil {
+		return c.deserializeFunc(key, v)
+	}
+	return v, nil
+}
+
+func (c *SimpleCache) getValue(key interface{}, onLoad bool) (interface{}, error) {
+	c.mu.Lock()
+	item, ok := c.items[key]
+	if ok {
+		if !item.IsExpired(nil) {
+			v := item.value
+			c.mu.Unlock()
+			if !onLoad {
+				c.stats.IncrHitCount()
+			}
+			return v, nil
+		}
+		c.remove(key)
+	}
+	c.mu.Unlock()
+	if !onLoad {
+		c.stats.IncrMissCount()
+	}
+	return nil, KeyNotFoundError
+}
+
+func (c *SimpleCache) getWithLoader(key interface{}, isWait bool) (interface{}, error) {
+	if c.loaderExpireFunc == nil {
+		return nil, KeyNotFoundError
+	}
+	value, _, err := c.load(key, func(v interface{}, expiration *time.Duration, e error) (interface{}, error) {
+		if e != nil {
+			return nil, e
+		}
+		c.mu.Lock()
+		defer c.mu.Unlock()
+		item, err := c.set(key, v)
+		if err != nil {
+			return nil, err
+		}
+		if expiration != nil {
+			t := c.clock.Now().Add(*expiration)
+			item.(*simpleItem).expiration = &t
+		}
+		return v, nil
+	}, isWait)
+	if err != nil {
+		return nil, err
+	}
+	return value, nil
+}
+
+func (c *SimpleCache) evict(count int) {
+	now := c.clock.Now()
+	current := 0
+	for key, item := range c.items {
+		if current >= count {
+			return
+		}
+		if item.expiration == nil || now.After(*item.expiration) {
+			defer c.remove(key)
+			current++
+		}
+	}
+}
+
+// Has checks if key exists in cache
+func (c *SimpleCache) Has(key interface{}) bool {
+	c.mu.RLock()
+	defer c.mu.RUnlock()
+	now := time.Now()
+	return c.has(key, &now)
+}
+
+func (c *SimpleCache) has(key interface{}, now *time.Time) bool {
+	item, ok := c.items[key]
+	if !ok {
+		return false
+	}
+	return !item.IsExpired(now)
+}
+
+// Remove removes the provided key from the cache.
+func (c *SimpleCache) Remove(key interface{}) bool {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+
+	return c.remove(key)
+}
+
+func (c *SimpleCache) remove(key interface{}) bool {
+	item, ok := c.items[key]
+	if ok {
+		delete(c.items, key)
+		if c.evictedFunc != nil {
+			c.evictedFunc(key, item.value)
+		}
+		return true
+	}
+	return false
+}
+
+// Returns a slice of the keys in the cache.
+func (c *SimpleCache) keys() []interface{} {
+	c.mu.RLock()
+	defer c.mu.RUnlock()
+	keys := make([]interface{}, len(c.items))
+	var i = 0
+	for k := range c.items {
+		keys[i] = k
+		i++
+	}
+	return keys
+}
+
+// Keys returns a slice of the keys in the cache.
+func (c *SimpleCache) Keys() []interface{} {
+	keys := []interface{}{}
+	for _, k := range c.keys() {
+		_, err := c.GetIFPresent(k)
+		if err == nil {
+			keys = append(keys, k)
+		}
+	}
+	return keys
+}
+
+// GetALL returns all key-value pairs in the cache.
+func (c *SimpleCache) GetALL() map[interface{}]interface{} {
+	m := make(map[interface{}]interface{})
+	for _, k := range c.keys() {
+		v, err := c.GetIFPresent(k)
+		if err == nil {
+			m[k] = v
+		}
+	}
+	return m
+}
+
+// Len returns the number of items in the cache.
+func (c *SimpleCache) Len() int {
+	return len(c.GetALL())
+}
+
+// Completely clear the cache
+func (c *SimpleCache) Purge() {
+	c.mu.Lock()
+	defer c.mu.Unlock()
+
+	if c.purgeVisitorFunc != nil {
+		for key, item := range c.items {
+			c.purgeVisitorFunc(key, item.value)
+		}
+	}
+
+	c.init()
+}
+
+type simpleItem struct {
+	clock      Clock
+	value      interface{}
+	expiration *time.Time
+}
+
+// IsExpired returns boolean value whether this item is expired or not.
+func (si *simpleItem) IsExpired(now *time.Time) bool {
+	if si.expiration == nil {
+		return false
+	}
+	if now == nil {
+		t := si.clock.Now()
+		now = &t
+	}
+	return si.expiration.Before(*now)
+}
diff --git a/vendor/github.com/bluele/gcache/singleflight.go b/vendor/github.com/bluele/gcache/singleflight.go
new file mode 100644
index 00000000..2c6285e8
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/singleflight.go
@@ -0,0 +1,82 @@
+package gcache
+
+/*
+Copyright 2012 Google Inc.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+*/
+
+// This module provides a duplicate function call suppression
+// mechanism.
+
+import "sync"
+
+// call is an in-flight or completed Do call
+type call struct {
+	wg  sync.WaitGroup
+	val interface{}
+	err error
+}
+
+// Group represents a class of work and forms a namespace in which
+// units of work can be executed with duplicate suppression.
+type Group struct {
+	cache Cache
+	mu    sync.Mutex            // protects m
+	m     map[interface{}]*call // lazily initialized
+}
+
+// Do executes and returns the results of the given function, making
+// sure that only one execution is in-flight for a given key at a
+// time. If a duplicate comes in, the duplicate caller waits for the
+// original to complete and receives the same results.
+func (g *Group) Do(key interface{}, fn func() (interface{}, error), isWait bool) (interface{}, bool, error) {
+	g.mu.Lock()
+	v, err := g.cache.get(key, true)
+	if err == nil {
+		g.mu.Unlock()
+		return v, false, nil
+	}
+	if g.m == nil {
+		g.m = make(map[interface{}]*call)
+	}
+	if c, ok := g.m[key]; ok {
+		g.mu.Unlock()
+		if !isWait {
+			return nil, false, KeyNotFoundError
+		}
+		c.wg.Wait()
+		return c.val, false, c.err
+	}
+	c := new(call)
+	c.wg.Add(1)
+	g.m[key] = c
+	g.mu.Unlock()
+	if !isWait {
+		go g.call(c, key, fn)
+		return nil, false, KeyNotFoundError
+	}
+	v, err = g.call(c, key, fn)
+	return v, true, err
+}
+
+func (g *Group) call(c *call, key interface{}, fn func() (interface{}, error)) (interface{}, error) {
+	c.val, c.err = fn()
+	c.wg.Done()
+
+	g.mu.Lock()
+	delete(g.m, key)
+	g.mu.Unlock()
+
+	return c.val, c.err
+}
diff --git a/vendor/github.com/bluele/gcache/stats.go b/vendor/github.com/bluele/gcache/stats.go
new file mode 100644
index 00000000..ca0bf318
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/stats.go
@@ -0,0 +1,53 @@
+package gcache
+
+import (
+	"sync/atomic"
+)
+
+type statsAccessor interface {
+	HitCount() uint64
+	MissCount() uint64
+	LookupCount() uint64
+	HitRate() float64
+}
+
+// statistics
+type stats struct {
+	hitCount  uint64
+	missCount uint64
+}
+
+// increment hit count
+func (st *stats) IncrHitCount() uint64 {
+	return atomic.AddUint64(&st.hitCount, 1)
+}
+
+// increment miss count
+func (st *stats) IncrMissCount() uint64 {
+	return atomic.AddUint64(&st.missCount, 1)
+}
+
+// HitCount returns hit count
+func (st *stats) HitCount() uint64 {
+	return atomic.LoadUint64(&st.hitCount)
+}
+
+// MissCount returns miss count
+func (st *stats) MissCount() uint64 {
+	return atomic.LoadUint64(&st.missCount)
+}
+
+// LookupCount returns lookup count
+func (st *stats) LookupCount() uint64 {
+	return st.HitCount() + st.MissCount()
+}
+
+// HitRate returns rate for cache hitting
+func (st *stats) HitRate() float64 {
+	hc, mc := st.HitCount(), st.MissCount()
+	total := hc + mc
+	if total == 0 {
+		return 0.0
+	}
+	return float64(hc) / float64(total)
+}
diff --git a/vendor/github.com/bluele/gcache/utils.go b/vendor/github.com/bluele/gcache/utils.go
new file mode 100644
index 00000000..1f784e4c
--- /dev/null
+++ b/vendor/github.com/bluele/gcache/utils.go
@@ -0,0 +1,15 @@
+package gcache
+
+func minInt(x, y int) int {
+	if x < y {
+		return x
+	}
+	return y
+}
+
+func maxInt(x, y int) int {
+	if x > y {
+		return x
+	}
+	return y
+}
diff --git a/vendor/github.com/btcsuite/btcutil/LICENSE b/vendor/github.com/btcsuite/btcutil/LICENSE
new file mode 100644
index 00000000..3e7b1679
--- /dev/null
+++ b/vendor/github.com/btcsuite/btcutil/LICENSE
@@ -0,0 +1,16 @@
+ISC License
+
+Copyright (c) 2013-2017 The btcsuite developers
+Copyright (c) 2016-2017 The Lightning Network Developers
+
+Permission to use, copy, modify, and distribute this software for any
+purpose with or without fee is hereby granted, provided that the above
+copyright notice and this permission notice appear in all copies.
+
+THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
diff --git a/vendor/github.com/btcsuite/btcutil/base58/alphabet.go b/vendor/github.com/btcsuite/btcutil/base58/alphabet.go
new file mode 100644
index 00000000..6bb39fef
--- /dev/null
+++ b/vendor/github.com/btcsuite/btcutil/base58/alphabet.go
@@ -0,0 +1,49 @@
+// Copyright (c) 2015 The btcsuite developers
+// Use of this source code is governed by an ISC
+// license that can be found in the LICENSE file.
+
+// AUTOGENERATED by genalphabet.go; do not edit.
+
+package base58
+
+const (
+	// alphabet is the modified base58 alphabet used by Bitcoin.
+	alphabet = "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
+
+	alphabetIdx0 = '1'
+)
+
+var b58 = [256]byte{
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 0, 1, 2, 3, 4, 5, 6,
+	7, 8, 255, 255, 255, 255, 255, 255,
+	255, 9, 10, 11, 12, 13, 14, 15,
+	16, 255, 17, 18, 19, 20, 21, 255,
+	22, 23, 24, 25, 26, 27, 28, 29,
+	30, 31, 32, 255, 255, 255, 255, 255,
+	255, 33, 34, 35, 36, 37, 38, 39,
+	40, 41, 42, 43, 255, 44, 45, 46,
+	47, 48, 49, 50, 51, 52, 53, 54,
+	55, 56, 57, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255,
+}
diff --git a/vendor/github.com/btcsuite/btcutil/base58/base58.go b/vendor/github.com/btcsuite/btcutil/base58/base58.go
new file mode 100644
index 00000000..19a72de2
--- /dev/null
+++ b/vendor/github.com/btcsuite/btcutil/base58/base58.go
@@ -0,0 +1,75 @@
+// Copyright (c) 2013-2015 The btcsuite developers
+// Use of this source code is governed by an ISC
+// license that can be found in the LICENSE file.
+
+package base58
+
+import (
+	"math/big"
+)
+
+//go:generate go run genalphabet.go
+
+var bigRadix = big.NewInt(58)
+var bigZero = big.NewInt(0)
+
+// Decode decodes a modified base58 string to a byte slice.
+func Decode(b string) []byte {
+	answer := big.NewInt(0)
+	j := big.NewInt(1)
+
+	scratch := new(big.Int)
+	for i := len(b) - 1; i >= 0; i-- {
+		tmp := b58[b[i]]
+		if tmp == 255 {
+			return []byte("")
+		}
+		scratch.SetInt64(int64(tmp))
+		scratch.Mul(j, scratch)
+		answer.Add(answer, scratch)
+		j.Mul(j, bigRadix)
+	}
+
+	tmpval := answer.Bytes()
+
+	var numZeros int
+	for numZeros = 0; numZeros < len(b); numZeros++ {
+		if b[numZeros] != alphabetIdx0 {
+			break
+		}
+	}
+	flen := numZeros + len(tmpval)
+	val := make([]byte, flen)
+	copy(val[numZeros:], tmpval)
+
+	return val
+}
+
+// Encode encodes a byte slice to a modified base58 string.
+func Encode(b []byte) string {
+	x := new(big.Int)
+	x.SetBytes(b)
+
+	answer := make([]byte, 0, len(b)*136/100)
+	for x.Cmp(bigZero) > 0 {
+		mod := new(big.Int)
+		x.DivMod(x, bigRadix, mod)
+		answer = append(answer, alphabet[mod.Int64()])
+	}
+
+	// leading zero bytes
+	for _, i := range b {
+		if i != 0 {
+			break
+		}
+		answer = append(answer, alphabetIdx0)
+	}
+
+	// reverse
+	alen := len(answer)
+	for i := 0; i < alen/2; i++ {
+		answer[i], answer[alen-1-i] = answer[alen-1-i], answer[i]
+	}
+
+	return string(answer)
+}
diff --git a/vendor/github.com/btcsuite/btcutil/base58/base58check.go b/vendor/github.com/btcsuite/btcutil/base58/base58check.go
new file mode 100644
index 00000000..7cdafeee
--- /dev/null
+++ b/vendor/github.com/btcsuite/btcutil/base58/base58check.go
@@ -0,0 +1,52 @@
+// Copyright (c) 2013-2014 The btcsuite developers
+// Use of this source code is governed by an ISC
+// license that can be found in the LICENSE file.
+
+package base58
+
+import (
+	"crypto/sha256"
+	"errors"
+)
+
+// ErrChecksum indicates that the checksum of a check-encoded string does not verify against
+// the checksum.
+var ErrChecksum = errors.New("checksum error")
+
+// ErrInvalidFormat indicates that the check-encoded string has an invalid format.
+var ErrInvalidFormat = errors.New("invalid format: version and/or checksum bytes missing")
+
+// checksum: first four bytes of sha256^2
+func checksum(input []byte) (cksum [4]byte) {
+	h := sha256.Sum256(input)
+	h2 := sha256.Sum256(h[:])
+	copy(cksum[:], h2[:4])
+	return
+}
+
+// CheckEncode prepends a version byte and appends a four byte checksum.
+func CheckEncode(input []byte, version byte) string {
+	b := make([]byte, 0, 1+len(input)+4)
+	b = append(b, version)
+	b = append(b, input[:]...)
+	cksum := checksum(b)
+	b = append(b, cksum[:]...)
+	return Encode(b)
+}
+
+// CheckDecode decodes a string that was encoded with CheckEncode and verifies the checksum.
+func CheckDecode(input string) (result []byte, version byte, err error) {
+	decoded := Decode(input)
+	if len(decoded) < 5 {
+		return nil, 0, ErrInvalidFormat
+	}
+	version = decoded[0]
+	var cksum [4]byte
+	copy(cksum[:], decoded[len(decoded)-4:])
+	if checksum(decoded[:len(decoded)-4]) != cksum {
+		return nil, 0, ErrChecksum
+	}
+	payload := decoded[1 : len(decoded)-4]
+	result = append(result, payload...)
+	return
+}
diff --git a/vendor/github.com/btcsuite/btcutil/base58/doc.go b/vendor/github.com/btcsuite/btcutil/base58/doc.go
new file mode 100644
index 00000000..9a2c0e6e
--- /dev/null
+++ b/vendor/github.com/btcsuite/btcutil/base58/doc.go
@@ -0,0 +1,29 @@
+// Copyright (c) 2014 The btcsuite developers
+// Use of this source code is governed by an ISC
+// license that can be found in the LICENSE file.
+
+/*
+Package base58 provides an API for working with modified base58 and Base58Check
+encodings.
+
+Modified Base58 Encoding
+
+Standard base58 encoding is similar to standard base64 encoding except, as the
+name implies, it uses a 58 character alphabet which results in an alphanumeric
+string and allows some characters which are problematic for humans to be
+excluded.  Due to this, there can be various base58 alphabets.
+
+The modified base58 alphabet used by Bitcoin, and hence this package, omits the
+0, O, I, and l characters that look the same in many fonts and are therefore
+hard to humans to distinguish.
+
+Base58Check Encoding Scheme
+
+The Base58Check encoding scheme is primarily used for Bitcoin addresses at the
+time of this writing, however it can be used to generically encode arbitrary
+byte arrays into human-readable strings along with a version byte that can be
+used to differentiate the same payload.  For Bitcoin addresses, the extra
+version is used to differentiate the network of otherwise identical public keys
+which helps prevent using an address intended for one network on another.
+*/
+package base58
diff --git a/vendor/github.com/btcsuite/btcutil/base58/genalphabet.go b/vendor/github.com/btcsuite/btcutil/base58/genalphabet.go
new file mode 100644
index 00000000..010cbee3
--- /dev/null
+++ b/vendor/github.com/btcsuite/btcutil/base58/genalphabet.go
@@ -0,0 +1,79 @@
+// Copyright (c) 2015 The btcsuite developers
+// Use of this source code is governed by an ISC
+// license that can be found in the LICENSE file.
+
+//+build ignore
+
+package main
+
+import (
+	"bytes"
+	"io"
+	"log"
+	"os"
+	"strconv"
+)
+
+var (
+	start = []byte(`// Copyright (c) 2015 The btcsuite developers
+// Use of this source code is governed by an ISC
+// license that can be found in the LICENSE file.
+
+// AUTOGENERATED by genalphabet.go; do not edit.
+
+package base58
+
+const (
+	// alphabet is the modified base58 alphabet used by Bitcoin.
+	alphabet = "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
+
+	alphabetIdx0 = '1'
+)
+
+var b58 = [256]byte{`)
+
+	end = []byte(`}`)
+
+	alphabet = []byte("123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz")
+	tab      = []byte("\t")
+	invalid  = []byte("255")
+	comma    = []byte(",")
+	space    = []byte(" ")
+	nl       = []byte("\n")
+)
+
+func write(w io.Writer, b []byte) {
+	_, err := w.Write(b)
+	if err != nil {
+		log.Fatal(err)
+	}
+}
+
+func main() {
+	fi, err := os.Create("alphabet.go")
+	if err != nil {
+		log.Fatal(err)
+	}
+	defer fi.Close()
+
+	write(fi, start)
+	write(fi, nl)
+	for i := byte(0); i < 32; i++ {
+		write(fi, tab)
+		for j := byte(0); j < 8; j++ {
+			idx := bytes.IndexByte(alphabet, i*8+j)
+			if idx == -1 {
+				write(fi, invalid)
+			} else {
+				write(fi, strconv.AppendInt(nil, int64(idx), 10))
+			}
+			write(fi, comma)
+			if j != 7 {
+				write(fi, space)
+			}
+		}
+		write(fi, nl)
+	}
+	write(fi, end)
+	write(fi, nl)
+}
diff --git a/vendor/github.com/magiconair/properties/assert/assert.go b/vendor/github.com/magiconair/properties/assert/assert.go
new file mode 100644
index 00000000..d0f27046
--- /dev/null
+++ b/vendor/github.com/magiconair/properties/assert/assert.go
@@ -0,0 +1,90 @@
+// Copyright 2018 Frank Schroeder. All rights reserved.
+// Use of this source code is governed by a BSD-style
+// license that can be found in the LICENSE file.
+
+// Package assert provides helper functions for testing.
+package assert
+
+import (
+	"fmt"
+	"path/filepath"
+	"reflect"
+	"regexp"
+	"runtime"
+	"strings"
+	"testing"
+)
+
+// skip defines the default call depth
+const skip = 2
+
+// Equal asserts that got and want are equal as defined by
+// reflect.DeepEqual. The test fails with msg if they are not equal.
+func Equal(t *testing.T, got, want interface{}, msg ...string) {
+	if x := equal(2, got, want, msg...); x != "" {
+		fmt.Println(x)
+		t.Fail()
+	}
+}
+
+func equal(skip int, got, want interface{}, msg ...string) string {
+	if !reflect.DeepEqual(got, want) {
+		return fail(skip, "got %v want %v %s", got, want, strings.Join(msg, " "))
+	}
+	return ""
+}
+
+// Panic asserts that function fn() panics.
+// It assumes that recover() either returns a string or
+// an error and fails if the message does not match
+// the regular expression in 'matches'.
+func Panic(t *testing.T, fn func(), matches string) {
+	if x := doesPanic(2, fn, matches); x != "" {
+		fmt.Println(x)
+		t.Fail()
+	}
+}
+
+func doesPanic(skip int, fn func(), expr string) (err string) {
+	defer func() {
+		r := recover()
+		if r == nil {
+			err = fail(skip, "did not panic")
+			return
+		}
+		var v string
+		switch r.(type) {
+		case error:
+			v = r.(error).Error()
+		case string:
+			v = r.(string)
+		}
+		err = matches(skip, v, expr)
+	}()
+	fn()
+	return ""
+}
+
+// Matches asserts that a value matches a given regular expression.
+func Matches(t *testing.T, value, expr string) {
+	if x := matches(2, value, expr); x != "" {
+		fmt.Println(x)
+		t.Fail()
+	}
+}
+
+func matches(skip int, value, expr string) string {
+	ok, err := regexp.MatchString(expr, value)
+	if err != nil {
+		return fail(skip, "invalid pattern %q. %s", expr, err)
+	}
+	if !ok {
+		return fail(skip, "got %s which does not match %s", value, expr)
+	}
+	return ""
+}
+
+func fail(skip int, format string, args ...interface{}) string {
+	_, file, line, _ := runtime.Caller(skip)
+	return fmt.Sprintf("\t%s:%d: %s\n", filepath.Base(file), line, fmt.Sprintf(format, args...))
+}
diff --git a/vendor/github.com/pkg/errors/errors.go b/vendor/github.com/pkg/errors/errors.go
index 842ee804..7421f326 100644
--- a/vendor/github.com/pkg/errors/errors.go
+++ b/vendor/github.com/pkg/errors/errors.go
@@ -6,7 +6,7 @@
 //             return err
 //     }
 //
-// which applied recursively up the call stack results in error reports
+// which when applied recursively up the call stack results in error reports
 // without context or debugging information. The errors package allows
 // programmers to add context to the failure path in their code in a way
 // that does not destroy the original value of the error.
@@ -15,16 +15,17 @@
 //
 // The errors.Wrap function returns a new error that adds context to the
 // original error by recording a stack trace at the point Wrap is called,
-// and the supplied message. For example
+// together with the supplied message. For example
 //
 //     _, err := ioutil.ReadAll(r)
 //     if err != nil {
 //             return errors.Wrap(err, "read failed")
 //     }
 //
-// If additional control is required the errors.WithStack and errors.WithMessage
-// functions destructure errors.Wrap into its component operations of annotating
-// an error with a stack trace and an a message, respectively.
+// If additional control is required, the errors.WithStack and
+// errors.WithMessage functions destructure errors.Wrap into its component
+// operations: annotating an error with a stack trace and with a message,
+// respectively.
 //
 // Retrieving the cause of an error
 //
@@ -38,7 +39,7 @@
 //     }
 //
 // can be inspected by errors.Cause. errors.Cause will recursively retrieve
-// the topmost error which does not implement causer, which is assumed to be
+// the topmost error that does not implement causer, which is assumed to be
 // the original cause. For example:
 //
 //     switch err := errors.Cause(err).(type) {
@@ -48,16 +49,16 @@
 //             // unknown error
 //     }
 //
-// causer interface is not exported by this package, but is considered a part
-// of stable public API.
+// Although the causer interface is not exported by this package, it is
+// considered a part of its stable public interface.
 //
 // Formatted printing of errors
 //
 // All error values returned from this package implement fmt.Formatter and can
-// be formatted by the fmt package. The following verbs are supported
+// be formatted by the fmt package. The following verbs are supported:
 //
 //     %s    print the error. If the error has a Cause it will be
-//           printed recursively
+//           printed recursively.
 //     %v    see %s
 //     %+v   extended format. Each Frame of the error's StackTrace will
 //           be printed in detail.
@@ -65,13 +66,13 @@
 // Retrieving the stack trace of an error or wrapper
 //
 // New, Errorf, Wrap, and Wrapf record a stack trace at the point they are
-// invoked. This information can be retrieved with the following interface.
+// invoked. This information can be retrieved with the following interface:
 //
 //     type stackTracer interface {
 //             StackTrace() errors.StackTrace
 //     }
 //
-// Where errors.StackTrace is defined as
+// The returned errors.StackTrace type is defined as
 //
 //     type StackTrace []Frame
 //
@@ -85,8 +86,8 @@
 //             }
 //     }
 //
-// stackTracer interface is not exported by this package, but is considered a part
-// of stable public API.
+// Although the stackTracer interface is not exported by this package, it is
+// considered a part of its stable public interface.
 //
 // See the documentation for Frame.Format for more details.
 package errors
@@ -192,7 +193,7 @@ func Wrap(err error, message string) error {
 }
 
 // Wrapf returns an error annotating err with a stack trace
-// at the point Wrapf is call, and the format specifier.
+// at the point Wrapf is called, and the format specifier.
 // If err is nil, Wrapf returns nil.
 func Wrapf(err error, format string, args ...interface{}) error {
 	if err == nil {
@@ -220,6 +221,18 @@ func WithMessage(err error, message string) error {
 	}
 }
 
+// WithMessagef annotates err with the format specifier.
+// If err is nil, WithMessagef returns nil.
+func WithMessagef(err error, format string, args ...interface{}) error {
+	if err == nil {
+		return nil
+	}
+	return &withMessage{
+		cause: err,
+		msg:   fmt.Sprintf(format, args...),
+	}
+}
+
 type withMessage struct {
 	cause error
 	msg   string
diff --git a/vendor/github.com/pkg/errors/stack.go b/vendor/github.com/pkg/errors/stack.go
index 6b1f2891..2874a048 100644
--- a/vendor/github.com/pkg/errors/stack.go
+++ b/vendor/github.com/pkg/errors/stack.go
@@ -46,7 +46,8 @@ func (f Frame) line() int {
 //
 // Format accepts flags that alter the printing of some verbs, as follows:
 //
-//    %+s   path of source file relative to the compile time GOPATH
+//    %+s   function name and path of source file relative to the compile time
+//          GOPATH separated by \n\t (<funcname>\n\t<path>)
 //    %+v   equivalent to %+s:%d
 func (f Frame) Format(s fmt.State, verb rune) {
 	switch verb {
@@ -79,6 +80,14 @@ func (f Frame) Format(s fmt.State, verb rune) {
 // StackTrace is stack of Frames from innermost (newest) to outermost (oldest).
 type StackTrace []Frame
 
+// Format formats the stack of Frames according to the fmt.Formatter interface.
+//
+//    %s	lists source files for each Frame in the stack
+//    %v	lists the source file and line number for each Frame in the stack
+//
+// Format accepts flags that alter the printing of some verbs, as follows:
+//
+//    %+v   Prints filename, function, and line number for each Frame in the stack.
 func (st StackTrace) Format(s fmt.State, verb rune) {
 	switch verb {
 	case 'v':
@@ -136,43 +145,3 @@ func funcname(name string) string {
 	i = strings.Index(name, ".")
 	return name[i+1:]
 }
-
-func trimGOPATH(name, file string) string {
-	// Here we want to get the source file path relative to the compile time
-	// GOPATH. As of Go 1.6.x there is no direct way to know the compiled
-	// GOPATH at runtime, but we can infer the number of path segments in the
-	// GOPATH. We note that fn.Name() returns the function name qualified by
-	// the import path, which does not include the GOPATH. Thus we can trim
-	// segments from the beginning of the file path until the number of path
-	// separators remaining is one more than the number of path separators in
-	// the function name. For example, given:
-	//
-	//    GOPATH     /home/user
-	//    file       /home/user/src/pkg/sub/file.go
-	//    fn.Name()  pkg/sub.Type.Method
-	//
-	// We want to produce:
-	//
-	//    pkg/sub/file.go
-	//
-	// From this we can easily see that fn.Name() has one less path separator
-	// than our desired output. We count separators from the end of the file
-	// path until it finds two more than in the function name and then move
-	// one character forward to preserve the initial path segment without a
-	// leading separator.
-	const sep = "/"
-	goal := strings.Count(name, sep) + 2
-	i := len(file)
-	for n := 0; n < goal; n++ {
-		i = strings.LastIndex(file[:i], sep)
-		if i == -1 {
-			// not enough separators found, set i so that the slice expression
-			// below leaves file unmodified
-			i = -len(sep)
-			break
-		}
-	}
-	// get back to 0 or trim the leading separator
-	file = file[i+len(sep):]
-	return file
-}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/LICENSE b/vendor/github.com/trustbloc/fabric-peer-ext/LICENSE
new file mode 100644
index 00000000..261eeb9e
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/LICENSE
@@ -0,0 +1,201 @@
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/block_serialization.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/block_serialization.go
new file mode 100644
index 00000000..75c327d4
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/block_serialization.go
@@ -0,0 +1,67 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cdbblkstorage
+
+import (
+	"github.com/pkg/errors"
+
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protoutil"
+)
+
+func extractTxIDFromEnvelope(txEnvelope *common.Envelope) (string, error) {
+	payload, err := protoutil.GetPayload(txEnvelope)
+	if err != nil {
+		return "", nil
+	}
+
+	payloadHeader := payload.Header
+	channelHeader, err := protoutil.UnmarshalChannelHeader(payloadHeader.ChannelHeader)
+	if err != nil {
+		return "", err
+	}
+
+	return channelHeader.TxId, nil
+}
+
+func extractTxnEnvelopeFromBlock(block *common.Block, txID string) (*common.Envelope, error) {
+	blockData := block.GetData()
+	for _, txEnvelopeBytes := range blockData.GetData() {
+		envelope, err := protoutil.GetEnvelopeFromBlock(txEnvelopeBytes)
+		if err != nil {
+			return nil, err
+		}
+
+		id, err := extractTxIDFromEnvelope(envelope)
+		if err != nil {
+			return nil, err
+		}
+		if id != txID {
+			continue
+		}
+
+		txEnvelope, err := protoutil.GetEnvelopeFromBlock(txEnvelopeBytes)
+		if err != nil {
+			return nil, err
+		}
+
+		return txEnvelope, nil
+	}
+
+	return nil, errors.Errorf("transaction not found [%s]", txID)
+}
+
+func extractEnvelopeFromBlock(block *common.Block, tranNum uint64) (*common.Envelope, error) {
+	blockData := block.GetData()
+	envelopes := blockData.GetData()
+	envelopesLen := uint64(len(envelopes))
+	if envelopesLen-1 < tranNum {
+		blockNum := block.GetHeader().GetNumber()
+		return nil, errors.Errorf("transaction number is invalid [%d, %d, %d]", blockNum, envelopesLen, tranNum)
+	}
+	return protoutil.GetEnvelopeFromBlock(envelopes[tranNum])
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/blocks_itr.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/blocks_itr.go
new file mode 100644
index 00000000..db281826
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/blocks_itr.go
@@ -0,0 +1,73 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cdbblkstorage
+
+import (
+	"sync"
+
+	"github.com/hyperledger/fabric/common/ledger"
+)
+
+// blocksItr - an iterator for iterating over a sequence of blocks
+type blocksItr struct {
+	cdbBlockStore        *cdbBlockStore
+	maxBlockNumAvailable uint64
+	blockNumToRetrieve   uint64
+	closeMarker          bool
+	closeMarkerLock      *sync.Mutex
+}
+
+func newBlockItr(cdbBlockStore *cdbBlockStore, startBlockNum uint64) *blocksItr {
+	return &blocksItr{cdbBlockStore, cdbBlockStore.cpInfo.lastBlockNumber, startBlockNum, false, &sync.Mutex{}}
+}
+
+func (itr *blocksItr) waitForBlock(blockNum uint64) uint64 {
+	itr.cdbBlockStore.cpInfoCond.L.Lock()
+	defer itr.cdbBlockStore.cpInfoCond.L.Unlock()
+	for itr.cdbBlockStore.cpInfo.lastBlockNumber < blockNum && !itr.shouldClose() {
+		logger.Debugf("Going to wait for newer blocks. maxAvailaBlockNumber=[%d], waitForBlockNum=[%d]",
+			itr.cdbBlockStore.cpInfo.lastBlockNumber, blockNum)
+		itr.cdbBlockStore.cpInfoCond.Wait()
+		logger.Debugf("Came out of wait. maxAvailaBlockNumber=[%d]", itr.cdbBlockStore.cpInfo.lastBlockNumber)
+	}
+	return itr.cdbBlockStore.cpInfo.lastBlockNumber
+}
+
+func (itr *blocksItr) shouldClose() bool {
+	itr.closeMarkerLock.Lock()
+	defer itr.closeMarkerLock.Unlock()
+	return itr.closeMarker
+}
+
+// Next moves the cursor to next block and returns true iff the iterator is not exhausted
+func (itr *blocksItr) Next() (ledger.QueryResult, error) {
+	if itr.maxBlockNumAvailable < itr.blockNumToRetrieve {
+		itr.maxBlockNumAvailable = itr.waitForBlock(itr.blockNumToRetrieve)
+	}
+	itr.closeMarkerLock.Lock()
+	defer itr.closeMarkerLock.Unlock()
+	if itr.closeMarker {
+		return nil, nil
+	}
+
+	nextBlock, err := itr.cdbBlockStore.RetrieveBlockByNumber(itr.blockNumToRetrieve)
+	if err != nil {
+		return nil, err
+	}
+	itr.blockNumToRetrieve++
+	return nextBlock, nil
+}
+
+// Close releases any resources held by the iterator
+func (itr *blocksItr) Close() {
+	itr.cdbBlockStore.cpInfoCond.L.Lock()
+	defer itr.cdbBlockStore.cpInfoCond.L.Unlock()
+	itr.closeMarkerLock.Lock()
+	defer itr.closeMarkerLock.Unlock()
+	itr.closeMarker = true
+	itr.cdbBlockStore.cpInfoCond.Broadcast()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage.go
new file mode 100644
index 00000000..753b92ec
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage.go
@@ -0,0 +1,368 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cdbblkstorage
+
+import (
+	"bytes"
+	"encoding/hex"
+	"fmt"
+	"math"
+	"strconv"
+	"sync"
+
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+
+	"github.com/hyperledger/fabric/protoutil"
+
+	"github.com/hyperledger/fabric/common/ledger"
+	"github.com/hyperledger/fabric/common/ledger/blkstorage"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/peer"
+	"github.com/pkg/errors"
+)
+
+// cdbBlockStore ...
+type cdbBlockStore struct {
+	blockStore *couchdb.CouchDatabase
+	txnStore   *couchdb.CouchDatabase
+	ledgerID   string
+	cpInfo     *checkpointInfo
+	cpInfoCond *sync.Cond
+	cp         *checkpoint
+	attachTxn  bool
+}
+
+// newCDBBlockStore constructs block store based on CouchDB
+func newCDBBlockStore(blockStore *couchdb.CouchDatabase, txnStore *couchdb.CouchDatabase, ledgerID string) *cdbBlockStore {
+	cp := newCheckpoint(blockStore)
+
+	cdbBlockStore := &cdbBlockStore{
+		blockStore: blockStore,
+		txnStore:   txnStore,
+		ledgerID:   ledgerID,
+		cp:         cp,
+		attachTxn:  false,
+	}
+
+	// cp = checkpointInfo, retrieve from the database the last block number that was written to that db.
+	cpInfo := cdbBlockStore.cp.getCheckpointInfo()
+	err := cdbBlockStore.cp.saveCurrentInfo(cpInfo)
+	if err != nil {
+		panic(fmt.Sprintf("Could not save cpInfo info to db: %s", err))
+	}
+
+	// Update the manager with the checkpoint info and the file writer
+	cdbBlockStore.cpInfo = cpInfo
+
+	// Create a checkpoint condition (event) variable, for the  goroutine waiting for
+	// or announcing the occurrence of an event.
+	cdbBlockStore.cpInfoCond = sync.NewCond(&sync.Mutex{})
+
+	return cdbBlockStore
+}
+
+// AddBlock adds a new block
+func (s *cdbBlockStore) AddBlock(block *common.Block) error {
+
+	if !roles.IsCommitter() {
+		// Nothing to do if not a committer
+		return nil
+	}
+
+	err := s.validateBlock(block)
+	if err != nil {
+		return err
+	}
+
+	err = s.storeBlock(block)
+	if err != nil {
+		return err
+	}
+
+	err = s.storeTransactions(block)
+	if err != nil {
+		return err
+	}
+
+	return s.checkpointBlock(block)
+}
+
+//validateBlock validates block before adding to store
+func (s *cdbBlockStore) validateBlock(block *common.Block) error {
+
+	if s.cpInfo.isChainEmpty {
+		//chain is empty, no need to validate, first block it is.
+		return nil
+	}
+	if block.Header.Number != s.cpInfo.lastBlockNumber+1 {
+		return errors.Errorf(
+			"block number should have been %d but was %d",
+			s.cpInfo.lastBlockNumber+1, block.Header.Number,
+		)
+	}
+
+	// Add the previous hash check - Though, not essential but may not be a bad idea to
+	// verify the field `block.Header.PreviousHash` present in the block.
+	// This check is a simple bytes comparison and hence does not cause any observable performance penalty
+	// and may help in detecting a rare scenario if there is any bug in the ordering service.
+	if !bytes.Equal(block.Header.PreviousHash, s.cpInfo.currentHash) {
+		return errors.Errorf(
+			"unexpected Previous block hash. Expected PreviousHash = [%x], PreviousHash referred in the latest block= [%x]",
+			s.cpInfo.currentHash, block.Header.PreviousHash,
+		)
+	}
+
+	return nil
+}
+
+func (s *cdbBlockStore) storeBlock(block *common.Block) error {
+	doc, err := blockToCouchDoc(block)
+	if err != nil {
+		return errors.WithMessage(err, "converting block to couchDB document failed")
+	}
+
+	id := blockNumberToKey(block.GetHeader().GetNumber())
+
+	rev, err := s.blockStore.SaveDoc(id, "", doc)
+	if err != nil {
+		return errors.WithMessage(err, "adding block to couchDB failed")
+	}
+	logger.Debugf("block added to couchDB [%d, %s]", block.GetHeader().GetNumber(), rev)
+	return nil
+}
+
+func (s *cdbBlockStore) storeTransactions(block *common.Block) error {
+	docs, err := blockToTxnCouchDocs(block, s.attachTxn)
+	if err != nil {
+		return errors.WithMessage(err, "converting block to couchDB txn documents failed")
+	}
+
+	if len(docs) == 0 {
+		return nil
+	}
+
+	_, err = s.txnStore.BatchUpdateDocuments(docs)
+	if err != nil {
+		return errors.WithMessage(err, "adding block to couchDB failed")
+	}
+	logger.Debugf("block transactions added to couchDB [%d]", block.GetHeader().GetNumber())
+	return nil
+}
+
+func (s *cdbBlockStore) checkpointBlock(block *common.Block) error {
+	//Update the checkpoint info with the results of adding the new block
+	newCPInfo := &checkpointInfo{
+		isChainEmpty:    false,
+		lastBlockNumber: block.Header.Number,
+		currentHash:     protoutil.BlockHeaderHash(block.Header),
+	}
+	//save the checkpoint information in the database
+	err := s.cp.saveCurrentInfo(newCPInfo)
+	if err != nil {
+		return errors.WithMessage(err, "adding cpInfo to couchDB failed")
+	}
+	//update the checkpoint info (for storage) and the blockchain info (for APIs) in the manager
+	s.updateCheckpoint(newCPInfo)
+	return nil
+}
+
+// GetBlockchainInfo returns the current info about blockchain
+func (s *cdbBlockStore) GetBlockchainInfo() (*common.BlockchainInfo, error) {
+	cpInfo := s.cp.getCheckpointInfo()
+	s.cpInfo = cpInfo
+	bcInfo := &common.BlockchainInfo{
+		Height: 0,
+	}
+	if !cpInfo.isChainEmpty {
+		//If start up is a restart of an existing storage, update BlockchainInfo for external API's
+		lastBlock, err := s.RetrieveBlockByNumber(cpInfo.lastBlockNumber)
+		if err != nil {
+			return nil, fmt.Errorf("RetrieveBlockByNumber return error: %s", err)
+		}
+
+		lastBlockHeader := lastBlock.GetHeader()
+		lastBlockHash := protoutil.BlockHeaderHash(lastBlockHeader)
+		previousBlockHash := lastBlockHeader.GetPreviousHash()
+		bcInfo = &common.BlockchainInfo{
+			Height:            lastBlockHeader.GetNumber() + 1,
+			CurrentBlockHash:  lastBlockHash,
+			PreviousBlockHash: previousBlockHash,
+		}
+	}
+	return bcInfo, nil
+}
+
+// RetrieveBlocks returns an iterator that can be used for iterating over a range of blocks
+func (s *cdbBlockStore) RetrieveBlocks(startNum uint64) (ledger.ResultsIterator, error) {
+	return newBlockItr(s, startNum), nil
+}
+
+// RetrieveBlockByHash returns the block for given block-hash
+func (s *cdbBlockStore) RetrieveBlockByHash(blockHash []byte) (*common.Block, error) {
+	blockHashHex := hex.EncodeToString(blockHash)
+	const queryFmt = `
+	{
+		"selector": {
+			"` + blockHeaderField + `.` + blockHashField + `": {
+				"$eq": "%s"
+			}
+		},
+		"use_index": ["_design/` + blockHashIndexDoc + `", "` + blockHashIndexName + `"]
+	}`
+
+	block, err := retrieveBlockQuery(s.blockStore, fmt.Sprintf(queryFmt, blockHashHex))
+	if err != nil {
+		// note: allow ErrNotFoundInIndex to pass through
+		return nil, err
+	}
+	return block, nil
+}
+
+// RetrieveBlockByNumber returns the block at a given blockchain height
+func (s *cdbBlockStore) RetrieveBlockByNumber(blockNum uint64) (*common.Block, error) {
+	// interpret math.MaxUint64 as a request for last block
+	if blockNum == math.MaxUint64 {
+		bcinfo, err := s.GetBlockchainInfo()
+		if err != nil {
+			return nil, errors.WithMessage(err, "retrieval of blockchain info failed")
+		}
+		blockNum = bcinfo.Height - 1
+	}
+
+	id := blockNumberToKey(blockNum)
+
+	doc, _, err := s.blockStore.ReadDoc(id)
+	if err != nil {
+		return nil, errors.WithMessage(err, fmt.Sprintf("retrieval of block from couchDB failed [%d]", blockNum))
+	}
+	if doc == nil {
+		return nil, blkstorage.ErrNotFoundInIndex
+	}
+
+	block, err := couchDocToBlock(doc)
+	if err != nil {
+		return nil, errors.WithMessage(err, fmt.Sprintf("unmarshal of block from couchDB failed [%d]", blockNum))
+	}
+
+	return block, nil
+}
+
+// RetrieveTxByID returns a transaction for given transaction id
+func (s *cdbBlockStore) RetrieveTxByID(txID string) (*common.Envelope, error) {
+	doc, _, err := s.txnStore.ReadDoc(txID)
+	if err != nil {
+		// note: allow ErrNotFoundInIndex to pass through
+		return nil, err
+	}
+	if doc == nil {
+		return nil, blkstorage.ErrNotFoundInIndex
+	}
+
+	// If this transaction includes the envelope as a valid attachment then can return immediately.
+	if len(doc.Attachments) > 0 {
+		attachedEnv, e := couchAttachmentsToTxnEnvelope(doc.Attachments)
+		if e == nil {
+			return attachedEnv, nil
+		}
+		logger.Debugf("transaction has attachment but failed to be extracted into envelope [%s]", err)
+	}
+
+	// Otherwise, we need to extract the transaction from the block document.
+	block, err := s.RetrieveBlockByTxID(txID)
+	if err != nil {
+		// note: allow ErrNotFoundInIndex to pass through
+		return nil, err
+	}
+
+	return extractTxnEnvelopeFromBlock(block, txID)
+}
+
+// RetrieveTxByBlockNumTranNum returns a transaction for given block ID and transaction ID
+func (s *cdbBlockStore) RetrieveTxByBlockNumTranNum(blockNum uint64, tranNum uint64) (*common.Envelope, error) {
+	block, err := s.RetrieveBlockByNumber(blockNum)
+	if err != nil {
+		// note: allow ErrNotFoundInIndex to pass through
+		return nil, err
+	}
+	return extractEnvelopeFromBlock(block, tranNum)
+}
+
+// RetrieveBlockByTxID returns a block for a given transaction ID
+func (s *cdbBlockStore) RetrieveBlockByTxID(txID string) (*common.Block, error) {
+	blockHash, err := s.retrieveBlockHashByTxID(txID)
+	if err != nil {
+		return nil, err
+	}
+
+	return s.RetrieveBlockByHash(blockHash)
+}
+
+func (s *cdbBlockStore) retrieveBlockHashByTxID(txID string) ([]byte, error) {
+	jsonResult, err := retrieveJSONQuery(s.txnStore, txID)
+	if err != nil {
+		// note: allow ErrNotFoundInIndex to pass through
+		logger.Errorf("retrieving transaction document from DB failed : %s", err)
+		return nil, blkstorage.ErrNotFoundInIndex
+	}
+
+	blockHashStoredUT, ok := jsonResult[txnBlockHashField]
+	if !ok {
+		return nil, errors.Errorf("block hash was not found for transaction ID [%s]", txID)
+	}
+
+	blockHashStored, ok := blockHashStoredUT.(string)
+	if !ok {
+		return nil, errors.Errorf("block hash has invalid type for transaction ID [%s]", txID)
+	}
+
+	blockHash, err := hex.DecodeString(blockHashStored)
+	if err != nil {
+		return nil, errors.Wrapf(err, "block hash was invalid for transaction ID [%s]", txID)
+	}
+
+	return blockHash, nil
+}
+
+// RetrieveTxValidationCodeByTxID returns a TX validation code for a given transaction ID
+func (s *cdbBlockStore) RetrieveTxValidationCodeByTxID(txID string) (peer.TxValidationCode, error) {
+	jsonResult, err := retrieveJSONQuery(s.txnStore, txID)
+	if err != nil {
+		// note: allow ErrNotFoundInIndex to pass through
+		return peer.TxValidationCode(-1), err
+	}
+
+	txnValidationCodeStoredUT, ok := jsonResult[txnValidationCode]
+	if !ok {
+		return peer.TxValidationCode_INVALID_OTHER_REASON, errors.Errorf("validation code was not found for transaction ID [%s]", txID)
+	}
+
+	txnValidationCodeStored, ok := txnValidationCodeStoredUT.(string)
+	if !ok {
+		return peer.TxValidationCode_INVALID_OTHER_REASON, errors.Errorf("validation code has invalid type for transaction ID [%s]", txID)
+	}
+
+	const sizeOfTxValidationCode = 32
+	txnValidationCode, err := strconv.ParseInt(txnValidationCodeStored, txnValidationCodeBase, sizeOfTxValidationCode)
+	if err != nil {
+		return peer.TxValidationCode_INVALID_OTHER_REASON, errors.Wrapf(err, "validation code was invalid for transaction ID [%s]", txID)
+	}
+
+	return peer.TxValidationCode(txnValidationCode), nil
+}
+
+// Shutdown closes the storage instance
+func (s *cdbBlockStore) Shutdown() {
+}
+
+func (s *cdbBlockStore) updateCheckpoint(cpInfo *checkpointInfo) {
+	s.cpInfoCond.L.Lock()
+	defer s.cpInfoCond.L.Unlock()
+	s.cpInfo = cpInfo
+	logger.Debugf("Broadcasting about update checkpointInfo: %s", cpInfo)
+	s.cpInfoCond.Broadcast()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage_provider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage_provider.go
new file mode 100644
index 00000000..2f88a44f
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage_provider.go
@@ -0,0 +1,159 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cdbblkstorage
+
+import (
+	"strings"
+
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/common/ledger/blkstorage"
+	"github.com/hyperledger/fabric/common/metrics/disabled"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/pkg/errors"
+)
+
+var logger = flogging.MustGetLogger("cdbblkstorage")
+
+const (
+	blockStoreName = "blocks"
+	txnStoreName   = "transactions"
+)
+
+// CDBBlockstoreProvider provides block storage in CouchDB
+type CDBBlockstoreProvider struct {
+	couchInstance *couchdb.CouchInstance
+	indexConfig   *blkstorage.IndexConfig
+}
+
+// NewProvider creates a new CouchDB BlockStoreProvider
+func NewProvider(indexConfig *blkstorage.IndexConfig) (blkstorage.BlockStoreProvider, error) {
+	logger.Debugf("constructing CouchDB block storage provider")
+	couchDBDef := couchdb.GetCouchDBDefinition()
+	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	if err != nil {
+		return nil, errors.WithMessage(err, "obtaining CouchDB instance failed")
+	}
+	return &CDBBlockstoreProvider{couchInstance, indexConfig}, nil
+}
+
+// CreateBlockStore creates a block store instance for the given ledger ID
+func (p *CDBBlockstoreProvider) CreateBlockStore(ledgerid string) (blkstorage.BlockStore, error) {
+	return p.OpenBlockStore(ledgerid)
+}
+
+// OpenBlockStore opens the block store for the given ledger ID
+func (p *CDBBlockstoreProvider) OpenBlockStore(ledgerid string) (blkstorage.BlockStore, error) {
+	id := strings.ToLower(ledgerid)
+	blockStoreDBName := couchdb.ConstructBlockchainDBName(id, blockStoreName)
+	txnStoreDBName := couchdb.ConstructBlockchainDBName(id, txnStoreName)
+
+	if roles.IsCommitter() {
+		return p.createCommitterBlockStore(ledgerid, blockStoreDBName, txnStoreDBName)
+	}
+
+	return p.createNonCommitterBlockStore(ledgerid, blockStoreDBName, txnStoreDBName)
+}
+
+//createCommitterBlockStore creates new couch db with gievn db name if doesn't exists
+func (p *CDBBlockstoreProvider) createCommitterBlockStore(ledgerid, blockStoreDBName, txnStoreDBName string) (blkstorage.BlockStore, error) {
+
+	blockStoreDB, err := couchdb.CreateCouchDatabase(p.couchInstance, blockStoreDBName)
+	if err != nil {
+		return nil, err
+	}
+
+	txnStoreDB, err := couchdb.CreateCouchDatabase(p.couchInstance, txnStoreDBName)
+	if err != nil {
+		return nil, err
+	}
+
+	err = p.createBlockStoreIndices(blockStoreDB)
+	if err != nil {
+		return nil, err
+	}
+
+	return newCDBBlockStore(blockStoreDB, txnStoreDB, ledgerid), nil
+}
+
+//createBlockStore opens existing couch db with given db name with retry
+func (p *CDBBlockstoreProvider) createNonCommitterBlockStore(ledgerid, blockStoreDBName, txnStoreDBName string) (blkstorage.BlockStore, error) {
+
+	//create new block store db
+	blockStoreDB, err := p.openCouchDB(blockStoreDBName)
+	if err != nil {
+		return nil, err
+	}
+
+	//check if indexes exists
+	indexExists, err := blockStoreDB.IndexDesignDocExistsWithRetry(blockHashIndexDoc)
+	if err != nil {
+		return nil, err
+	}
+	if !indexExists {
+		return nil, errors.Errorf("DB index not found: [%s]", blockStoreDBName)
+	}
+
+	//create new txn store db
+	txnStoreDB, err := p.openCouchDB(txnStoreDBName)
+	if err != nil {
+		return nil, err
+	}
+
+	return newCDBBlockStore(blockStoreDB, txnStoreDB, ledgerid), nil
+}
+
+func (p *CDBBlockstoreProvider) openCouchDB(dbName string) (*couchdb.CouchDatabase, error) {
+	//create new store db
+	cdb, err := couchdb.NewCouchDatabase(p.couchInstance, dbName)
+	if err != nil {
+		return nil, err
+	}
+
+	//check if store db exists
+	dbExists, err := cdb.ExistsWithRetry()
+	if err != nil {
+		return nil, err
+	}
+	if !dbExists {
+		return nil, errors.Errorf("DB not found: [%s]", dbName)
+	}
+
+	return cdb, nil
+}
+
+func (p *CDBBlockstoreProvider) createBlockStoreIndices(db *couchdb.CouchDatabase) error {
+	_, err := db.CreateIndex(blockHashIndexDef)
+	if err != nil {
+		return errors.WithMessage(err, "creation of block hash index failed")
+	}
+
+	return nil
+}
+
+// Exists returns whether or not the given ledger ID exists
+func (p *CDBBlockstoreProvider) Exists(ledgerid string) (bool, error) {
+	id := strings.ToLower(ledgerid)
+	blockStoreDBName := couchdb.ConstructBlockchainDBName(id, blockStoreName)
+	blockStoreDB, err := couchdb.NewCouchDatabase(p.couchInstance, blockStoreDBName)
+	if err != nil {
+		return false, err
+	}
+
+	return blockStoreDB.Exists()
+}
+
+// List returns the available ledger IDs, not supported in couchdb block storage
+func (p *CDBBlockstoreProvider) List() ([]string, error) {
+	panic("not supported")
+}
+
+// Close cleans up the Provider
+func (p *CDBBlockstoreProvider) Close() {
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_checkpoint.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_checkpoint.go
new file mode 100644
index 00000000..813ffd02
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_checkpoint.go
@@ -0,0 +1,121 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cdbblkstorage
+
+import (
+	"fmt"
+
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/pkg/errors"
+)
+
+const blkMgrInfoKey = "blkMgrInfo"
+
+type checkpoint struct {
+	db *couchdb.CouchDatabase
+}
+
+// checkpointInfo
+type checkpointInfo struct {
+	isChainEmpty    bool
+	lastBlockNumber uint64
+	currentHash     []byte
+}
+
+func newCheckpoint(db *couchdb.CouchDatabase) *checkpoint {
+	return &checkpoint{db: db}
+}
+
+func (cp *checkpoint) getCheckpointInfo() *checkpointInfo {
+	cpInfo, err := cp.loadCurrentInfo()
+	if err != nil {
+		panic(fmt.Sprintf("Could not get block file info for current block file from db: %s", err))
+	}
+	if cpInfo == nil {
+		cpInfo = &checkpointInfo{
+			isChainEmpty:    true,
+			lastBlockNumber: 0}
+	}
+	return cpInfo
+}
+
+//Get the current checkpoint information that is stored in the database
+func (cp *checkpoint) loadCurrentInfo() (*checkpointInfo, error) {
+	doc, _, err := cp.db.ReadDoc(blkMgrInfoKey)
+	if err != nil {
+		return nil, errors.WithMessage(err, fmt.Sprintf("retrieval of checkpointInfo from couchDB failed [%s]", blkMgrInfoKey))
+	}
+	if doc == nil {
+		return nil, nil
+	}
+	checkpointInfo, err := couchDocToCheckpointInfo(doc)
+	if err != nil {
+		return nil, errors.WithMessage(err, fmt.Sprintf("unmarshal of checkpointInfo from couchDB failed [%s]", blkMgrInfoKey))
+	}
+	logger.Debugf("loaded checkpointInfo:%s", checkpointInfo)
+	return checkpointInfo, nil
+}
+
+func (cp *checkpoint) saveCurrentInfo(i *checkpointInfo) error {
+	doc, err := checkpointInfoToCouchDoc(i)
+	if err != nil {
+		return errors.WithMessage(err, "converting checkpointInfo to couchDB document failed")
+	}
+	_, err = cp.db.SaveDoc(blkMgrInfoKey, "", doc)
+	if err != nil {
+		return errors.WithMessage(err, "adding checkpointInfo to couchDB failed")
+	}
+	return nil
+}
+
+func (i *checkpointInfo) marshal() ([]byte, error) {
+	buffer := proto.NewBuffer([]byte{})
+	var err error
+	if err = buffer.EncodeVarint(i.lastBlockNumber); err != nil {
+		return nil, err
+	}
+
+	if err = buffer.EncodeRawBytes(i.currentHash); err != nil {
+		return nil, err
+	}
+
+	var chainEmptyMarker uint64
+	if i.isChainEmpty {
+		chainEmptyMarker = 1
+	}
+	if err = buffer.EncodeVarint(chainEmptyMarker); err != nil {
+		return nil, err
+	}
+
+	return buffer.Bytes(), nil
+}
+
+func (i *checkpointInfo) unmarshal(b []byte) error {
+	buffer := proto.NewBuffer(b)
+	var chainEmptyMarker uint64
+	var err error
+
+	if i.lastBlockNumber, err = buffer.DecodeVarint(); err != nil {
+		return err
+	}
+
+	if i.currentHash, err = buffer.DecodeRawBytes(false); err != nil {
+		return err
+	}
+
+	if len(i.currentHash) == 0 {
+		i.currentHash = nil
+	}
+
+	if chainEmptyMarker, err = buffer.DecodeVarint(); err != nil {
+		return err
+	}
+	i.isChainEmpty = chainEmptyMarker == 1
+
+	return nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/couchdoc_conv.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/couchdoc_conv.go
new file mode 100644
index 00000000..c70ae3a1
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/couchdoc_conv.go
@@ -0,0 +1,377 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cdbblkstorage
+
+import (
+	"bytes"
+	"encoding/hex"
+	"encoding/json"
+	"strconv"
+
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/common/ledger/blkstorage"
+	ledgerUtil "github.com/hyperledger/fabric/core/ledger/util"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/peer"
+	"github.com/hyperledger/fabric/protoutil"
+	"github.com/pkg/errors"
+)
+
+// block document
+const (
+	idField             = "_id"
+	blockHashField      = "hash"
+	blockTxnsField      = "transactions"
+	blockTxnIDField     = "id"
+	blockHashIndexName  = "by_hash"
+	blockHashIndexDoc   = "indexHash"
+	blockAttachmentName = "block"
+	blockKeyPrefix      = ""
+	blockHeaderField    = "header"
+)
+
+// txn document
+const (
+	txnBlockNumberField   = "block_number"
+	txnBlockHashField     = "block_hash"
+	txnAttachmentName     = "transaction"
+	txnValidationCode     = "validation_code"
+	txnValidationCodeBase = 16
+)
+
+// checkpoint document
+const (
+	cpiAttachmentName        = "checkpointinfo"
+	cpiAttachmentContentType = "application/octet-stream"
+)
+
+const blockHashIndexDef = `
+	{
+		"index": {
+			"fields": ["` + blockHeaderField + `.` + blockHashField + `"]
+		},
+		"name": "` + blockHashIndexName + `",
+		"ddoc": "` + blockHashIndexDoc + `",
+		"type": "json"
+	}`
+
+type jsonValue map[string]interface{}
+
+func (v jsonValue) toBytes() ([]byte, error) {
+	return json.Marshal(v)
+}
+
+func blockToCouchDoc(block *common.Block) (*couchdb.CouchDoc, error) {
+	jsonMap := make(jsonValue)
+
+	blockHeader := block.GetHeader()
+
+	key := blockNumberToKey(blockHeader.GetNumber())
+	blockHashHex := hex.EncodeToString(protoutil.BlockHeaderHash(blockHeader))
+	blockTxns, err := blockToTransactionsField(block)
+	if err != nil {
+		return nil, err
+	}
+
+	jsonMap[idField] = key
+	header := make(jsonValue)
+	header[blockHashField] = blockHashHex
+	jsonMap[blockHeaderField] = header
+	jsonMap[blockTxnsField] = blockTxns
+
+	jsonBytes, err := jsonMap.toBytes()
+	if err != nil {
+		return nil, err
+	}
+	couchDoc := &couchdb.CouchDoc{JSONValue: jsonBytes}
+
+	attachment, err := blockToAttachment(block)
+	if err != nil {
+		return nil, err
+	}
+
+	attachments := append([]*couchdb.AttachmentInfo{}, attachment)
+	couchDoc.Attachments = attachments
+	return couchDoc, nil
+}
+
+func blockToTxnCouchDocs(block *common.Block, attachTxn bool) ([]*couchdb.CouchDoc, error) {
+	blockHeader := block.GetHeader()
+	blockNumber := blockNumberToKey(blockHeader.GetNumber())
+	blockHash := hex.EncodeToString(protoutil.BlockHeaderHash(blockHeader))
+
+	blockData := block.GetData()
+
+	blockMetadata := block.GetMetadata()
+	txValidationFlags := ledgerUtil.TxValidationFlags(blockMetadata.GetMetadata()[common.BlockMetadataIndex_TRANSACTIONS_FILTER])
+
+	txnDocs := make([]*couchdb.CouchDoc, 0)
+
+	for i, txEnvelopeBytes := range blockData.GetData() {
+		envelope, err := protoutil.GetEnvelopeFromBlock(txEnvelopeBytes)
+		if err != nil {
+			return nil, err
+		}
+
+		txnDoc, err := blockTxnToCouchDoc(blockNumber, blockHash, envelope, txValidationFlags.Flag(i), attachTxn)
+		if err == errorNoTxID {
+			continue
+		} else if err != nil {
+			return nil, err
+		}
+
+		txnDocs = append(txnDocs, txnDoc)
+	}
+
+	return txnDocs, nil
+}
+
+var errorNoTxID = errors.New("missing transaction ID")
+
+func blockTxnToCouchDoc(blockNumber string, blockHash string, txEnvelope *common.Envelope, validationCode peer.TxValidationCode, attachTxn bool) (*couchdb.CouchDoc, error) {
+	txID, err := extractTxIDFromEnvelope(txEnvelope)
+	if err != nil {
+		return nil, errors.WithMessage(err, "transaction ID could not be extracted")
+	}
+
+	// TODO: is the empty transaction queryable? If so, need to change this to a default transaction ID.
+	if txID == "" {
+		return nil, errorNoTxID
+	}
+
+	jsonMap := make(jsonValue)
+	jsonMap[idField] = txID
+	jsonMap[txnBlockHashField] = blockHash
+	jsonMap[txnBlockNumberField] = blockNumber
+	jsonMap[txnValidationCode] = strconv.FormatInt(int64(validationCode), txnValidationCodeBase)
+
+	jsonBytes, err := jsonMap.toBytes()
+	if err != nil {
+		return nil, err
+	}
+	couchDoc := &couchdb.CouchDoc{JSONValue: jsonBytes}
+
+	if attachTxn {
+		attachment, err := txnEnvelopeToAttachment(txEnvelope)
+		if err != nil {
+			return nil, err
+		}
+
+		attachments := append([]*couchdb.AttachmentInfo{}, attachment)
+		couchDoc.Attachments = attachments
+	}
+	return couchDoc, nil
+}
+
+func checkpointInfoToCouchDoc(i *checkpointInfo) (*couchdb.CouchDoc, error) {
+	jsonMap := make(jsonValue)
+
+	jsonMap[idField] = blkMgrInfoKey
+
+	jsonBytes, err := jsonMap.toBytes()
+	if err != nil {
+		return nil, err
+	}
+	couchDoc := &couchdb.CouchDoc{JSONValue: jsonBytes}
+
+	attachment, err := checkpointInfoToAttachment(i)
+	if err != nil {
+		return nil, err
+	}
+
+	attachments := append([]*couchdb.AttachmentInfo{}, attachment)
+	couchDoc.Attachments = attachments
+	return couchDoc, nil
+}
+
+func checkpointInfoToAttachment(i *checkpointInfo) (*couchdb.AttachmentInfo, error) {
+	checkpointInfoBytes, err := i.marshal()
+	if err != nil {
+		return nil, errors.Wrapf(err, "marshaling checkpointInfo failed")
+	}
+
+	attachment := &couchdb.AttachmentInfo{}
+	attachment.AttachmentBytes = checkpointInfoBytes
+	attachment.ContentType = cpiAttachmentContentType
+	attachment.Name = cpiAttachmentName
+
+	return attachment, nil
+}
+
+func blockToTransactionsField(block *common.Block) ([]jsonValue, error) {
+	blockData := block.GetData()
+
+	var txns []jsonValue
+
+	for _, txEnvelopeBytes := range blockData.GetData() {
+		envelope, err := protoutil.GetEnvelopeFromBlock(txEnvelopeBytes)
+		if err != nil {
+			return nil, err
+		}
+
+		txID, err := extractTxIDFromEnvelope(envelope)
+		if err != nil {
+			return nil, errors.WithMessage(err, "transaction ID could not be extracted")
+		}
+
+		txField := make(jsonValue)
+		txField[blockTxnIDField] = txID
+
+		txns = append(txns, txField)
+	}
+
+	return txns, nil
+}
+
+func txnEnvelopeToAttachment(txEnvelope *common.Envelope) (*couchdb.AttachmentInfo, error) {
+	txEnvelopeBytes, err := proto.Marshal(txEnvelope)
+	if err != nil {
+		return nil, errors.Wrapf(err, "marshaling block failed")
+	}
+
+	attachment := &couchdb.AttachmentInfo{}
+	attachment.AttachmentBytes = txEnvelopeBytes
+	attachment.ContentType = cpiAttachmentContentType
+	attachment.Name = txnAttachmentName
+
+	return attachment, nil
+}
+
+func blockToAttachment(block *common.Block) (*couchdb.AttachmentInfo, error) {
+	blockBytes, err := proto.Marshal(block)
+	if err != nil {
+		return nil, errors.Wrapf(err, "marshaling block failed")
+	}
+
+	attachment := &couchdb.AttachmentInfo{}
+	attachment.AttachmentBytes = blockBytes
+	attachment.ContentType = cpiAttachmentContentType
+	attachment.Name = blockAttachmentName
+
+	return attachment, nil
+}
+
+func couchDocToBlock(doc *couchdb.CouchDoc) (*common.Block, error) {
+	return couchAttachmentsToBlock(doc.Attachments)
+}
+
+func couchAttachmentsToBlock(attachments []*couchdb.AttachmentInfo) (*common.Block, error) {
+	var blockBytes []byte
+	block := common.Block{}
+
+	// get binary data from attachment
+	for _, a := range attachments {
+		if a.Name == blockAttachmentName {
+			blockBytes = a.AttachmentBytes
+		}
+	}
+
+	if len(blockBytes) == 0 {
+		return nil, errors.New("block is not within couchDB document")
+	}
+
+	err := proto.Unmarshal(blockBytes, &block)
+	if err != nil {
+		return nil, errors.Wrapf(err, "block from couchDB document could not be unmarshaled")
+	}
+
+	return &block, nil
+}
+
+func couchAttachmentsToTxnEnvelope(attachments []*couchdb.AttachmentInfo) (*common.Envelope, error) {
+	var envelope common.Envelope
+	var txnBytes []byte
+
+	// get binary data from attachment
+	for _, a := range attachments {
+		if a.Name == txnAttachmentName {
+			txnBytes = a.AttachmentBytes
+		}
+	}
+
+	if len(txnBytes) == 0 {
+		return nil, errors.New("transaction envelope is not within couchDB document")
+	}
+
+	err := proto.Unmarshal(txnBytes, &envelope)
+	if err != nil {
+		return nil, errors.Wrapf(err, "transaction from couchDB document could not be unmarshaled")
+	}
+
+	return &envelope, nil
+}
+
+func couchDocToCheckpointInfo(doc *couchdb.CouchDoc) (*checkpointInfo, error) {
+	return couchAttachmentsToCheckpointInfo(doc.Attachments)
+}
+
+func couchAttachmentsToCheckpointInfo(attachments []*couchdb.AttachmentInfo) (*checkpointInfo, error) {
+	var checkpointInfoBytes []byte
+	cpInfo := checkpointInfo{}
+	// get binary data from attachment
+	for _, a := range attachments {
+		if a.Name == cpiAttachmentName {
+			checkpointInfoBytes = a.AttachmentBytes
+		}
+	}
+	if len(checkpointInfoBytes) == 0 {
+		return nil, errors.New("checkpointInfo is not within couchDB document")
+	}
+	err := cpInfo.unmarshal(checkpointInfoBytes)
+	if err != nil {
+		return nil, errors.Wrapf(err, "checkpointInfo from couchDB document could not be unmarshaled")
+	}
+	return &cpInfo, nil
+}
+
+func blockNumberToKey(blockNum uint64) string {
+	return blockKeyPrefix + strconv.FormatUint(blockNum, 10)
+}
+
+func retrieveBlockQuery(db *couchdb.CouchDatabase, query string) (*common.Block, error) {
+	results, _, err := db.QueryDocuments(query)
+	if err != nil {
+		return nil, err
+	}
+
+	if len(results) == 0 {
+		return nil, blkstorage.ErrNotFoundInIndex
+	}
+
+	if len(results[0].Attachments) == 0 {
+		return nil, errors.New("block bytes not found")
+	}
+
+	return couchAttachmentsToBlock(results[0].Attachments)
+}
+
+func retrieveJSONQuery(db *couchdb.CouchDatabase, id string) (jsonValue, error) {
+	doc, _, err := db.ReadDoc(id)
+	if err != nil {
+		return nil, err
+	}
+	if doc == nil {
+		return nil, blkstorage.ErrNotFoundInIndex
+	}
+
+	return couchDocToJSON(doc)
+}
+
+func couchDocToJSON(doc *couchdb.CouchDoc) (jsonValue, error) {
+	// create a generic map unmarshal the json
+	jsonResult := make(map[string]interface{})
+	decoder := json.NewDecoder(bytes.NewBuffer(doc.JSONValue))
+	decoder.UseNumber()
+
+	err := decoder.Decode(&jsonResult)
+	if err != nil {
+		return nil, errors.Wrapf(err, "result from DB is not JSON encoded")
+	}
+
+	return jsonResult, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api/offledger.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api/offledger.go
new file mode 100644
index 00000000..c0b429c0
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api/offledger.go
@@ -0,0 +1,56 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package api
+
+import (
+	"context"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	cb "github.com/hyperledger/fabric/protos/common"
+	proto "github.com/hyperledger/fabric/protos/transientstore"
+)
+
+// Store manages the storage of private data collections.
+type Store interface {
+	// Persist stores the private write set of a transaction.
+	Persist(txid string, privateSimulationResultsWithConfig *proto.TxPvtReadWriteSetWithConfigInfo) error
+
+	// PutData stores the key/value.
+	PutData(config *cb.StaticCollectionConfig, key *storeapi.Key, value *storeapi.ExpiringValue) error
+
+	// GetData gets the value for the given item
+	GetData(key *storeapi.Key) (*storeapi.ExpiringValue, error)
+
+	// GetDataMultipleKeys gets the values for the multiple items in a single call
+	GetDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error)
+
+	// Close closes the store
+	Close()
+}
+
+// StoreProvider is an interface to open/close a store
+type StoreProvider interface {
+	// OpenStore creates a handle to the private data store for the given ledger ID
+	OpenStore(ledgerid string) (Store, error)
+
+	// Close cleans up the provider
+	Close()
+}
+
+// Retriever retrieves data
+type Retriever interface {
+	// GetData gets the value for the given data item
+	GetData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error)
+
+	// GetDataMultipleKeys gets the values for the multiple data items in a single call
+	GetDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error)
+}
+
+// Provider provides data retrievers
+type Provider interface {
+	RetrieverForChannel(channel string) Retriever
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/cas.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/cas.go
new file mode 100644
index 00000000..986f4bb0
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/cas.go
@@ -0,0 +1,41 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dcas
+
+import (
+	"crypto"
+	"encoding/base64"
+
+	"github.com/btcsuite/btcutil/base58"
+)
+
+// GetCASKey returns the content-addressable key for the given content.
+func GetCASKey(content []byte) string {
+	address := calculateAddress(content)
+
+	// Address above is as per CAS spec(sha256 hash + base64 URL encoding),
+	// however since fabric/couchdb doesn't support keys that start with _
+	// we have to do additional transformation
+	return base58.Encode(address)
+}
+
+func calculateAddress(content []byte) []byte {
+	hash := getHash(content)
+	buf := make([]byte, base64.URLEncoding.EncodedLen(len(hash)))
+	base64.URLEncoding.Encode(buf, hash)
+
+	return buf
+}
+
+// getHash will compute the hash for the supplied bytes using SHA256
+func getHash(bytes []byte) []byte {
+	h := crypto.SHA256.New()
+	// added no lint directive because there's no error from source code
+	// error cannot be produced, checked google source
+	h.Write(bytes) //nolint
+	return h.Sum(nil)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/dcas.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/dcas.go
new file mode 100644
index 00000000..a83cfeb9
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/dcas.go
@@ -0,0 +1,53 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dcas
+
+import (
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	"github.com/pkg/errors"
+)
+
+// Validator is an off-ledger validator that validates the CAS key against the value
+func Validator(_, _, _, key string, value []byte) error {
+	if value == nil {
+		return errors.Errorf("nil value for key [%s]", key)
+	}
+	expectedKey := GetCASKey(value)
+	if key != expectedKey {
+		return errors.Errorf("Invalid CAS key [%s] - the key should be the hash of the value", key)
+	}
+	return nil
+}
+
+// Decorator is an off-ledger decorator that ensures the given key is the hash of the value. If the key is not
+// specified then it is generated. If the key is provided then it is validated against the value.
+func Decorator(key *storeapi.Key, value *storeapi.ExpiringValue) (*storeapi.Key, *storeapi.ExpiringValue, error) {
+	dcasKey, err := validateCASKey(key.Key, value.Value)
+	if err != nil {
+		return nil, nil, err
+	}
+
+	if dcasKey == key.Key {
+		return key, value, nil
+	}
+
+	newKey := *key
+	newKey.Key = dcasKey
+	return &newKey, value, nil
+}
+
+func validateCASKey(key string, value []byte) (string, error) {
+	if value == nil {
+		return "", errors.Errorf("attempt to put nil value for key [%s]", key)
+	}
+
+	casKey := GetCASKey(value)
+	if key != "" && key != casKey {
+		return casKey, errors.New("invalid CAS key - the key should be the hash of the value")
+	}
+	return casKey, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminationplan.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminationplan.go
new file mode 100644
index 00000000..6b88752f
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminationplan.go
@@ -0,0 +1,99 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dissemination
+
+import (
+	protobuf "github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/extensions/collections/api/dissemination"
+	gossipapi "github.com/hyperledger/fabric/gossip/api"
+	gcommon "github.com/hyperledger/fabric/gossip/common"
+	gdiscovery "github.com/hyperledger/fabric/gossip/discovery"
+	"github.com/hyperledger/fabric/gossip/gossip"
+	"github.com/hyperledger/fabric/gossip/protoext"
+	cb "github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	"github.com/pkg/errors"
+	"github.com/spf13/viper"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas"
+)
+
+type gossipAdapter interface {
+	PeersOfChannel(gcommon.ChainID) []gdiscovery.NetworkMember
+	SelfMembershipInfo() gdiscovery.NetworkMember
+	IdentityInfo() gossipapi.PeerIdentitySet
+}
+
+// ComputeDisseminationPlan returns the dissemination plan for off ledger data
+func ComputeDisseminationPlan(
+	channelID, ns string,
+	rwSet *rwset.CollectionPvtReadWriteSet,
+	collConfig *cb.StaticCollectionConfig,
+	colAP privdata.CollectionAccessPolicy,
+	pvtDataMsg *protoext.SignedGossipMessage,
+	gossipAdapter gossipAdapter) ([]*dissemination.Plan, bool, error) {
+	logger.Debugf("Computing dissemination plan for [%s:%s]", ns, rwSet.CollectionName)
+
+	kvRwSet := &kvrwset.KVRWSet{}
+	if err := protobuf.Unmarshal(rwSet.Rwset, kvRwSet); err != nil {
+		return nil, true, errors.WithMessage(err, "error unmarshalling KV read/write set")
+	}
+
+	if err := validateAll(collConfig.Type, kvRwSet); err != nil {
+		return nil, false, errors.WithMessagef(err, "one or more keys did not validate for collection [%s:%s]", ns, rwSet.CollectionName)
+	}
+
+	peers := New(channelID, ns, rwSet.CollectionName, colAP, gossipAdapter).resolvePeersForDissemination().Remote()
+
+	logger.Debugf("Peers for dissemination of collection [%s:%s]: %s", ns, rwSet.CollectionName, peers)
+
+	routingFilter := func(member gdiscovery.NetworkMember) bool {
+		if peers.ContainsPeer(member.Endpoint) {
+			logger.Debugf("Including peer [%s] for dissemination of [%s:%s]", member.Endpoint, ns, rwSet.CollectionName)
+			return true
+		}
+
+		logger.Debugf("Not including peer [%s] for dissemination of [%s:%s]", member.Endpoint, ns, rwSet.CollectionName)
+		return false
+	}
+
+	sc := gossip.SendCriteria{
+		Timeout:    viper.GetDuration("peer.gossip.pvtData.pushAckTimeout"),
+		Channel:    gcommon.ChainID(channelID),
+		MaxPeers:   len(peers),
+		MinAck:     colAP.RequiredPeerCount(),
+		IsEligible: routingFilter,
+	}
+
+	return []*dissemination.Plan{{
+		Criteria: sc,
+		Msg:      pvtDataMsg,
+	}}, true, nil
+}
+
+func validateAll(collType cb.CollectionType, kvRWSet *kvrwset.KVRWSet) error {
+	for _, ws := range kvRWSet.Writes {
+		if err := validate(collType, ws); err != nil {
+			return err
+		}
+	}
+	return nil
+}
+
+func validate(collType cb.CollectionType, ws *kvrwset.KVWrite) error {
+	if ws.Value == nil {
+		return errors.Errorf("attempt to store nil value for key [%s]", ws.Key)
+	}
+	if collType == cb.CollectionType_COL_DCAS {
+		expectedKey := dcas.GetCASKey(ws.Value)
+		if ws.Key != expectedKey {
+			return errors.Errorf("invalid CAS key [%s] - the key should be the hash of the value", ws.Key)
+		}
+	}
+	return nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminator.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminator.go
new file mode 100644
index 00000000..037dbe27
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminator.go
@@ -0,0 +1,126 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dissemination
+
+import (
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/discovery"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+)
+
+var logger = flogging.MustGetLogger("ext_offledger")
+
+// Disseminator disseminates collection data to other endorsers
+type Disseminator struct {
+	*discovery.Discovery
+	namespace  string
+	collection string
+	policy     privdata.CollectionAccessPolicy
+}
+
+// New returns a new disseminator
+func New(channelID, namespace, collection string, policy privdata.CollectionAccessPolicy, gossip gossipAdapter) *Disseminator {
+	return &Disseminator{
+		Discovery:  discovery.New(channelID, gossip),
+		namespace:  namespace,
+		collection: collection,
+		policy:     policy,
+	}
+}
+
+// resolvePeersForDissemination resolves to a set of committers to which data should be disseminated
+func (d *Disseminator) resolvePeersForDissemination() discovery.PeerGroup {
+	orgs := d.policy.MemberOrgs()
+	maxPeerCount := d.policy.MaximumPeerCount()
+
+	logger.Debugf("[%s] Member orgs: %s", d.ChannelID(), orgs)
+
+	// Include all committers
+	peersForDissemination := d.getPeersWithRole(roles.CommitterRole, orgs)
+
+	if len(peersForDissemination) < maxPeerCount {
+		logger.Debugf("[%s] MaximumPeerCount in collection policy is %d and we only have %d committers. Adding some endorsers too...", d.ChannelID(), maxPeerCount, len(peersForDissemination))
+		for _, peer := range d.getPeersWithRole(roles.EndorserRole, orgs).Remote().Shuffle() {
+			if len(peersForDissemination) >= maxPeerCount {
+				// We have enough peers
+				break
+			}
+			logger.Debugf("Adding endorser [%s] ...", peer)
+			peersForDissemination = append(peersForDissemination, peer)
+		}
+	}
+
+	logger.Debugf("[%s] Peers for dissemination from orgs %s: %s", d.ChannelID(), orgs, peersForDissemination)
+
+	return peersForDissemination
+}
+
+// ResolvePeersForRetrieval resolves to a set of peers from which data should may be retrieved
+func (d *Disseminator) ResolvePeersForRetrieval() discovery.PeerGroup {
+	orgs := d.policy.MemberOrgs()
+
+	logger.Debugf("[%s] Member orgs: %s", d.ChannelID(), orgs)
+
+	// Maximum number of peers to ask for the data
+	maxPeers := getMaxPeersForRetrieval()
+
+	var peersForRetrieval discovery.PeerGroup
+	for _, peer := range d.getPeersWithRole(roles.EndorserRole, orgs).Remote().Shuffle() {
+		if len(peersForRetrieval) >= maxPeers {
+			// We have enough peers
+			break
+		}
+		logger.Debugf("Adding endorser [%s] ...", peer)
+		peersForRetrieval = append(peersForRetrieval, peer)
+	}
+
+	if len(peersForRetrieval) < maxPeers {
+		// Add some committers too
+		for _, peer := range d.getPeersWithRole(roles.CommitterRole, orgs).Remote().Shuffle() {
+			if len(peersForRetrieval) >= maxPeers {
+				// We have enough peers
+				break
+			}
+			logger.Debugf("Adding committer [%s] ...", peer)
+			peersForRetrieval = append(peersForRetrieval, peer)
+		}
+	}
+
+	logger.Debugf("[%s] Peers for retrieval from orgs %s: %s", d.ChannelID(), orgs, peersForRetrieval)
+
+	return peersForRetrieval
+}
+
+func (d *Disseminator) getPeersWithRole(role roles.Role, mspIDs []string) discovery.PeerGroup {
+	return d.GetMembers(func(m *discovery.Member) bool {
+		if !m.HasRole(role) {
+			logger.Debugf("[%s] Not adding peer [%s] since it does not have the role [%s]", d.ChannelID(), m.Endpoint, role)
+			return false
+		}
+		if !contains(mspIDs, m.MSPID) {
+			logger.Debugf("[%s] Not adding peer [%s] since it is not in any of the orgs [%s]", d.ChannelID(), m.Endpoint, mspIDs)
+			return false
+		}
+		return true
+	})
+}
+
+func contains(mspIDs []string, mspID string) bool {
+	for _, m := range mspIDs {
+		if m == mspID {
+			return true
+		}
+	}
+	return false
+}
+
+// getMaxPeersForRetrieval may be overridden by unit tests
+var getMaxPeersForRetrieval = func() int {
+	return config.GetOLCollMaxPeersForRetrieval()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/mocks/mockprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/mocks/mockprovider.go
new file mode 100644
index 00000000..efb33e70
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/mocks/mockprovider.go
@@ -0,0 +1,40 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"context"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	olapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api"
+)
+
+// Provider is a mock off-ledger data data provider
+type Provider struct {
+}
+
+// RetrieverForChannel returns the retriever for the given channel
+func (p *Provider) RetrieverForChannel(channel string) olapi.Retriever {
+	return &retriever{}
+}
+
+type retriever struct {
+}
+
+// GetData gets data for the given key
+func (m *retriever) GetData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return &storeapi.ExpiringValue{Value: []byte(key.Key)}, nil
+}
+
+// GetDataMultipleKeys gets data for multiple keys
+func (m *retriever) GetDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	values := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		values[i] = &storeapi.ExpiringValue{Value: []byte(k)}
+	}
+	return values, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/policy/validator.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/policy/validator.go
new file mode 100644
index 00000000..03d3e0c8
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/policy/validator.go
@@ -0,0 +1,42 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package policy
+
+import (
+	"time"
+
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/pkg/errors"
+)
+
+// ValidateConfig validates the Off-Ledger Collection configuration
+func ValidateConfig(config *common.StaticCollectionConfig) error {
+	if config.Type != common.CollectionType_COL_OFFLEDGER && config.Type != common.CollectionType_COL_DCAS {
+		return errors.Errorf("unsupported off-ledger collection type: %s", config.Type)
+	}
+
+	if config.RequiredPeerCount <= 0 {
+		return errors.Errorf("collection-name: %s -- required peer count must be greater than 0", config.Name)
+	}
+
+	if config.RequiredPeerCount > config.MaximumPeerCount {
+		return errors.Errorf("collection-name: %s -- maximum peer count (%d) must be greater than or equal to required peer count (%d)", config.Name, config.MaximumPeerCount, config.RequiredPeerCount)
+	}
+
+	if config.BlockToLive != 0 {
+		return errors.Errorf("collection-name: %s -- block-to-live not supported", config.Name)
+	}
+
+	if config.TimeToLive != "" {
+		_, err := time.ParseDuration(config.TimeToLive)
+		if err != nil {
+			return errors.Errorf("collection-name: %s -- invalid time format for time to live: %s", config.Name, err)
+		}
+	}
+
+	return nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever/olretriever.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever/olretriever.go
new file mode 100644
index 00000000..b6a53a63
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever/olretriever.go
@@ -0,0 +1,431 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package retriever
+
+import (
+	"context"
+	"sync"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	supportapi "github.com/hyperledger/fabric/extensions/collections/api/support"
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	"github.com/hyperledger/fabric/gossip/comm"
+	mspmgmt "github.com/hyperledger/fabric/msp/mgmt"
+	cb "github.com/hyperledger/fabric/protos/common"
+	gproto "github.com/hyperledger/fabric/protos/gossip"
+	"github.com/pkg/errors"
+	olapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/discovery"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/multirequest"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/requestmgr"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+)
+
+var logger = flogging.MustGetLogger("ext_offledger")
+
+type support interface {
+	Config(channelID, ns, coll string) (*cb.StaticCollectionConfig, error)
+	Policy(channel, ns, collection string) (privdata.CollectionAccessPolicy, error)
+	BlockPublisher(channelID string) gossipapi.BlockPublisher
+}
+
+// Validator is a key/value validator
+type Validator func(txID, ns, coll, key string, value []byte) error
+
+// Provider is a collection data data provider.
+type Provider struct {
+	support
+	storeForChannel func(channelID string) olapi.Store
+	gossipAdapter   func() supportapi.GossipAdapter
+	validators      map[cb.CollectionType]Validator
+}
+
+// Option is a provider option
+type Option func(p *Provider)
+
+// WithValidator sets the key/value validator
+func WithValidator(collType cb.CollectionType, validator Validator) Option {
+	return func(p *Provider) {
+		p.validators[collType] = validator
+	}
+}
+
+// NewProvider returns a new collection data provider
+func NewProvider(storeProvider func(channelID string) olapi.Store, support support, gossipProvider func() supportapi.GossipAdapter, opts ...Option) olapi.Provider {
+	p := &Provider{
+		support:         support,
+		storeForChannel: storeProvider,
+		gossipAdapter:   gossipProvider,
+		validators:      make(map[cb.CollectionType]Validator),
+	}
+
+	// Apply options
+	for _, opt := range opts {
+		opt(p)
+	}
+	return p
+}
+
+// RetrieverForChannel returns the collection data retriever for the given channel
+func (p *Provider) RetrieverForChannel(channelID string) olapi.Retriever {
+	r := &retriever{
+		support:       p.support,
+		gossipAdapter: p.gossipAdapter(),
+		store:         p.storeForChannel(channelID),
+		channelID:     channelID,
+		reqMgr:        requestmgr.Get(channelID),
+		resolvers:     make(map[collKey]resolver),
+		validators:    p.validators,
+	}
+
+	// Add a handler so that we can remove the resolver for a chaincode that has been upgraded
+	p.support.BlockPublisher(channelID).AddCCUpgradeHandler(func(blockNum uint64, txID string, chaincodeID string) error {
+		logger.Infof("[%s] Chaincode [%s] has been upgraded. Clearing resolver cache for chaincode.", channelID, chaincodeID)
+		r.removeResolvers(chaincodeID)
+		return nil
+	})
+
+	return r
+}
+
+type resolver interface {
+	// ResolvePeersForRetrieval resolves to a set of peers from which data should be retrieved
+	ResolvePeersForRetrieval() discovery.PeerGroup
+}
+
+type collKey struct {
+	ns   string
+	coll string
+}
+
+func newCollKey(ns, coll string) collKey {
+	return collKey{ns: ns, coll: coll}
+}
+
+type retriever struct {
+	support
+	gossipAdapter supportapi.GossipAdapter
+	channelID     string
+	store         olapi.Store
+	resolvers     map[collKey]resolver
+	lock          sync.RWMutex
+	reqMgr        requestmgr.RequestMgr
+	validators    map[cb.CollectionType]Validator
+}
+
+// GetData gets the values for the data item
+func (r *retriever) GetData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	values, err := r.GetDataMultipleKeys(ctxt, storeapi.NewMultiKey(key.EndorsedAtTxID, key.Namespace, key.Collection, key.Key))
+	if err != nil {
+		return nil, err
+	}
+
+	if values.Values().IsEmpty() {
+		return nil, nil
+	}
+
+	return values[0], nil
+}
+
+// GetDataMultipleKeys gets the values for the multiple data items in a single call
+func (r *retriever) GetDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	authorized, err := r.isAuthorized(key.Namespace, key.Collection)
+	if err != nil {
+		return nil, err
+	}
+	if !authorized {
+		logger.Infof("[%s] This peer does not have access to the collection [%s:%s]", r.channelID, key.Namespace, key.Collection)
+		return nil, nil
+	}
+
+	localValues, err := r.getMultipleKeysFromLocal(key)
+	if err != nil {
+		return nil, err
+	}
+	if localValues.Values().AllSet() {
+		err = r.validateValues(key, localValues)
+		if err != nil {
+			logger.Warningf(err.Error())
+			return nil, err
+		}
+		return localValues, nil
+	}
+
+	res, err := r.getResolver(key.Namespace, key.Collection)
+	if err != nil {
+		return nil, errors.WithMessagef(err, "unable to get resolver for channel [%s] and [%s:%s]", r.channelID, key.Namespace, key.Collection)
+	}
+
+	// Retrieve from the remote peers
+	cReq := multirequest.New()
+	for _, peer := range res.ResolvePeersForRetrieval() {
+		logger.Debugf("Adding request to get data for [%s] from [%s] ...", key, peer)
+		cReq.Add(peer.String(), r.getDataFromPeer(key, peer))
+	}
+
+	response := cReq.Execute(ctxt)
+
+	// Merge the values with the values received locally
+	values := asExpiringValues(localValues.Values().Merge(response.Values))
+
+	if err := r.validateValues(key, values); err != nil {
+		logger.Warningf(err.Error())
+		return nil, err
+	}
+
+	if roles.IsCommitter() {
+		r.persistMissingKeys(key, localValues, values)
+	}
+
+	return values, nil
+}
+
+func (r *retriever) getMultipleKeysFromLocal(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	localValues := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		value, retrieveErr := r.store.GetData(storeapi.NewKey(key.EndorsedAtTxID, key.Namespace, key.Collection, k))
+		if retrieveErr != nil {
+			logger.Warningf("[%s] Error getting data from local store for [%s]: %s", r.channelID, key, retrieveErr)
+			return nil, errors.WithMessagef(retrieveErr, "unable to get data for channel [%s] and [%s]", r.channelID, key)
+		}
+		localValues[i] = value
+	}
+	return localValues, nil
+}
+
+func getMissingKeyIndexes(values []*storeapi.ExpiringValue) []int {
+	var missingIndexes []int
+	for i, v := range values {
+		if v == nil {
+			missingIndexes = append(missingIndexes, i)
+		}
+	}
+	return missingIndexes
+}
+
+// persistMissingKeys persists the keys that were missing from the local store
+func (r *retriever) persistMissingKeys(key *storeapi.MultiKey, localValues, values storeapi.ExpiringValues) {
+	for _, i := range getMissingKeyIndexes(localValues) {
+		v := values[i]
+		if v != nil {
+			r.persistMissingKey(
+				storeapi.NewKey(key.EndorsedAtTxID, key.Namespace, key.Collection, key.Keys[i]),
+				&storeapi.ExpiringValue{Value: v.Value, Expiry: v.Expiry},
+			)
+		}
+	}
+}
+
+func (r *retriever) persistMissingKey(k *storeapi.Key, val *storeapi.ExpiringValue) {
+	logger.Debugf("Persisting key [%s] that was missing from the local store", k)
+	collConfig, err := r.Config(r.channelID, k.Namespace, k.Collection)
+	if err != nil {
+		logger.Warningf("Error persisting key [%s] that was missing from the local store: %s", k, err)
+	}
+	if err := r.store.PutData(collConfig, k, val); err != nil {
+		logger.Warningf("Error persisting key [%s] that was missing from the local store: %s", k, err)
+	}
+}
+
+func (r *retriever) validateValues(key *storeapi.MultiKey, values storeapi.ExpiringValues) error {
+	config, err := r.Config(r.channelID, key.Namespace, key.Collection)
+	if err != nil {
+		return err
+	}
+
+	validate, ok := r.validators[config.Type]
+	if !ok {
+		// No validator for config
+		return nil
+	}
+
+	for i, v := range values {
+		if v != nil && v.Value != nil {
+			err := validate(key.EndorsedAtTxID, key.Namespace, key.Collection, key.Keys[i], v.Value)
+			if err != nil {
+				return err
+			}
+		}
+	}
+	return nil
+}
+
+func (r *retriever) getDataFromPeer(key *storeapi.MultiKey, endorser *discovery.Member) multirequest.Request {
+	return func(ctxt context.Context) (common.Values, error) {
+		logger.Debugf("Getting data for [%s] from [%s] ...", key, endorser)
+
+		values, err := r.getData(ctxt, key, endorser)
+		if err != nil {
+			if err == context.Canceled {
+				logger.Debugf("[%s] Request to get data from [%s] for [%s] was cancelled", r.channelID, endorser, key)
+			} else {
+				logger.Debugf("[%s] Error getting data from [%s] for [%s]: %s", r.channelID, endorser, key, err)
+			}
+			return nil, err
+		}
+
+		return values.Values(), nil
+	}
+}
+
+func (r *retriever) getResolver(ns, coll string) (resolver, error) {
+	key := newCollKey(ns, coll)
+
+	r.lock.RLock()
+	resolver, ok := r.resolvers[key]
+	r.lock.RUnlock()
+
+	if ok {
+		return resolver, nil
+	}
+
+	return r.getOrCreateResolver(key)
+}
+
+func (r *retriever) getOrCreateResolver(key collKey) (resolver, error) {
+	r.lock.Lock()
+	defer r.lock.Unlock()
+
+	resolver, ok := r.resolvers[key]
+	if ok {
+		return resolver, nil
+	}
+
+	policy, err := r.Policy(r.channelID, key.ns, key.coll)
+	if err != nil {
+		return nil, err
+	}
+
+	resolver = dissemination.New(r.channelID, key.ns, key.coll, policy, r.gossipAdapter)
+
+	r.resolvers[key] = resolver
+
+	return resolver, nil
+}
+
+func (r *retriever) removeResolvers(ns string) {
+	r.lock.Lock()
+	defer r.lock.Unlock()
+
+	for key := range r.resolvers {
+		if key.ns == ns {
+			logger.Debugf("[%s] Removing resolver [%s:%s] from cache", r.channelID, key.ns, key.coll)
+			delete(r.resolvers, key)
+		}
+	}
+}
+
+func (r *retriever) getData(ctxt context.Context, key *storeapi.MultiKey, peers ...*discovery.Member) (storeapi.ExpiringValues, error) {
+	logger.Debugf("[%s] Sending Gossip request to %s for data for [%s]", r.channelID, peers, key)
+
+	req := r.reqMgr.NewRequest()
+
+	logger.Debugf("[%s] Creating Gossip request %d for data for [%s]", r.channelID, req.ID(), key)
+	msg := r.createCollDataRequestMsg(req, key)
+
+	logger.Debugf("[%s] Sending Gossip request %d for data for [%s]", r.channelID, req.ID(), key)
+	r.gossipAdapter.Send(msg, asRemotePeers(peers)...)
+
+	logger.Debugf("[%s] Waiting for response for %d for data for [%s]", r.channelID, req.ID(), key)
+	res, err := req.GetResponse(ctxt)
+	if err != nil {
+		return nil, err
+	}
+
+	logger.Debugf("[%s] Got response for %d for data for [%s]", r.channelID, req.ID(), key)
+
+	data := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		d, ok := res.Data.Get(key.Namespace, key.Collection, k)
+		if !ok {
+			return nil, errors.Errorf("the response does not contain a value for key [%s:%s:%s]", key.Namespace, key.Collection, k)
+		}
+		if d.Value == nil {
+			data[i] = nil
+		} else {
+			data[i] = &storeapi.ExpiringValue{Value: d.Value, Expiry: d.Expiry}
+		}
+	}
+
+	return data, nil
+}
+
+// isAuthorized returns true if the local peer has access to the given collection
+func (r *retriever) isAuthorized(ns, coll string) (bool, error) {
+	policy, err := r.Policy(r.channelID, ns, coll)
+	if err != nil {
+		return false, errors.WithMessagef(err, "unable to get policy for [%s:%s]", ns, coll)
+	}
+
+	localMSPID, err := getLocalMSPID()
+	if err != nil {
+		return false, errors.WithMessagef(err, "unable to get local MSP ID")
+	}
+
+	for _, mspID := range policy.MemberOrgs() {
+		if mspID == localMSPID {
+			return true, nil
+		}
+	}
+
+	return false, nil
+}
+
+func (r *retriever) createCollDataRequestMsg(req requestmgr.Request, key *storeapi.MultiKey) *gproto.GossipMessage {
+	var digests []*gproto.CollDataDigest
+	for _, k := range key.Keys {
+		digests = append(digests, &gproto.CollDataDigest{
+			Namespace:      key.Namespace,
+			Collection:     key.Collection,
+			Key:            k,
+			EndorsedAtTxID: key.EndorsedAtTxID,
+		})
+	}
+
+	return &gproto.GossipMessage{
+		Tag:     gproto.GossipMessage_CHAN_ONLY,
+		Channel: []byte(r.channelID),
+		Content: &gproto.GossipMessage_CollDataReq{
+			CollDataReq: &gproto.RemoteCollDataRequest{
+				Nonce:   req.ID(),
+				Digests: digests,
+			},
+		},
+	}
+}
+
+func asRemotePeers(members []*discovery.Member) []*comm.RemotePeer {
+	var peers []*comm.RemotePeer
+	for _, m := range members {
+		peers = append(peers, &comm.RemotePeer{
+			Endpoint: m.Endpoint,
+			PKIID:    m.PKIid,
+		})
+	}
+	return peers
+}
+
+// getLocalMSPID returns the MSP ID of the local peer. This variable may be overridden by unit tests.
+var getLocalMSPID = func() (string, error) {
+	return mspmgmt.GetLocalMSP().GetIdentifier()
+}
+
+func asExpiringValues(cv common.Values) storeapi.ExpiringValues {
+	vals := make(storeapi.ExpiringValues, len(cv))
+	for i, v := range cv {
+		if common.IsNil(v) {
+			vals[i] = nil
+		} else {
+			vals[i] = v.(*storeapi.ExpiringValue)
+		}
+	}
+	return vals
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstore.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstore.go
new file mode 100644
index 00000000..50cd2246
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstore.go
@@ -0,0 +1,316 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	"time"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/rwsetutil"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	mspmgmt "github.com/hyperledger/fabric/msp/mgmt"
+	"github.com/hyperledger/fabric/protos/common"
+	cb "github.com/hyperledger/fabric/protos/common"
+	pb "github.com/hyperledger/fabric/protos/transientstore"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+)
+
+var logger = flogging.MustGetLogger("ext_offledger")
+
+type store struct {
+	channelID   string
+	dbProvider  api.DBProvider
+	cache       *cache.Cache
+	collConfigs map[common.CollectionType]*collTypeConfig
+}
+
+func newStore(channelID string, dbProvider api.DBProvider, collConfigs map[common.CollectionType]*collTypeConfig) *store {
+	logger.Debugf("constructing collection data store")
+	return &store{
+		channelID:   channelID,
+		collConfigs: collConfigs,
+		dbProvider:  dbProvider,
+		cache:       cache.New(channelID, dbProvider, config.GetOLCollCacheSize()),
+	}
+}
+
+// Close closes the store
+func (s *store) Close() {
+	s.dbProvider.Close()
+}
+
+// Persist persists all data within the private data simulation results
+func (s *store) Persist(txID string, privateSimulationResultsWithConfig *pb.TxPvtReadWriteSetWithConfigInfo) error {
+	rwSet, err := rwsetutil.TxPvtRwSetFromProtoMsg(privateSimulationResultsWithConfig.PvtRwset)
+	if err != nil {
+		return errors.WithMessage(err, "error getting pvt RW set from bytes")
+	}
+
+	for _, nsRWSet := range rwSet.NsPvtRwSet {
+		for _, collRWSet := range nsRWSet.CollPvtRwSets {
+			if err := s.persistColl(txID, nsRWSet.NameSpace, privateSimulationResultsWithConfig.CollectionConfigs, collRWSet); err != nil {
+				return err
+			}
+		}
+	}
+
+	return nil
+}
+
+// PutData returns the  data for the given key
+func (s *store) PutData(config *cb.StaticCollectionConfig, key *storeapi.Key, value *storeapi.ExpiringValue) error {
+	if value.Value == nil {
+		return errors.Errorf("attempt to put nil value for key [%s]", key)
+	}
+	if config.Name != key.Collection {
+		return errors.Errorf("invalid collection config for key [%s]", key)
+	}
+
+	key, value, err := s.decorate(config, key, value)
+	if err != nil {
+		return err
+	}
+
+	if !value.Expiry.IsZero() {
+		if value.Expiry.Before(time.Now()) {
+			// Already expired
+			logger.Debugf("[%s] Key [%s] already expired", s.channelID, key)
+			return nil
+		}
+	}
+
+	db, err := s.dbProvider.GetDB(key.Namespace, key.Collection)
+	if err != nil {
+		return err
+	}
+
+	logger.Debugf("[%s] Putting key [%s] to DB", s.channelID, key)
+	err = db.Put(api.NewKeyValue(key.Key, value.Value, key.EndorsedAtTxID, value.Expiry))
+	if err != nil {
+		return err
+	}
+
+	logger.Debugf("[%s] Putting key [%s] to cache", s.channelID, key)
+	s.cache.Put(key.Namespace, key.Collection, key.Key,
+		&api.Value{
+			Value:      value.Value,
+			TxID:       key.EndorsedAtTxID,
+			ExpiryTime: value.Expiry,
+		},
+	)
+
+	return nil
+}
+
+// GetData returns the  data for the given key
+func (s *store) GetData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return s.getData(key.EndorsedAtTxID, key.Namespace, key.Collection, key.Key)
+}
+
+// tDataMultipleKeys returns the  data for the given keys
+func (s *store) GetDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	return s.getDataMultipleKeys(key.EndorsedAtTxID, key.Namespace, key.Collection, key.Keys...)
+}
+
+func (s *store) persistColl(txID string, ns string, collConfigPkgs map[string]*common.CollectionConfigPackage, collRWSet *rwsetutil.CollPvtRwSet) error {
+	config, exists := s.getCollectionConfig(collConfigPkgs, ns, collRWSet.CollectionName)
+	if !exists {
+		logger.Debugf("[%s]  config for collection [%s:%s] not found in config packages", s.channelID, ns, collRWSet.CollectionName)
+		return nil
+	}
+
+	authorized, err := s.isAuthorized(ns, config)
+	if err != nil {
+		return err
+	}
+	if !authorized {
+		logger.Infof("[%s] Will not store  collection [%s:%s] since local peer is not authorized.", s.channelID, ns, collRWSet.CollectionName)
+		return nil
+	}
+
+	logger.Debugf("[%s] Collection [%s:%s] is a  collection", s.channelID, ns, collRWSet.CollectionName)
+
+	expiryTime, err := s.getExpirationTime(config)
+	if err != nil {
+		return err
+	}
+
+	batch, err := s.createBatch(txID, ns, config, collRWSet, expiryTime)
+	if err != nil {
+		return err
+	}
+
+	db, err := s.dbProvider.GetDB(ns, collRWSet.CollectionName)
+	if err != nil {
+		return err
+	}
+
+	err = db.Put(batch...)
+	if err != nil {
+		return errors.WithMessagef(err, "error persisting to [%s:%s]", ns, collRWSet.CollectionName)
+	}
+
+	for _, kv := range batch {
+		logger.Debugf("[%s] Putting key [%s:%s:%s] in Tx [%s]", s.channelID, ns, collRWSet.CollectionName, kv.Key, kv.TxID)
+		s.cache.Put(ns, collRWSet.CollectionName, kv.Key, kv.Value)
+	}
+
+	return nil
+}
+
+func (s *store) getData(txID, ns, coll, key string) (*storeapi.ExpiringValue, error) {
+	value, err := s.cache.Get(ns, coll, key)
+	if err != nil {
+		return nil, err
+	}
+
+	if value == nil {
+		return nil, nil
+	}
+
+	logger.Debugf("[%s] Got value for key [%s:%s:%s] which was persisted in transaction [%s]. Current tx [%s]", s.channelID, ns, coll, key, value.TxID, txID)
+	if value.TxID == txID {
+		logger.Debugf("[%s] Key [%s:%s:%s] was persisted in same transaction [%s] as caller. Returning nil.", s.channelID, ns, coll, key, txID)
+		return nil, nil
+	}
+
+	return &storeapi.ExpiringValue{Value: value.Value, Expiry: value.ExpiryTime}, nil
+}
+
+func (s *store) getDataMultipleKeys(txID, ns, coll string, keys ...string) (storeapi.ExpiringValues, error) {
+	values, err := s.cache.GetMultiple(ns, coll, keys...)
+	if err != nil {
+		return nil, err
+	}
+
+	if len(values) != len(keys) {
+		return nil, errors.New("not all of the values were returned for the set of keys")
+	}
+
+	var ret storeapi.ExpiringValues
+	for i, value := range values {
+		var v *storeapi.ExpiringValue
+		if value != nil {
+			logger.Debugf("[%s] Got value for key [%s:%s:%s] which was persisted in transaction [%s]. Current tx [%s]", s.channelID, ns, coll, keys[i], value.TxID, txID)
+			if value.TxID == txID {
+				logger.Debugf("[%s] Key [%s:%s:%s] was persisted in same transaction [%s] as caller. Returning nil.", s.channelID, ns, coll, keys[i], txID)
+			} else {
+				v = &storeapi.ExpiringValue{Value: value.Value, Expiry: value.ExpiryTime}
+			}
+		}
+		ret = append(ret, v)
+	}
+
+	return ret, nil
+}
+
+func (s *store) createBatch(txID, ns string, config *cb.StaticCollectionConfig, collRWSet *rwsetutil.CollPvtRwSet, expiryTime time.Time) ([]*api.KeyValue, error) {
+	var batch []*api.KeyValue
+	for _, wSet := range collRWSet.KvRwSet.Writes {
+		if wSet.IsDelete {
+			return nil, errors.Errorf("[%s] Attempt to delete key [%s] in collection [%s:%s]", s.channelID, wSet.Key, ns, collRWSet.CollectionName)
+		}
+
+		key := storeapi.NewKey(txID, ns, collRWSet.CollectionName, wSet.Key)
+		value := &storeapi.ExpiringValue{
+			Value:  wSet.Value,
+			Expiry: expiryTime,
+		}
+
+		key, value, err := s.decorate(config, key, value)
+		if err != nil {
+			return nil, err
+		}
+
+		batch = append(batch, api.NewKeyValue(key.Key, value.Value, txID, value.Expiry))
+	}
+	return batch, nil
+}
+
+func (s *store) isAuthorized(ns string, config *common.StaticCollectionConfig) (bool, error) {
+	policy, err := s.loadPolicy(ns, config)
+	if err != nil {
+		logger.Errorf("[%s] Error loading policy for collection [%s:%s]: %s", s.channelID, ns, config.Name, err)
+		return false, err
+	}
+
+	localMSPID, err := getLocalMSPID()
+	if err != nil {
+		logger.Errorf("[%s] Error getting local MSP ID: %s", s.channelID, err)
+		return false, err
+	}
+	for _, mspID := range policy.MemberOrgs() {
+		if mspID == localMSPID {
+			return true, nil
+		}
+	}
+	return false, nil
+}
+
+// TODO: Consider caching policies to avoid marshalling every time
+func (s *store) loadPolicy(ns string, config *common.StaticCollectionConfig) (privdata.CollectionAccessPolicy, error) {
+	logger.Debugf("[%s] Loading collection policy for [%s:%s]", s.channelID, ns, config.Name)
+
+	colAP := &privdata.SimpleCollection{}
+	err := colAP.Setup(config, mspmgmt.GetIdentityDeserializer(s.channelID))
+	if err != nil {
+		return nil, errors.Wrapf(err, "error setting up collection policy %s", config.Name)
+	}
+
+	return colAP, nil
+}
+
+func (s *store) getExpirationTime(config *common.StaticCollectionConfig) (time.Time, error) {
+	var expiryTime time.Time
+	if config.TimeToLive == "" {
+		return expiryTime, nil
+	}
+	ttl, e := time.ParseDuration(config.TimeToLive)
+	if e != nil {
+		// This shouldn't happen since the config was validated before being persisted
+		return expiryTime, errors.Wrapf(e, "error parsing time-to-live for collection [%s]", config.Name)
+	}
+	return time.Now().Add(ttl), nil
+}
+
+func (s *store) getCollectionConfig(collConfigPkgs map[string]*common.CollectionConfigPackage, namespace, collName string) (*common.StaticCollectionConfig, bool) {
+	collConfigPkg, ok := collConfigPkgs[namespace]
+	if !ok {
+		return nil, false
+	}
+
+	for _, collConfig := range collConfigPkg.Config {
+		config := collConfig.GetStaticCollectionConfig()
+		if config != nil && config.Name == collName && s.collTypeSupported(config.Type) {
+			return config, true
+		}
+	}
+
+	return nil, false
+}
+
+func (s *store) decorate(config *cb.StaticCollectionConfig, key *storeapi.Key, value *storeapi.ExpiringValue) (*storeapi.Key, *storeapi.ExpiringValue, error) {
+	cfg, ok := s.collConfigs[config.Type]
+	if !ok || cfg.decorator == nil {
+		return key, value, nil
+	}
+	return cfg.decorator(key, value)
+}
+
+func (s *store) collTypeSupported(collType cb.CollectionType) bool {
+	_, ok := s.collConfigs[collType]
+	return ok
+}
+
+// getLocalMSPID returns the MSP ID of the local peer. This variable may be overridden by unit tests.
+var getLocalMSPID = func() (string, error) {
+	return mspmgmt.GetLocalMSP().GetIdentifier()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstoreprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstoreprovider.go
new file mode 100644
index 00000000..0b94ea9e
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstoreprovider.go
@@ -0,0 +1,108 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	"sync"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	"github.com/hyperledger/fabric/protos/common"
+	olapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore"
+)
+
+// Option is a store provider option
+type Option func(p *StoreProvider)
+
+// CollOption is a collection option
+type CollOption func(c *collTypeConfig)
+
+// WithCollectionType adds a collection type to the set of collection types supported by the off-ledger store
+// along with any options
+func WithCollectionType(collType common.CollectionType, opts ...CollOption) Option {
+	return func(p *StoreProvider) {
+		c := &collTypeConfig{}
+		p.collConfigs[collType] = c
+
+		for _, opt := range opts {
+			opt(c)
+		}
+	}
+}
+
+// Decorator allows the key/value to be modified before being persisted
+type Decorator func(key *storeapi.Key, value *storeapi.ExpiringValue) (*storeapi.Key, *storeapi.ExpiringValue, error)
+
+// WithDecorator sets a decorator for a collection type allowing the key/value to be modified before being persisted
+func WithDecorator(decorator Decorator) CollOption {
+	return func(c *collTypeConfig) {
+		c.decorator = decorator
+	}
+}
+
+type collTypeConfig struct {
+	decorator Decorator
+}
+
+// New returns a store provider factory
+func New(opts ...Option) *StoreProvider {
+	p := &StoreProvider{
+		stores:      make(map[string]olapi.Store),
+		dbProvider:  getDBProvider(),
+		collConfigs: make(map[common.CollectionType]*collTypeConfig),
+	}
+
+	// OFF_LEDGER collection type supported by default
+	opts = append(opts, WithCollectionType(common.CollectionType_COL_OFFLEDGER))
+
+	// Apply options
+	for _, opt := range opts {
+		opt(p)
+	}
+	return p
+}
+
+// StoreProvider is a store provider
+type StoreProvider struct {
+	stores map[string]olapi.Store
+	sync.RWMutex
+	dbProvider  api.DBProvider
+	collConfigs map[common.CollectionType]*collTypeConfig
+}
+
+// StoreForChannel returns the store for the given channel
+func (sp *StoreProvider) StoreForChannel(channelID string) olapi.Store {
+	sp.RLock()
+	defer sp.RUnlock()
+	return sp.stores[channelID]
+}
+
+// OpenStore opens the store for the given channel
+func (sp *StoreProvider) OpenStore(channelID string) (olapi.Store, error) {
+	sp.Lock()
+	defer sp.Unlock()
+
+	store, ok := sp.stores[channelID]
+	if !ok {
+		store = newStore(channelID, sp.dbProvider, sp.collConfigs)
+		sp.stores[channelID] = store
+	}
+	return store, nil
+}
+
+// Close shuts down all of the stores
+func (sp *StoreProvider) Close() {
+	for _, s := range sp.stores {
+		s.Close()
+	}
+}
+
+// getDBProvider returns the DB provider. This var may be overridden by unit tests
+var getDBProvider = func() api.DBProvider {
+	return couchdbstore.NewDBProvider()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api/api.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api/api.go
new file mode 100644
index 00000000..e5fc5fda
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api/api.go
@@ -0,0 +1,61 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package api
+
+import (
+	"time"
+)
+
+// Value is a data value
+type Value struct {
+	Value      []byte
+	TxID       string
+	ExpiryTime time.Time
+}
+
+// KeyValue is a struct to store a key value pair
+type KeyValue struct {
+	*Value
+	Key string
+}
+
+// NewKeyValue returns a new key
+func NewKeyValue(key string, value []byte, txID string, expiryTime time.Time) *KeyValue {
+	return &KeyValue{
+		Key:   key,
+		Value: &Value{Value: value, TxID: txID, ExpiryTime: expiryTime},
+	}
+}
+
+// String returns the string representation of the key
+func (k *KeyValue) String() string {
+	return k.Key
+}
+
+// DB persists collection data.
+type DB interface {
+	// Put stores the given set of keys/values. If expiry time is 0 then the data lives forever.
+	Put(keyVal ...*KeyValue) error
+
+	// Get returns the value for the given key or nil if the key doesn't exist
+	Get(key string) (*Value, error)
+
+	// Get returns the values for multiple keys. The values are returned in the same order as the keys.
+	GetMultiple(keys ...string) ([]*Value, error)
+
+	// DeleteExpiredKeys deletes all of the expired keys
+	DeleteExpiredKeys() error
+}
+
+// DBProvider returns the persister for the given namespace/collection
+type DBProvider interface {
+	// GetDB return the DB for the given namespace/collection
+	GetDB(ns, coll string) (DB, error)
+
+	// Close closes the DB provider
+	Close()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache/cache.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache/cache.go
new file mode 100644
index 00000000..abaad49c
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache/cache.go
@@ -0,0 +1,159 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cache
+
+import (
+	"fmt"
+	"time"
+
+	"github.com/bluele/gcache"
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api"
+)
+
+var logger = flogging.MustGetLogger("ext_offledger")
+
+// Cache implements a cache for collection data
+type Cache struct {
+	channelID  string
+	cache      gcache.Cache
+	dbProvider api.DBProvider
+}
+
+type cacheKey struct {
+	namespace  string
+	collection string
+	key        string
+}
+
+func (k cacheKey) String() string {
+	return fmt.Sprintf("%s:%s:%s", k.namespace, k.collection, k.key)
+}
+
+// New returns a new collection data cache
+func New(channelID string, dbProvider api.DBProvider, size int) *Cache {
+	c := &Cache{
+		channelID:  channelID,
+		dbProvider: dbProvider,
+	}
+	c.cache = gcache.New(size).ARC().LoaderExpireFunc(
+		func(k interface{}) (interface{}, *time.Duration, error) {
+			key := k.(cacheKey)
+			v, remainingTime, err := c.load(key)
+			if err != nil {
+				logger.Warningf("[%s] Error loading key [%s]: %s", c.channelID, key, err)
+				return nil, nil, err
+			}
+			return v, remainingTime, nil
+		}).Build()
+	return c
+}
+
+// Put adds the value for the given key.
+func (c *Cache) Put(ns, coll, key string, value *api.Value) {
+	cKey := cacheKey{
+		namespace:  ns,
+		collection: coll,
+		key:        key,
+	}
+
+	var err error
+	if value.ExpiryTime.IsZero() {
+		logger.Debugf("[%s] Putting key [%s]. Expires: NEVER", c.channelID, cKey)
+		err = c.cache.Set(cKey, value)
+	} else if value.ExpiryTime.Before(time.Now()) {
+		logger.Debugf("[%s] Expiry time for key [%s] occurs in the past. Value will not be added", c.channelID, cKey)
+	} else {
+		logger.Debugf("[%s] Putting key [%s]. Expires: %s", c.channelID, cKey, value.ExpiryTime)
+		err = c.cache.SetWithExpire(cKey, value, time.Until(value.ExpiryTime))
+	}
+
+	if err != nil {
+		panic("Set must never return an error")
+	}
+}
+
+// Get returns the values for the given keys
+func (c *Cache) Get(ns, coll, key string) (*api.Value, error) {
+	cKey := cacheKey{
+		namespace:  ns,
+		collection: coll,
+		key:        key,
+	}
+
+	value, err := c.cache.Get(cKey)
+	if err != nil {
+		logger.Warningf("[%s] Error getting key [%s]: %s", c.channelID, cKey, err)
+		return nil, err
+	}
+
+	if value == nil {
+		logger.Debugf("[%s] Key not found [%s]", c.channelID, cKey)
+		return nil, nil
+	}
+
+	v, ok := value.(*api.Value)
+	if !ok {
+		panic("Invalid value type!")
+	}
+	if v == nil {
+		logger.Debugf("[%s] Key not found [%s]", c.channelID, cKey)
+		return nil, nil
+	}
+
+	logger.Debugf("[%s] Got key [%s]. Expires: %s", c.channelID, cKey, v.ExpiryTime)
+	return v, nil
+}
+
+// GetMultiple returns the values for the given keys
+func (c *Cache) GetMultiple(ns, coll string, keys ...string) ([]*api.Value, error) {
+	values := make([]*api.Value, len(keys))
+	for i, key := range keys {
+		value, err := c.Get(ns, coll, key)
+		if err != nil {
+			return nil, err
+		}
+		values[i] = value
+	}
+	return values, nil
+}
+
+func (c *Cache) load(key cacheKey) (*api.Value, *time.Duration, error) {
+	db, err := c.dbProvider.GetDB(key.namespace, key.collection)
+	if err != nil {
+		return nil, nil, errors.WithMessage(err, "error getting database")
+	}
+
+	logger.Debugf("Loading value for key %s from DB", key)
+	v, err := db.Get(key.key)
+	if err != nil {
+		return nil, nil, errors.WithMessage(err, "error loading value")
+	}
+
+	logger.Debugf("Loaded value %v for key %s from DB", v, key)
+	if v == nil {
+		logger.Debugf("[%s] Value not found for key [%s]", c.channelID, key)
+		return nil, nil, nil
+	}
+
+	logger.Debugf("Checking expiry time for key %s", key)
+	if v.ExpiryTime.IsZero() {
+		logger.Debugf("[%s] Loaded key [%s]. Expires: NEVER", c.channelID, key)
+		return v, nil, nil
+
+	}
+	remainingTime := time.Until(v.ExpiryTime)
+	if remainingTime < 0 {
+		// Already expired
+		logger.Debugf("[%s] Loaded key [%s]. Expires: NOW", c.channelID, key)
+		return nil, nil, nil
+	}
+
+	logger.Debugf("[%s] Loaded key [%s]. Expires: %s", c.channelID, key, v.ExpiryTime)
+	return v, &remainingTime, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore.go
new file mode 100644
index 00000000..9b0fe525
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore.go
@@ -0,0 +1,212 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package couchdbstore
+
+import (
+	"encoding/json"
+	"fmt"
+	"time"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api"
+)
+
+var (
+	logger          = flogging.MustGetLogger("ext_offledger")
+	compositeKeySep = "!"
+)
+
+const (
+	fetchExpiryDataQuery = `
+	{
+		"selector": {
+			"` + expiryField + `": {
+				"$lt": %v
+			}
+		},
+		"use_index": ["_design/` + expiryIndexDoc + `", "` + expiryIndexName + `"]
+	}`
+)
+
+// dataModel couch doc dataModel
+type dataModel struct {
+	ID      string `json:"_id"`
+	Rev     string `json:"_rev,omitempty"`
+	Data    string `json:"dataModel"`
+	TxnID   string `json:"txnID"`
+	Expiry  int64  `json:"expiry"`
+	Deleted bool   `json:"_deleted"`
+}
+
+type dbstore struct {
+	dbName string
+	db     *couchdb.CouchDatabase
+}
+
+// newDBStore constructs an instance of db store
+func newDBStore(db *couchdb.CouchDatabase, dbName string) *dbstore {
+	return &dbstore{dbName, db}
+}
+
+//-----------------Interface implementation functions--------------------//
+// AddKey adds dataModel to db
+func (s *dbstore) Put(keyVal ...*api.KeyValue) error {
+	docs := make([]*couchdb.CouchDoc, 0)
+	for _, kv := range keyVal {
+
+		dataDoc, err := createCouchDoc(string(encodeKey(kv.Key, time.Time{})), kv.Value)
+		if err != nil {
+			return err
+		}
+		if dataDoc != nil {
+			docs = append(docs, dataDoc)
+		}
+	}
+
+	_, err := s.db.BatchUpdateDocuments(docs)
+	if nil != err {
+		return errors.WithMessage(err, fmt.Sprintf("BatchUpdateDocuments failed for [%d] documents", len(docs)))
+	}
+
+	return nil
+}
+
+// GetKey get dataModel based on key from db
+func (s *dbstore) Get(key string) (*api.Value, error) {
+	data, err := fetchData(s.db, string(encodeKey(key, time.Time{})))
+	if err != nil {
+		return nil, errors.Wrapf(err, "Failed to load key [%s] from db", key)
+	}
+
+	if data != nil {
+		val := &api.Value{Value: []byte(data.Data), TxID: data.TxnID, ExpiryTime: time.Unix(0, data.Expiry)}
+		return val, nil
+	}
+
+	return nil, nil
+}
+
+// GetMultiple retrieves values for multiple keys at once
+func (s *dbstore) GetMultiple(keys ...string) ([]*api.Value, error) {
+	values := make([]*api.Value, len(keys))
+	for i, k := range keys {
+		v, err := s.Get(k)
+		if err != nil {
+			return nil, err
+		}
+		values[i] = v
+	}
+
+	return values, nil
+}
+
+// DeleteExpiredKeys delete expired keys from db
+func (s *dbstore) DeleteExpiredKeys() error {
+	data, err := fetchExpiryData(s.db, time.Now())
+	if err != nil {
+		return err
+	}
+	if len(data) == 0 {
+		logger.Debugf("No keys to delete from db")
+		return nil
+	}
+
+	docs := make([]*couchdb.CouchDoc, 0)
+	docIDs := make([]string, 0)
+	for _, doc := range data {
+		updateDoc := &dataModel{ID: doc.ID, Data: doc.Data, TxnID: doc.TxnID, Expiry: doc.Expiry, Rev: doc.Rev, Deleted: true}
+		jsonBytes, err := json.Marshal(updateDoc)
+		if err != nil {
+			return err
+		}
+		couchDoc := couchdb.CouchDoc{JSONValue: jsonBytes}
+		docs = append(docs, &couchDoc)
+		docIDs = append(docIDs, updateDoc.ID)
+	}
+
+	if len(docs) > 0 {
+		_, err := s.db.BatchUpdateDocuments(docs)
+		if err != nil {
+			return errors.WithMessage(err, fmt.Sprintf("BatchUpdateDocuments failed for [%d] documents", len(docs)))
+		}
+		logger.Debugf("Deleted expired keys %s from db", docIDs)
+	}
+
+	return nil
+}
+
+// Close db
+func (s *dbstore) Close() {
+}
+
+//-----------------helper functions--------------------//
+func encodeKey(key string, expiryTime time.Time) []byte {
+	var compositeKey []byte
+	if !expiryTime.IsZero() {
+		compositeKey = append(compositeKey, []byte(fmt.Sprintf("%d", expiryTime.UnixNano()/int64(time.Millisecond)))...)
+		compositeKey = append(compositeKey, compositeKeySep...)
+	}
+	compositeKey = append(compositeKey, []byte(key)...)
+	return compositeKey
+}
+
+//-----------------database helper functions--------------------//
+func fetchData(db *couchdb.CouchDatabase, key string) (*dataModel, error) {
+	doc, _, err := db.ReadDoc(key)
+	if err != nil {
+		return nil, err
+	}
+
+	if doc == nil {
+		return nil, nil
+	}
+
+	var data dataModel
+	err = json.Unmarshal(doc.JSONValue, &data)
+	if err != nil {
+		return nil, errors.Wrapf(err, "Result from DB is not JSON encoded")
+	}
+
+	return &data, nil
+}
+
+func createCouchDoc(key string, value *api.Value) (*couchdb.CouchDoc, error) {
+	data := &dataModel{ID: key, Data: string(value.Value), TxnID: value.TxID, Expiry: value.ExpiryTime.UnixNano() / int64(time.Millisecond)}
+
+	jsonBytes, err := json.Marshal(data)
+	if err != nil {
+		return nil, errors.Wrapf(err, "result from DB is not JSON encoded")
+	}
+
+	couchDoc := couchdb.CouchDoc{JSONValue: jsonBytes}
+
+	return &couchDoc, nil
+}
+
+func fetchExpiryData(db *couchdb.CouchDatabase, expiry time.Time) ([]*dataModel, error) {
+	results, _, err := db.QueryDocuments(fmt.Sprintf(fetchExpiryDataQuery, expiry.UnixNano()/int64(time.Millisecond)))
+	if err != nil {
+		return nil, err
+	}
+
+	if len(results) == 0 {
+		return nil, nil
+	}
+
+	var responses []*dataModel
+	for _, result := range results {
+		var data dataModel
+		err = json.Unmarshal(result.Value, &data)
+		if err != nil {
+			return nil, errors.Wrapf(err, "result from DB is not JSON encoded")
+		}
+		responses = append(responses, &data)
+	}
+
+	return responses, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore_provider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore_provider.go
new file mode 100644
index 00000000..bf4391ed
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore_provider.go
@@ -0,0 +1,145 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package couchdbstore
+
+import (
+	"fmt"
+	"sync"
+	"time"
+
+	"github.com/hyperledger/fabric/common/metrics/disabled"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+)
+
+const (
+	expiryField     = "expiry"
+	expiryIndexName = "by_expiry"
+	expiryIndexDoc  = "indexExpiry"
+	expiryIndexDef  = `
+	{
+		"index": {
+			"fields": ["` + expiryField + `"]
+		},
+		"name": "` + expiryIndexName + `",
+		"ddoc": "` + expiryIndexDoc + `",
+		"type": "json"
+	}`
+)
+
+// CouchDBProvider provides an handle to a db
+type CouchDBProvider struct {
+	couchInstance *couchdb.CouchInstance
+	stores        map[string]*dbstore
+	mutex         sync.RWMutex
+	done          chan struct{}
+	closed        bool
+}
+
+// NewDBProvider creates a CouchDB Provider
+func NewDBProvider() *CouchDBProvider {
+	couchDBDef := couchdb.GetCouchDBDefinition()
+
+	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	if err != nil {
+		logger.Error(err)
+		return nil
+	}
+
+	p := &CouchDBProvider{
+		couchInstance: couchInstance,
+		done:          make(chan struct{}),
+		stores:        make(map[string]*dbstore),
+	}
+
+	p.periodicPurge()
+
+	return p
+}
+
+//GetDB based on ns%coll
+func (p *CouchDBProvider) GetDB(ns, coll string) (api.DB, error) {
+	dbName := dbName(ns, coll)
+
+	p.mutex.RLock()
+	s, ok := p.stores[dbName]
+	p.mutex.RUnlock()
+
+	if ok {
+		return s, nil
+	}
+
+	p.mutex.Lock()
+	defer p.mutex.Unlock()
+
+	if !ok {
+		db, err := couchdb.CreateCouchDatabase(p.couchInstance, dbName)
+		if nil != err {
+			logger.Error(err)
+			return nil, nil
+		}
+		s = newDBStore(db, dbName)
+
+		err = db.CreateNewIndexWithRetry(expiryIndexDef, expiryIndexDoc)
+		if err != nil {
+			return nil, err
+		}
+		p.stores[dbName] = s
+	}
+
+	return s, nil
+}
+
+// Close cleans up the Provider
+func (p *CouchDBProvider) Close() {
+	p.mutex.RLock()
+	defer p.mutex.RUnlock()
+
+	if !p.closed {
+		p.done <- struct{}{}
+		p.closed = true
+	}
+}
+
+// periodicPurge goroutine to purge dataModel based on config interval time
+func (p *CouchDBProvider) periodicPurge() {
+	ticker := time.NewTicker(config.GetOLCollExpirationCheckInterval())
+	go func() {
+		defer ticker.Stop()
+		for {
+			select {
+			case <-ticker.C:
+				for _, s := range p.getStores() {
+					err := s.DeleteExpiredKeys()
+					if err != nil {
+						logger.Errorf("Error deleting expired keys for [%s]", s.dbName)
+					}
+				}
+			case <-p.done:
+				logger.Infof("Periodic purge is exiting")
+				return
+			}
+		}
+	}()
+}
+
+// getStores retrieves dbstores contained in the provider
+func (p *CouchDBProvider) getStores() []*dbstore {
+	p.mutex.RLock()
+	defer p.mutex.RUnlock()
+
+	var stores []*dbstore
+	for _, s := range p.stores {
+		stores = append(stores, s)
+	}
+	return stores
+}
+
+func dbName(ns, coll string) string {
+	return fmt.Sprintf("%s$%s", ns, coll)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatahandler/pvtdatahandler.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatahandler/pvtdatahandler.go
new file mode 100644
index 00000000..859eaf23
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatahandler/pvtdatahandler.go
@@ -0,0 +1,156 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatahandler
+
+import (
+	"context"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+)
+
+var logger = flogging.MustGetLogger("ext_pvtdatahandler")
+
+// Handler handles the retrieval of kevlar-defined collection types
+type Handler struct {
+	channelID        string
+	collDataProvider storeapi.Provider
+}
+
+// New returns a new Handler
+func New(channelID string, collDataProvider storeapi.Provider) *Handler {
+	return &Handler{
+		channelID:        channelID,
+		collDataProvider: collDataProvider,
+	}
+}
+
+// HandleGetPrivateData if the collection is one of the custom Kevlar collections then the private data is returned
+func (h *Handler) HandleGetPrivateData(txID, ns string, config *common.StaticCollectionConfig, key string) ([]byte, bool, error) {
+	switch config.Type {
+	case common.CollectionType_COL_TRANSIENT:
+		logger.Debugf("Collection [%s:%s] is of type TransientData. Returning transient data for key [%s]", ns, config.Name, key)
+		value, err := h.getTransientData(txID, ns, config.Name, key)
+		if err != nil {
+			return nil, true, err
+		}
+		return value, true, nil
+	case common.CollectionType_COL_DCAS:
+		fallthrough
+	case common.CollectionType_COL_OFFLEDGER:
+		logger.Debugf("Collection [%s:%s] is an off-ledger store. Returning data for key [%s]", ns, config.Name, key)
+		value, err := h.getData(txID, ns, config.Name, key)
+		if err != nil {
+			return nil, true, err
+		}
+		return value, true, nil
+	default:
+		return nil, false, nil
+	}
+}
+
+// HandleGetPrivateDataMultipleKeys if the collection is one of the custom Kevlar collections then the private data is returned
+func (h *Handler) HandleGetPrivateDataMultipleKeys(txID, ns string, config *common.StaticCollectionConfig, keys []string) ([][]byte, bool, error) {
+	switch config.Type {
+	case common.CollectionType_COL_TRANSIENT:
+		logger.Debugf("Collection [%s:%s] is of type TransientData. Returning transient data for keys [%s]", ns, config.Name, keys)
+		values, err := h.getTransientDataMultipleKeys(txID, ns, config.Name, keys)
+		if err != nil {
+			return nil, true, err
+		}
+		return values, true, nil
+	case common.CollectionType_COL_DCAS:
+		fallthrough
+	case common.CollectionType_COL_OFFLEDGER:
+		logger.Debugf("Collection [%s:%s] is of an off-ledger store. Returning data for keys [%s]", ns, config.Name, keys)
+		values, err := h.getDataMultipleKeys(txID, ns, config.Name, keys)
+		if err != nil {
+			return nil, true, err
+		}
+		return values, true, nil
+	default:
+		return nil, false, nil
+	}
+}
+
+func (h *Handler) getTransientData(txID, ns, coll, key string) ([]byte, error) {
+	ctxt, cancel := context.WithTimeout(context.Background(), config.GetTransientDataPullTimeout())
+	defer cancel()
+
+	v, err := h.collDataProvider.RetrieverForChannel(h.channelID).
+		GetTransientData(ctxt, storeapi.NewKey(txID, ns, coll, key))
+	if err != nil {
+		return nil, err
+	}
+
+	if v == nil {
+		return nil, nil
+	}
+
+	return v.Value, nil
+}
+
+func (h *Handler) getTransientDataMultipleKeys(txID, ns, coll string, keys []string) ([][]byte, error) {
+	ctxt, cancel := context.WithTimeout(context.Background(), config.GetTransientDataPullTimeout())
+	defer cancel()
+
+	vals, err := h.collDataProvider.RetrieverForChannel(h.channelID).
+		GetTransientDataMultipleKeys(ctxt, storeapi.NewMultiKey(txID, ns, coll, keys...))
+	if err != nil {
+		return nil, err
+	}
+
+	values := make([][]byte, len(vals))
+	for i, v := range vals {
+		if v == nil {
+			values[i] = nil
+		} else {
+			values[i] = v.Value
+		}
+	}
+	return values, nil
+}
+
+func (h *Handler) getData(txID, ns, coll, key string) ([]byte, error) {
+	ctxt, cancel := context.WithTimeout(context.Background(), config.GetOLCollPullTimeout())
+	defer cancel()
+
+	v, err := h.collDataProvider.RetrieverForChannel(h.channelID).
+		GetData(ctxt, storeapi.NewKey(txID, ns, coll, key))
+	if err != nil {
+		return nil, err
+	}
+
+	if v == nil {
+		return nil, nil
+	}
+
+	return v.Value, nil
+}
+
+func (h *Handler) getDataMultipleKeys(txID, ns, coll string, keys []string) ([][]byte, error) {
+	ctxt, cancel := context.WithTimeout(context.Background(), config.GetOLCollPullTimeout())
+	defer cancel()
+
+	vals, err := h.collDataProvider.RetrieverForChannel(h.channelID).
+		GetDataMultipleKeys(ctxt, storeapi.NewMultiKey(txID, ns, coll, keys...))
+	if err != nil {
+		return nil, err
+	}
+
+	values := make([][]byte, len(vals))
+	for i, v := range vals {
+		if v == nil {
+			values[i] = nil
+		} else {
+			values[i] = v.Value
+		}
+	}
+	return values, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatastore/pvtdatastore.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatastore/pvtdatastore.go
new file mode 100644
index 00000000..50d69e45
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/pvtdatastore/pvtdatastore.go
@@ -0,0 +1,190 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatastore
+
+import (
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/rwsetutil"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/hyperledger/fabric/protos/transientstore"
+	"github.com/pkg/errors"
+)
+
+var logger = flogging.MustGetLogger("ext_pvtdatastore")
+
+type transientStore interface {
+	// PersistWithConfig stores the private write set of a transaction along with the collection config
+	// in the transient store based on txid and the block height the private data was received at
+	PersistWithConfig(txid string, blockHeight uint64, privateSimulationResultsWithConfig *transientstore.TxPvtReadWriteSetWithConfigInfo) error
+}
+
+// Store persists private data from collection R/W sets
+type Store struct {
+	channelID      string
+	transientStore transientStore
+	collDataStore  storeapi.Store
+}
+
+// New returns a new Store
+func New(channelID string, transientStore transientStore, collDataStore storeapi.Store) *Store {
+	return &Store{
+		channelID:      channelID,
+		transientStore: transientStore,
+		collDataStore:  collDataStore,
+	}
+}
+
+// StorePvtData used to persist private date into transient and/or extended collection store(s)
+func (c *Store) StorePvtData(txID string, privData *transientstore.TxPvtReadWriteSetWithConfigInfo, blkHeight uint64) error {
+	// Filter out all of the R/W sets that are not to be persisted to the ledger, i.e. we just
+	// want the regular private data R/W sets
+	pvtRWSet, err := newPvtRWSetFilter(c.channelID, txID, blkHeight, privData).apply()
+	if err != nil {
+		logger.Errorf("[%s:%d:%s] Unable to extract transient r/w set from private data: %s", c.channelID, blkHeight, txID, err)
+		return err
+	}
+
+	// Persist the extended collection data (this includes Transient Data, etc.)
+	err = c.collDataStore.Persist(txID, privData)
+	if err != nil {
+		logger.Errorf("[%s:%d:%s] Unable to persist collection data: %s", c.channelID, blkHeight, txID, err)
+		return err
+	}
+
+	if pvtRWSet == nil {
+		logger.Debugf("[%s:%d:%s] Nothing to persist to transient store", c.channelID, blkHeight, txID)
+		return nil
+	}
+
+	logger.Debugf("[%s:%d:%s] Persisting private data to transient store", c.channelID, blkHeight, txID)
+
+	return c.transientStore.PersistWithConfig(
+		txID, blkHeight,
+		&transientstore.TxPvtReadWriteSetWithConfigInfo{
+			PvtRwset:          pvtRWSet,
+			CollectionConfigs: privData.CollectionConfigs,
+			EndorsedAt:        privData.EndorsedAt,
+		})
+}
+
+// pvtRWSetFilter filters out all of the R/W sets that are not to be persisted to the ledger,
+// i.e. we just want the regular private data R/W sets
+type pvtRWSetFilter struct {
+	channelID string
+	txID      string
+	blkHeight uint64
+	privData  *transientstore.TxPvtReadWriteSetWithConfigInfo
+}
+
+func newPvtRWSetFilter(channelID, txID string, blkHeight uint64, privData *transientstore.TxPvtReadWriteSetWithConfigInfo) *pvtRWSetFilter {
+	return &pvtRWSetFilter{
+		channelID: channelID,
+		txID:      txID,
+		blkHeight: blkHeight,
+		privData:  privData,
+	}
+}
+
+func (f *pvtRWSetFilter) apply() (*rwset.TxPvtReadWriteSet, error) {
+	txPvtRWSet, err := rwsetutil.TxPvtRwSetFromProtoMsg(f.privData.PvtRwset)
+	if err != nil {
+		return nil, errors.New("error getting pvt RW set from bytes")
+	}
+
+	nsPvtRwSet, modified, err := f.extractPvtRWSets(txPvtRWSet.NsPvtRwSet)
+	if err != nil {
+		return nil, err
+	}
+	if !modified {
+		logger.Debugf("[%s:%d:%s] Rewrite to NsPvtRwSet not required for transient store", f.channelID, f.blkHeight, f.txID)
+		return f.privData.PvtRwset, nil
+	}
+	if len(nsPvtRwSet) == 0 {
+		logger.Debugf("[%s:%d:%s] Didn't find any private data to persist to transient store", f.channelID, f.blkHeight, f.txID)
+		return nil, nil
+	}
+
+	logger.Debugf("[%s:%d:%s] Rewriting NsPvtRwSet for transient store", f.channelID, f.blkHeight, f.txID)
+	txPvtRWSet.NsPvtRwSet = nsPvtRwSet
+	newPvtRwset, err := txPvtRWSet.ToProtoMsg()
+	if err != nil {
+		return nil, errors.WithMessage(err, "error marshalling private data r/w set")
+	}
+
+	logger.Debugf("[%s:%d:%s] Rewriting private data r/w set since it was modified", f.channelID, f.blkHeight, f.txID)
+	return newPvtRwset, nil
+}
+
+func (f *pvtRWSetFilter) extractPvtRWSets(srcNsPvtRwSets []*rwsetutil.NsPvtRwSet) ([]*rwsetutil.NsPvtRwSet, bool, error) {
+	modified := false
+	var nsPvtRWSets []*rwsetutil.NsPvtRwSet
+	for _, nsRWSet := range srcNsPvtRwSets {
+		collPvtRwSets, err := f.extractPvtCollPvtRWSets(nsRWSet)
+		if err != nil {
+			return nil, false, err
+		}
+		if len(collPvtRwSets) != len(nsRWSet.CollPvtRwSets) {
+			modified = true
+		}
+		if len(collPvtRwSets) > 0 {
+			if len(collPvtRwSets) != len(nsRWSet.CollPvtRwSets) {
+				logger.Debugf("[%s:%d:%s] Rewriting collections for [%s] in transient store", f.channelID, f.blkHeight, f.txID, nsRWSet.NameSpace)
+				nsRWSet.CollPvtRwSets = collPvtRwSets
+				modified = true
+			} else {
+				logger.Debugf("[%s:%d:%s] Not touching collections for [%s] in transient store", f.channelID, f.blkHeight, f.txID, nsRWSet.NameSpace)
+			}
+			logger.Debugf("[%s:%d:%s] Adding NsPvtRwSet for [%s] in transient store", f.channelID, f.blkHeight, f.txID, nsRWSet.NameSpace)
+			nsPvtRWSets = append(nsPvtRWSets, nsRWSet)
+		} else {
+			logger.Debugf("[%s:%d:%s] NOT adding NsPvtRwSet for [%s] in transient store since no private data collections found", f.channelID, f.blkHeight, f.txID, nsRWSet.NameSpace)
+		}
+	}
+	return nsPvtRWSets, modified, nil
+}
+
+func (f *pvtRWSetFilter) extractPvtCollPvtRWSets(nsPvtRWSet *rwsetutil.NsPvtRwSet) ([]*rwsetutil.CollPvtRwSet, error) {
+	var filteredCollPvtRwSets []*rwsetutil.CollPvtRwSet
+	for _, collRWSet := range nsPvtRWSet.CollPvtRwSets {
+		ok, e := f.isPvtData(nsPvtRWSet.NameSpace, collRWSet.CollectionName)
+		if e != nil {
+			return nil, errors.WithMessage(e, "error in collection config")
+		}
+		if !ok {
+			logger.Debugf("[%s:%d:%s] Not persisting collection [%s:%s] in transient store", f.channelID, f.blkHeight, f.txID, nsPvtRWSet.NameSpace, collRWSet.CollectionName)
+			continue
+		}
+		logger.Debugf("[%s:%d:%s] Persisting collection [%s:%s] in transient store", f.channelID, f.blkHeight, f.txID, nsPvtRWSet.NameSpace, collRWSet.CollectionName)
+		filteredCollPvtRwSets = append(filteredCollPvtRwSets, collRWSet)
+	}
+	return filteredCollPvtRwSets, nil
+}
+
+// isPvtData returns true if the given collection is a standard private data collection
+func (f *pvtRWSetFilter) isPvtData(ns, coll string) (bool, error) {
+	pkg, ok := f.privData.CollectionConfigs[ns]
+	if !ok {
+		return false, errors.Errorf("could not find collection configs for namespace [%s]", ns)
+	}
+
+	var config *common.StaticCollectionConfig
+	for _, c := range pkg.Config {
+		staticConfig := c.GetStaticCollectionConfig()
+		if staticConfig.Name == coll {
+			config = staticConfig
+			break
+		}
+	}
+
+	if config == nil {
+		return false, errors.Errorf("could not find collection config for collection [%s:%s]", ns, coll)
+	}
+
+	return config.Type == common.CollectionType_COL_UNKNOWN || config.Type == common.CollectionType_COL_PRIVATE, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/retriever.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/retriever.go
new file mode 100644
index 00000000..79d82e39
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/retriever.go
@@ -0,0 +1,123 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package retriever
+
+import (
+	"context"
+	"sync"
+
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/core/ledger"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	supportapi "github.com/hyperledger/fabric/extensions/collections/api/support"
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	cb "github.com/hyperledger/fabric/protos/common"
+	olapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas"
+	olretriever "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever"
+	tdataapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+	tretriever "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/retriever"
+	supp "github.com/trustbloc/fabric-peer-ext/pkg/common/support"
+)
+
+// Provider is a transient data provider.
+type Provider struct {
+	transientDataProvider tdataapi.Provider
+	offLedgerProvider     olapi.Provider
+	retrievers            map[string]*retriever
+	mutex                 sync.RWMutex
+}
+
+// NewProvider returns a new transient data Retriever provider
+func NewProvider(
+	storeProvider func(channelID string) storeapi.Store,
+	ledgerProvider func(channelID string) ledger.PeerLedger,
+	gossipProvider func() supportapi.GossipAdapter,
+	blockPublisherProvider func(channelID string) gossipapi.BlockPublisher) storeapi.Provider {
+
+	support := supp.New(ledgerProvider, blockPublisherProvider)
+
+	tdataStoreProvider := func(channelID string) tdataapi.Store { return storeProvider(channelID) }
+	offLedgerStoreProvider := func(channelID string) olapi.Store { return storeProvider(channelID) }
+
+	return &Provider{
+		transientDataProvider: getTransientDataProvider(tdataStoreProvider, support, gossipProvider),
+		offLedgerProvider:     getOffLedgerProvider(offLedgerStoreProvider, support, gossipProvider),
+		retrievers:            make(map[string]*retriever),
+	}
+}
+
+// RetrieverForChannel returns the collection retriever for the given channel
+func (p *Provider) RetrieverForChannel(channelID string) storeapi.Retriever {
+	p.mutex.RLock()
+	r, ok := p.retrievers[channelID]
+	p.mutex.RUnlock()
+
+	if ok {
+		return r
+	}
+
+	return p.getOrCreateRetriever(channelID)
+}
+
+func (p *Provider) getOrCreateRetriever(channelID string) storeapi.Retriever {
+	p.mutex.Lock()
+	defer p.mutex.Unlock()
+
+	r, ok := p.retrievers[channelID]
+	if !ok {
+		r = &retriever{
+			transientDataRetriever: p.transientDataProvider.RetrieverForChannel(channelID),
+			offLedgerRetriever:     p.offLedgerProvider.RetrieverForChannel(channelID),
+		}
+		p.retrievers[channelID] = r
+	}
+
+	return r
+}
+
+type retriever struct {
+	transientDataRetriever tdataapi.Retriever
+	offLedgerRetriever     olapi.Retriever
+}
+
+// GetTransientData returns the transient data for the given key
+func (r *retriever) GetTransientData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return r.transientDataRetriever.GetTransientData(ctxt, key)
+}
+
+// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+func (r *retriever) GetTransientDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	return r.transientDataRetriever.GetTransientDataMultipleKeys(ctxt, key)
+}
+
+// GetData gets the value for the given data item
+func (r *retriever) GetData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return r.offLedgerRetriever.GetData(ctxt, key)
+}
+
+// GetDataMultipleKeys gets the values for the multiple data items in a single call
+func (r *retriever) GetDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	return r.offLedgerRetriever.GetDataMultipleKeys(ctxt, key)
+}
+
+// Support defines the supporting functions required by the transient data provider
+type Support interface {
+	Config(channelID, ns, coll string) (*cb.StaticCollectionConfig, error)
+	Policy(channel, ns, collection string) (privdata.CollectionAccessPolicy, error)
+	BlockPublisher(channelID string) gossipapi.BlockPublisher
+}
+
+var getTransientDataProvider = func(storeProvider func(channelID string) tdataapi.Store, support Support, gossipProvider func() supportapi.GossipAdapter) tdataapi.Provider {
+	return tretriever.NewProvider(storeProvider, support, gossipProvider)
+}
+
+var getOffLedgerProvider = func(storeProvider func(channelID string) olapi.Store, support Support, gossipProvider func() supportapi.GossipAdapter) olapi.Provider {
+	return olretriever.NewProvider(storeProvider, support, gossipProvider,
+		olretriever.WithValidator(cb.CollectionType_COL_DCAS, dcas.Validator),
+	)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/test_exports.go
new file mode 100644
index 00000000..24cb1b36
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/test_exports.go
@@ -0,0 +1,25 @@
+// +build testing
+
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package retriever
+
+import (
+	supportapi "github.com/hyperledger/fabric/extensions/collections/api/support"
+	olapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api"
+	tdataapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+)
+
+// SetTransientDataProvider sets the transient data Retriever provider for unit tests
+func SetTransientDataProvider(provider func(storeProvider func(channelID string) tdataapi.Store, support Support, gossipProvider func() supportapi.GossipAdapter) tdataapi.Provider) {
+	getTransientDataProvider = provider
+}
+
+// SetOffLedgerProvider sets the off-ledger Retriever provider for unit tests
+func SetOffLedgerProvider(provider func(storeProvider func(channelID string) olapi.Store, support Support, gossipProvider func() supportapi.GossipAdapter) olapi.Provider) {
+	getOffLedgerProvider = provider
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/store.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/store.go
new file mode 100644
index 00000000..36854104
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/store.go
@@ -0,0 +1,86 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	cb "github.com/hyperledger/fabric/protos/common"
+	pb "github.com/hyperledger/fabric/protos/transientstore"
+	"github.com/pkg/errors"
+	olapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api"
+	tdapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+)
+
+type targetStores struct {
+	transientDataStore tdapi.Store
+	offLedgerStore     olapi.Store
+}
+
+type store struct {
+	channelID string
+	targetStores
+}
+
+func newDelegatingStore(channelID string, targets targetStores) *store {
+	return &store{
+		channelID:    channelID,
+		targetStores: targets,
+	}
+}
+
+// Persist persists all transient data within the private data simulation results
+func (d *store) Persist(txID string, privateSimulationResultsWithConfig *pb.TxPvtReadWriteSetWithConfigInfo) error {
+	if err := d.transientDataStore.Persist(txID, privateSimulationResultsWithConfig); err != nil {
+		return errors.WithMessage(err, "error persisting transient data")
+	}
+
+	// Off-ledger data should only be persisted on committers
+	if isCommitter() {
+		if err := d.offLedgerStore.Persist(txID, privateSimulationResultsWithConfig); err != nil {
+			return errors.WithMessage(err, "error persisting off-ledger data")
+		}
+	}
+
+	return nil
+}
+
+// GetTransientData returns the transient data for the given key
+func (d *store) GetTransientData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return d.transientDataStore.GetTransientData(key)
+}
+
+// GetTransientData returns the transient data for the given keys
+func (d *store) GetTransientDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	return d.transientDataStore.GetTransientDataMultipleKeys(key)
+}
+
+// GetData gets the value for the given key
+func (d *store) GetData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return d.offLedgerStore.GetData(key)
+}
+
+// PutData stores the key/value.
+func (d *store) PutData(config *cb.StaticCollectionConfig, key *storeapi.Key, value *storeapi.ExpiringValue) error {
+	return d.offLedgerStore.PutData(config, key, value)
+}
+
+// GetDataMultipleKeys gets the values for multiple keys in a single call
+func (d *store) GetDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	return d.offLedgerStore.GetDataMultipleKeys(key)
+}
+
+// Close closes all of the stores store
+func (d *store) Close() {
+	d.transientDataStore.Close()
+	d.offLedgerStore.Close()
+}
+
+// isCommitter may be overridden in unit tests
+var isCommitter = func() bool {
+	return roles.IsCommitter()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/storeprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/storeprovider.go
new file mode 100644
index 00000000..e56824a3
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/storeprovider.go
@@ -0,0 +1,92 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	"sync"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	cb "github.com/hyperledger/fabric/protos/common"
+	olapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas"
+	olstoreprovider "github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider"
+	tdapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider"
+)
+
+// New returns a new store provider factory
+func New() *StoreProvider {
+	return &StoreProvider{
+		transientDataProvider: newTransientDataProvider(),
+		olProvider:            newOffLedgerProvider(),
+		stores:                make(map[string]*store),
+	}
+}
+
+// StoreProvider is a store provider that creates delegating stores.
+// A delegating store delegates requests to collection-specific store.
+// For example, transient data store, Off-ledger store, etc.
+type StoreProvider struct {
+	transientDataProvider tdapi.StoreProvider
+	olProvider            olapi.StoreProvider
+	stores                map[string]*store
+	sync.RWMutex
+}
+
+// StoreForChannel returns the store for the given channel
+func (sp *StoreProvider) StoreForChannel(channelID string) storeapi.Store {
+	sp.RLock()
+	defer sp.RUnlock()
+	return sp.stores[channelID]
+}
+
+// OpenStore opens the store for the given channel
+func (sp *StoreProvider) OpenStore(channelID string) (storeapi.Store, error) {
+	sp.Lock()
+	defer sp.Unlock()
+
+	store, ok := sp.stores[channelID]
+	if !ok {
+		tdataStore, err := sp.transientDataProvider.OpenStore(channelID)
+		if err != nil {
+			return nil, err
+		}
+		olStore, err := sp.olProvider.OpenStore(channelID)
+		if err != nil {
+			return nil, err
+		}
+		store = newDelegatingStore(channelID,
+			targetStores{
+				transientDataStore: tdataStore,
+				offLedgerStore:     olStore,
+			},
+		)
+		sp.stores[channelID] = store
+	}
+	return store, nil
+}
+
+// Close shuts down all of the stores
+func (sp *StoreProvider) Close() {
+	for _, s := range sp.stores {
+		s.Close()
+	}
+}
+
+// newTransientDataProvider may be overridden in unit tests
+var newTransientDataProvider = func() tdapi.StoreProvider {
+	return storeprovider.New()
+}
+
+// newOffLedgerProvider may be overridden in unit tests
+var newOffLedgerProvider = func() olapi.StoreProvider {
+	return olstoreprovider.New(
+		olstoreprovider.WithCollectionType(
+			cb.CollectionType_COL_DCAS, olstoreprovider.WithDecorator(dcas.Decorator),
+		),
+	)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/test_exports.go
new file mode 100644
index 00000000..c026262a
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/test_exports.go
@@ -0,0 +1,18 @@
+// +build testing
+
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	tdapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+)
+
+// SetNewTransientDataProvider sets the transient data provider for unit tests
+func SetNewTransientDataProvider(provider func() tdapi.StoreProvider) {
+	newTransientDataProvider = provider
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api/transientdata.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api/transientdata.go
new file mode 100644
index 00000000..3b508269
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api/transientdata.go
@@ -0,0 +1,52 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package api
+
+import (
+	"context"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	proto "github.com/hyperledger/fabric/protos/transientstore"
+)
+
+// Store manages the storage of transient data.
+type Store interface {
+	// Persist stores the private write set of a transaction.
+	Persist(txID string, privateSimulationResultsWithConfig *proto.TxPvtReadWriteSetWithConfigInfo) error
+
+	// GetTransientData gets the value for the given transient data item
+	GetTransientData(key *storeapi.Key) (*storeapi.ExpiringValue, error)
+
+	// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+	GetTransientDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error)
+
+	// Close closes the store
+	Close()
+}
+
+// StoreProvider is an interface to open/close a provider
+type StoreProvider interface {
+	// OpenStore creates a handle to the transient data store for the given ledger ID
+	OpenStore(ledgerid string) (Store, error)
+
+	// Close cleans up the provider
+	Close()
+}
+
+// Retriever retrieves transient data
+type Retriever interface {
+	// GetTransientData gets the value for the given transient data item
+	GetTransientData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error)
+
+	// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+	GetTransientDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error)
+}
+
+// Provider provides transient data retrievers
+type Provider interface {
+	RetrieverForChannel(channel string) Retriever
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination/disseminationplan.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination/disseminationplan.go
new file mode 100644
index 00000000..2f11ccc1
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination/disseminationplan.go
@@ -0,0 +1,92 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dissemination
+
+import (
+	protobuf "github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/extensions/collections/api/dissemination"
+	gossipapi "github.com/hyperledger/fabric/gossip/api"
+	"github.com/hyperledger/fabric/gossip/common"
+	gdiscovery "github.com/hyperledger/fabric/gossip/discovery"
+	"github.com/hyperledger/fabric/gossip/gossip"
+	"github.com/hyperledger/fabric/gossip/protoext"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	"github.com/pkg/errors"
+	"github.com/spf13/viper"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/discovery"
+)
+
+type gossipAdapter interface {
+	PeersOfChannel(common.ChainID) []gdiscovery.NetworkMember
+	SelfMembershipInfo() gdiscovery.NetworkMember
+	IdentityInfo() gossipapi.PeerIdentitySet
+}
+
+// ComputeDisseminationPlan returns the dissemination plan for transient data
+func ComputeDisseminationPlan(
+	channelID, ns string,
+	rwSet *rwset.CollectionPvtReadWriteSet,
+	colAP privdata.CollectionAccessPolicy,
+	pvtDataMsg *protoext.SignedGossipMessage,
+	gossipAdapter gossipAdapter) ([]*dissemination.Plan, bool, error) {
+	logger.Debugf("Computing transient data dissemination plan for [%s:%s]", ns, rwSet.CollectionName)
+
+	disseminator := New(channelID, ns, rwSet.CollectionName, colAP, gossipAdapter)
+
+	kvRwSet := &kvrwset.KVRWSet{}
+	if err := protobuf.Unmarshal(rwSet.Rwset, kvRwSet); err != nil {
+		return nil, true, errors.WithMessage(err, "error unmarshalling KV read/write set for transient data")
+	}
+
+	var endorsers discovery.PeerGroup
+	for _, kvWrite := range kvRwSet.Writes {
+		if kvWrite.IsDelete {
+			continue
+		}
+		endorsersForKey, err := disseminator.ResolveEndorsers(kvWrite.Key)
+		if err != nil {
+			return nil, true, errors.WithMessage(err, "error resolving endorsers for transient data")
+		}
+
+		logger.Debugf("Endorsers for key [%s:%s:%s]: %s", ns, rwSet.CollectionName, kvWrite.Key, endorsersForKey)
+
+		for _, endorser := range endorsersForKey {
+			if endorser.Local {
+				logger.Debugf("Not adding local endorser for key [%s:%s:%s]", ns, rwSet.CollectionName, kvWrite.Key)
+				continue
+			}
+			endorsers = discovery.Merge(endorsers, endorser)
+		}
+	}
+
+	logger.Debugf("Endorsers for collection [%s:%s]: %s", ns, rwSet.CollectionName, endorsers)
+
+	routingFilter := func(member gdiscovery.NetworkMember) bool {
+		if endorsers.ContainsPeer(member.Endpoint) {
+			logger.Debugf("Peer [%s] is an endorser for [%s:%s]", member.Endpoint, ns, rwSet.CollectionName)
+			return true
+		}
+
+		logger.Debugf("Peer [%s] is NOT an endorser for [%s:%s]", member.Endpoint, ns, rwSet.CollectionName)
+		return false
+	}
+
+	sc := gossip.SendCriteria{
+		Timeout:    viper.GetDuration("peer.gossip.pvtData.pushAckTimeout"),
+		Channel:    common.ChainID(channelID),
+		MaxPeers:   colAP.MaximumPeerCount(),
+		MinAck:     colAP.RequiredPeerCount(),
+		IsEligible: routingFilter,
+	}
+
+	return []*dissemination.Plan{{
+		Criteria: sc,
+		Msg:      pvtDataMsg,
+	}}, true, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination/disseminator.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination/disseminator.go
new file mode 100644
index 00000000..93f4767a
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination/disseminator.go
@@ -0,0 +1,135 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dissemination
+
+import (
+	"hash/fnv"
+	"sort"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/discovery"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+)
+
+var logger = flogging.MustGetLogger("transientdata")
+
+// Disseminator disseminates transient data to a deterministic set of endorsers
+type Disseminator struct {
+	*discovery.Discovery
+	namespace  string
+	collection string
+	policy     privdata.CollectionAccessPolicy
+}
+
+// New returns a new transient data disseminator
+func New(channelID, namespace, collection string, policy privdata.CollectionAccessPolicy, gossip gossipAdapter) *Disseminator {
+	return &Disseminator{
+		Discovery:  discovery.New(channelID, gossip),
+		namespace:  namespace,
+		collection: collection,
+		policy:     policy,
+	}
+}
+
+// ResolveEndorsers resolves to a set of endorsers to which transient data should be disseminated
+func (d *Disseminator) ResolveEndorsers(key string) (discovery.PeerGroup, error) {
+	h, err := getHash32(key)
+	if err != nil {
+		return nil, errors.WithMessage(err, "error computing int32 hash of key")
+	}
+
+	orgs := d.chooseOrgs(h)
+
+	logger.Debugf("[%s] Chosen orgs: %s", d.ChannelID(), orgs)
+
+	endorsers := d.chooseEndorsers(h, orgs)
+
+	logger.Debugf("[%s] Chosen endorsers from orgs %s: %s", d.ChannelID(), orgs, endorsers)
+	return endorsers, nil
+}
+
+func (d *Disseminator) chooseEndorsers(h uint32, orgs []string) discovery.PeerGroup {
+	var endorsers discovery.PeerGroup
+
+	for i := 0; i < d.policy.MaximumPeerCount(); i++ {
+		for _, org := range orgs {
+			if len(endorsers) == d.policy.MaximumPeerCount() {
+				// We have enough endorsers
+				break
+			}
+
+			// Get a sorted list of endorsers for the org
+			endorsersForOrg := d.getEndorsers(org).Sort()
+			if len(endorsersForOrg) == 0 {
+				logger.Debugf("[%s] There are no endorsers in org [%s]", d.ChannelID(), org)
+				continue
+			}
+
+			logger.Debugf("[%s] Endorsers for [%s]: %s", d.ChannelID(), org, endorsersForOrg)
+
+			// Deterministically choose an endorser
+			endorserForOrg := endorsersForOrg[(int(h)+i)%len(endorsersForOrg)]
+			if endorsers.Contains(endorserForOrg) {
+				logger.Debugf("[%s] Will not add endorser [%s] from org [%s] since it is already added", d.ChannelID(), endorserForOrg, org)
+				continue
+			}
+
+			endorsers = append(endorsers, endorserForOrg)
+		}
+	}
+	return endorsers
+}
+
+func (d *Disseminator) getEndorsers(mspID string) discovery.PeerGroup {
+	return d.GetMembers(func(m *discovery.Member) bool {
+		if m.MSPID != mspID {
+			logger.Debugf("[%s] Not adding peer [%s] as an endorser since it is not in org [%s]", d.ChannelID(), m.Endpoint, mspID)
+			return false
+		}
+		if !m.HasRole(roles.EndorserRole) {
+			logger.Debugf("[%s] Not adding peer [%s] as an endorser since it does not have the endorser role", d.ChannelID(), m.Endpoint)
+			return false
+		}
+		return true
+	})
+
+}
+
+func (d *Disseminator) chooseOrgs(h uint32) []string {
+	memberOrgs := d.policy.MemberOrgs()
+	numOrgs := min(d.policy.MaximumPeerCount(), len(memberOrgs))
+
+	// Copy and sort the orgs
+	var sortedOrgs []string
+	sortedOrgs = append(sortedOrgs, memberOrgs...)
+	sort.Strings(sortedOrgs)
+
+	var chosenOrgs []string
+	for i := 0; i < numOrgs; i++ {
+		chosenOrgs = append(chosenOrgs, sortedOrgs[(int(h)+i)%len(sortedOrgs)])
+	}
+
+	return chosenOrgs
+}
+
+func getHash32(key string) (uint32, error) {
+	h := fnv.New32a()
+	_, err := h.Write([]byte(key))
+	if err != nil {
+		return 0, err
+	}
+	return h.Sum32(), nil
+}
+
+func min(i, j int) int {
+	if i < j {
+		return i
+	}
+	return j
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/mocks/mockprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/mocks/mockprovider.go
new file mode 100644
index 00000000..5358ecca
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/mocks/mockprovider.go
@@ -0,0 +1,40 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"context"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	tdataapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+)
+
+// TransientDataProvider is a mock transient data provider
+type TransientDataProvider struct {
+}
+
+// RetrieverForChannel returns a provider for the given channel
+func (p *TransientDataProvider) RetrieverForChannel(channel string) tdataapi.Retriever {
+	return &transientDataRetriever{}
+}
+
+type transientDataRetriever struct {
+}
+
+// GetTransientData returns the transientData
+func (m *transientDataRetriever) GetTransientData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return &storeapi.ExpiringValue{Value: []byte(key.Key)}, nil
+}
+
+// GetTransientDataMultipleKeys returns the data with multiple keys
+func (m *transientDataRetriever) GetTransientDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	values := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		values[i] = &storeapi.ExpiringValue{Value: []byte(k)}
+	}
+	return values, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/policy/validator.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/policy/validator.go
new file mode 100644
index 00000000..fc5050c8
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/policy/validator.go
@@ -0,0 +1,39 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package policy
+
+import (
+	"time"
+
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/pkg/errors"
+)
+
+// ValidateConfig validates the Transient Data Collection configuration
+func ValidateConfig(config *common.StaticCollectionConfig) error {
+	if config.RequiredPeerCount <= 0 {
+		return errors.Errorf("collection-name: %s -- required peer count must be greater than 0", config.Name)
+	}
+
+	if config.RequiredPeerCount > config.MaximumPeerCount {
+		return errors.Errorf("collection-name: %s -- maximum peer count (%d) must be greater than or equal to required peer count (%d)", config.Name, config.MaximumPeerCount, config.RequiredPeerCount)
+	}
+	if config.TimeToLive == "" {
+		return errors.Errorf("collection-name: %s -- time to live must be specified", config.Name)
+	}
+
+	if config.BlockToLive != 0 {
+		return errors.Errorf("collection-name: %s -- block-to-live not supported", config.Name)
+	}
+
+	_, err := time.ParseDuration(config.TimeToLive)
+	if err != nil {
+		return errors.Errorf("collection-name: %s -- invalid time format for time to live: %s", config.Name, err)
+	}
+
+	return nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/retriever/transientdataretriever.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/retriever/transientdataretriever.go
new file mode 100644
index 00000000..b2ca340c
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/retriever/transientdataretriever.go
@@ -0,0 +1,384 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package retriever
+
+import (
+	"context"
+	"sync"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	supportapi "github.com/hyperledger/fabric/extensions/collections/api/support"
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	"github.com/hyperledger/fabric/gossip/comm"
+	mspmgmt "github.com/hyperledger/fabric/msp/mgmt"
+	gproto "github.com/hyperledger/fabric/protos/gossip"
+	"github.com/pkg/errors"
+	tdataapi "github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/dissemination"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/discovery"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/multirequest"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/requestmgr"
+)
+
+var logger = flogging.MustGetLogger("transientdata")
+
+type support interface {
+	Policy(channel, ns, collection string) (privdata.CollectionAccessPolicy, error)
+	BlockPublisher(channelID string) gossipapi.BlockPublisher
+}
+
+// Provider is a transient data provider.
+type Provider struct {
+	support
+	storeForChannel func(channelID string) tdataapi.Store
+	gossipAdapter   func() supportapi.GossipAdapter
+}
+
+// NewProvider returns a new transient data provider
+func NewProvider(storeProvider func(channelID string) tdataapi.Store, support support, gossipProvider func() supportapi.GossipAdapter) tdataapi.Provider {
+	return &Provider{
+		support:         support,
+		storeForChannel: storeProvider,
+		gossipAdapter:   gossipProvider,
+	}
+}
+
+// RetrieverForChannel returns the transient data dataRetriever for the given channel
+func (p *Provider) RetrieverForChannel(channelID string) tdataapi.Retriever {
+	r := &retriever{
+		support:       p.support,
+		gossipAdapter: p.gossipAdapter(),
+		store:         p.storeForChannel(channelID),
+		channelID:     channelID,
+		reqMgr:        requestmgr.Get(channelID),
+		resolvers:     make(map[collKey]resolver),
+	}
+
+	// Add a handler so that we can remove the resolver for a chaincode that has been upgraded
+	p.support.BlockPublisher(channelID).AddCCUpgradeHandler(func(blockNum uint64, txID string, chaincodeID string) error {
+		logger.Infof("[%s] Chaincode [%s] has been upgraded. Clearing resolver cache for chaincode.", channelID, chaincodeID)
+		r.removeResolvers(chaincodeID)
+		return nil
+	})
+
+	return r
+}
+
+// ResolveEndorsers resolves to a set of endorsers to which transient data should be disseminated
+type resolver interface {
+	ResolveEndorsers(key string) (discovery.PeerGroup, error)
+}
+
+type collKey struct {
+	ns   string
+	coll string
+}
+
+func newCollKey(ns, coll string) collKey {
+	return collKey{ns: ns, coll: coll}
+}
+
+type retriever struct {
+	support
+	channelID     string
+	gossipAdapter supportapi.GossipAdapter
+	store         tdataapi.Store
+	resolvers     map[collKey]resolver
+	lock          sync.RWMutex
+	reqMgr        requestmgr.RequestMgr
+}
+
+func (r *retriever) GetTransientData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	authorized, err := r.isAuthorized(key.Namespace, key.Collection)
+	if err != nil {
+		return nil, err
+	}
+	if !authorized {
+		logger.Infof("[%s] This peer does not have access to the collection [%s:%s]", r.channelID, key.Namespace, key.Collection)
+		return nil, nil
+	}
+
+	endorsers, err := r.resolveEndorsers(key)
+	if err != nil {
+		return nil, errors.WithMessagef(err, "unable to get resolve endorsers for channel [%s] and [%s]", r.channelID, key)
+	}
+
+	logger.Debugf("[%s] Endorsers for [%s]: %s", r.channelID, key, endorsers)
+
+	if endorsers.ContainsLocal() {
+		value, ok, err := r.getTransientDataFromLocal(key)
+		if err != nil {
+			return nil, err
+		}
+		if ok {
+			return value, nil
+		}
+	}
+
+	return r.getTransientDataFromRemote(ctxt, key, endorsers.Remote())
+}
+
+type valueResp struct {
+	value *storeapi.ExpiringValue
+	err   error
+}
+
+// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+func (r *retriever) GetTransientDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	if len(key.Keys) == 0 {
+		return nil, errors.New("at least one key must be specified")
+	}
+
+	var wg sync.WaitGroup
+	wg.Add(len(key.Keys))
+	var mutex sync.Mutex
+
+	// TODO: This can be optimized by sending one request to endorsers that have multiple keys, as opposed to one request per key.
+	responses := make(map[string]*valueResp)
+	for _, k := range key.Keys {
+		go func(key *storeapi.Key) {
+			cctxt, cancel := context.WithCancel(ctxt)
+			defer cancel()
+
+			value, err := r.GetTransientData(cctxt, key)
+			mutex.Lock()
+			responses[key.Key] = &valueResp{value: value, err: err}
+			logger.Debugf("Got response for [%s]: %s, Err: %s", key.Key, value, err)
+			mutex.Unlock()
+			wg.Done()
+		}(storeapi.NewKey(key.EndorsedAtTxID, key.Namespace, key.Collection, k))
+	}
+
+	wg.Wait()
+
+	// Return the responses in the order of the requested keys
+	values := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		r, ok := responses[k]
+		if !ok {
+			return nil, errors.Errorf("no response for key [%s:%s:%s]", key.Namespace, key.Collection, k)
+		}
+		if r.err != nil {
+			return nil, r.err
+		}
+		values[i] = r.value
+	}
+
+	return values, nil
+}
+
+// resolveEndorsers returns the endorsers that (should) have the transient data
+func (r *retriever) resolveEndorsers(key *storeapi.Key) (discovery.PeerGroup, error) {
+	res, err := r.getResolver(key.Namespace, key.Collection)
+	if err != nil {
+		return nil, errors.WithMessagef(err, "unable to get resolver for channel [%s] and [%s:%s]", r.channelID, key.Namespace, key.Collection)
+	}
+	return res.ResolveEndorsers(key.Key)
+}
+
+func (r *retriever) getTransientDataFromLocal(key *storeapi.Key) (*storeapi.ExpiringValue, bool, error) {
+	value, retrieveErr := r.store.GetTransientData(key)
+	if retrieveErr != nil {
+		logger.Debugf("[%s] Error getting transient data from local store for [%s]: %s", r.channelID, key, retrieveErr)
+		return nil, false, errors.WithMessagef(retrieveErr, "unable to get transient data for channel [%s] and [%s]", r.channelID, key)
+	}
+
+	if value != nil && len(value.Value) > 0 {
+		logger.Debugf("[%s] Got transient data from local store for [%s]", r.channelID, key)
+		return value, true, nil
+	}
+
+	logger.Debugf("[%s] nil transient data in local store for [%s]. Will try to pull from remote peer(s).", r.channelID, key)
+	return nil, false, nil
+}
+
+func (r *retriever) getTransientDataFromRemote(ctxt context.Context, key *storeapi.Key, endorsers discovery.PeerGroup) (*storeapi.ExpiringValue, error) {
+	cReq := multirequest.New()
+	for _, endorser := range endorsers {
+		logger.Debugf("Adding request to get transient data for [%s] from [%s] ...", key, endorser)
+		cReq.Add(endorser.String(), r.getTransientDataRequest(key, endorser))
+	}
+
+	response := cReq.Execute(ctxt)
+
+	if response.Values.IsEmpty() {
+		logger.Debugf("Got empty transient data response for [%s] ...", key)
+		return nil, nil
+	}
+
+	logger.Debugf("Got non-nil transient data response for [%s] ...", key)
+	return response.Values[0].(*storeapi.ExpiringValue), nil
+}
+
+func (r *retriever) getTransientDataRequest(key *storeapi.Key, endorser *discovery.Member) func(ctxt context.Context) (common.Values, error) {
+	return func(ctxt context.Context) (common.Values, error) {
+		return r.getTransientDataFromEndorser(ctxt, key, endorser)
+	}
+}
+
+func (r *retriever) getTransientDataFromEndorser(ctxt context.Context, key *storeapi.Key, endorser *discovery.Member) (common.Values, error) {
+	logger.Debugf("Getting transient data for [%s] from [%s] ...", key, endorser)
+
+	value, err := r.getTransientData(ctxt, key, endorser)
+	if err != nil {
+		if err == context.Canceled {
+			logger.Debugf("[%s] Request to get transient data from [%s] for [%s] was cancelled", r.channelID, endorser, key)
+		} else {
+			logger.Debugf("[%s] Error getting transient data from [%s] for [%s]: %s", r.channelID, endorser, key, err)
+		}
+		return common.Values{nil}, err
+	}
+
+	if value == nil {
+		logger.Debugf("[%s] Transient data not found on [%s] for [%s]", r.channelID, endorser, key)
+	} else {
+		logger.Debugf("[%s] Got transient data from [%s] for [%s]", r.channelID, endorser, key)
+	}
+
+	return common.Values{value}, nil
+}
+
+func (r *retriever) getResolver(ns, coll string) (resolver, error) {
+	key := newCollKey(ns, coll)
+
+	r.lock.RLock()
+	resolver, ok := r.resolvers[key]
+	r.lock.RUnlock()
+
+	if ok {
+		return resolver, nil
+	}
+
+	return r.getOrCreateResolver(key)
+}
+
+func (r *retriever) getOrCreateResolver(key collKey) (resolver, error) {
+	r.lock.Lock()
+	defer r.lock.Unlock()
+
+	resolver, ok := r.resolvers[key]
+	if ok {
+		return resolver, nil
+	}
+
+	policy, err := r.Policy(r.channelID, key.ns, key.coll)
+	if err != nil {
+		return nil, err
+	}
+
+	resolver = dissemination.New(r.channelID, key.ns, key.coll, policy, r.gossipAdapter)
+
+	r.resolvers[key] = resolver
+
+	return resolver, nil
+}
+
+func (r *retriever) removeResolvers(ns string) {
+	r.lock.Lock()
+	defer r.lock.Unlock()
+
+	for key := range r.resolvers {
+		if key.ns == ns {
+			logger.Debugf("[%s] Removing resolver [%s:%s] from cache", r.channelID, key.ns, key.coll)
+			delete(r.resolvers, key)
+		}
+	}
+}
+
+func (r *retriever) getTransientData(ctxt context.Context, key *storeapi.Key, endorsers ...*discovery.Member) (*storeapi.ExpiringValue, error) {
+	logger.Debugf("[%s] Sending Gossip request to %s for transient data for [%s]", r.channelID, endorsers, key)
+
+	req := r.reqMgr.NewRequest()
+
+	logger.Debugf("[%s] Creating Gossip request %d for transient data for [%s]", r.channelID, req.ID(), key)
+	msg := r.createCollDataRequestMsg(req, key)
+
+	logger.Debugf("[%s] Sending Gossip request %d for transient data for [%s]", r.channelID, req.ID(), key)
+	r.gossipAdapter.Send(msg, asRemotePeers(endorsers)...)
+
+	logger.Debugf("[%s] Waiting for response for %d for transient data for [%s]", r.channelID, req.ID(), key)
+	res, err := req.GetResponse(ctxt)
+	if err != nil {
+		return nil, err
+	}
+
+	logger.Debugf("[%s] Got response for %d for transient data for [%s]", r.channelID, req.ID(), key)
+	return r.findValue(res.Data, key)
+}
+
+func (r *retriever) findValue(data requestmgr.Elements, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	for _, e := range data {
+		if e.Namespace == key.Namespace && e.Collection == key.Collection && e.Key == key.Key {
+			logger.Debugf("[%s] Got response for transient data for [%s]", r.channelID, key)
+			if e.Value == nil {
+				return nil, nil
+			}
+			return &storeapi.ExpiringValue{Value: e.Value, Expiry: e.Expiry}, nil
+		}
+	}
+	return nil, errors.Errorf("expecting a response to a transient data request for [%s] but got a response for another key", key)
+}
+
+func (r *retriever) createCollDataRequestMsg(req requestmgr.Request, key *storeapi.Key) *gproto.GossipMessage {
+	return &gproto.GossipMessage{
+		Tag:     gproto.GossipMessage_CHAN_ONLY,
+		Channel: []byte(r.channelID),
+		Content: &gproto.GossipMessage_CollDataReq{
+			CollDataReq: &gproto.RemoteCollDataRequest{
+				Nonce: req.ID(),
+				Digests: []*gproto.CollDataDigest{
+					{
+						Namespace:      key.Namespace,
+						Collection:     key.Collection,
+						Key:            key.Key,
+						EndorsedAtTxID: key.EndorsedAtTxID,
+					},
+				},
+			},
+		},
+	}
+}
+
+// isAuthorized returns true if the local peer has access to the given collection
+func (r *retriever) isAuthorized(ns, coll string) (bool, error) {
+	policy, err := r.Policy(r.channelID, ns, coll)
+	if err != nil {
+		return false, errors.WithMessagef(err, "unable to get policy for [%s:%s]", ns, coll)
+	}
+
+	localMSPID, err := getLocalMSPID()
+	if err != nil {
+		return false, errors.WithMessagef(err, "unable to get local MSP ID")
+	}
+
+	for _, mspID := range policy.MemberOrgs() {
+		if mspID == localMSPID {
+			return true, nil
+		}
+	}
+
+	return false, nil
+}
+
+func asRemotePeers(members []*discovery.Member) []*comm.RemotePeer {
+	var peers []*comm.RemotePeer
+	for _, m := range members {
+		peers = append(peers, &comm.RemotePeer{
+			Endpoint: m.Endpoint,
+			PKIID:    m.PKIid,
+		})
+	}
+	return peers
+}
+
+// getLocalMSPID returns the MSP ID of the local peer. This variable may be overridden by unit tests.
+var getLocalMSPID = func() (string, error) {
+	return mspmgmt.GetLocalMSP().GetIdentifier()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/api/api.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/api/api.go
new file mode 100644
index 00000000..7c091717
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/api/api.go
@@ -0,0 +1,30 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package api
+
+import (
+	"fmt"
+	"time"
+)
+
+// Key is a transient data key
+type Key struct {
+	Namespace  string
+	Collection string
+	Key        string
+}
+
+func (k Key) String() string {
+	return fmt.Sprintf("%s:%s:%s", k.Namespace, k.Collection, k.Key)
+}
+
+// Value is a transient data value
+type Value struct {
+	Value      []byte
+	TxID       string
+	ExpiryTime time.Time
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/cache/cache.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/cache/cache.go
new file mode 100644
index 00000000..2e9af208
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/cache/cache.go
@@ -0,0 +1,150 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cache
+
+import (
+	"fmt"
+	"time"
+
+	"github.com/bluele/gcache"
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+)
+
+var logger = flogging.MustGetLogger("memtransientdatastore")
+
+// Cache is an in-memory key-value cache
+type Cache struct {
+	cache   gcache.Cache
+	ticker  *time.Ticker
+	dbstore transientDB
+}
+
+// transientDB - an interface for persisting and retrieving keys
+type transientDB interface {
+	AddKey(api.Key, *api.Value) error
+	DeleteExpiredKeys() error
+	GetKey(key api.Key) (*api.Value, error)
+}
+
+// New return a new in-memory key-value cache
+func New(size int, dbstore transientDB) *Cache {
+	c := &Cache{
+		ticker:  time.NewTicker(config.GetTransientDataExpiredIntervalTime()),
+		dbstore: dbstore,
+	}
+
+	c.cache = gcache.New(size).
+		LoaderExpireFunc(c.loadFromDB).
+		EvictedFunc(c.storeToDB).
+		ARC().Build()
+
+	// cleanup expired data in db
+	go c.periodicPurge()
+
+	return c
+}
+
+// Close closes the cache
+func (c *Cache) Close() {
+	c.cache.Purge()
+	c.ticker.Stop()
+}
+
+// Put adds the transient value for the given key.
+func (c *Cache) Put(key api.Key, value []byte, txID string) {
+	if err := c.cache.Set(key,
+		&api.Value{
+			Value: value,
+			TxID:  txID,
+		}); err != nil {
+		panic("Set must never return an error")
+	}
+}
+
+// PutWithExpire adds the transient value for the given key.
+func (c *Cache) PutWithExpire(key api.Key, value []byte, txID string, expiry time.Duration) {
+	if err := c.cache.SetWithExpire(key,
+		&api.Value{
+			Value:      value,
+			TxID:       txID,
+			ExpiryTime: time.Now().UTC().Add(expiry),
+		}, expiry); err != nil {
+		panic("Set must never return an error")
+	}
+}
+
+// Get returns the transient value for the given key
+func (c *Cache) Get(key api.Key) *api.Value {
+	value, err := c.cache.Get(key)
+	if err != nil {
+		if err != gcache.KeyNotFoundError {
+			panic(fmt.Sprintf("Get must never return an error other than KeyNotFoundError err:%s", err))
+		}
+		return nil
+	}
+
+	return value.(*api.Value)
+}
+
+func (c *Cache) loadFromDB(key interface{}) (interface{}, *time.Duration, error) {
+	logger.Debugf("LoaderExpireFunc for key %s", key)
+	value, err := c.dbstore.GetKey(key.(api.Key))
+	if value == nil || err != nil {
+		if err != nil {
+			logger.Error(err.Error())
+		}
+		logger.Debugf("Key [%s] not found in DB", key)
+		return nil, nil, gcache.KeyNotFoundError
+	}
+	isExpired, diff := checkExpiryTime(value.ExpiryTime)
+	if isExpired {
+		logger.Debugf("Key [%s] from DB has expired", key)
+		return nil, nil, gcache.KeyNotFoundError
+	}
+	logger.Debugf("Loaded key [%s] from DB", key)
+	return value, &diff, nil
+}
+
+func (c *Cache) storeToDB(key, value interface{}) {
+	logger.Debugf("EvictedFunc for key %s", key)
+	if value != nil {
+		k := key.(api.Key)
+		v := value.(*api.Value)
+		isExpired, _ := checkExpiryTime(v.ExpiryTime)
+		if !isExpired {
+			dbstoreErr := c.dbstore.AddKey(k, v)
+			if dbstoreErr != nil {
+				logger.Error(dbstoreErr.Error())
+			} else {
+				logger.Debugf("Key [%s] offloaded to DB", key)
+			}
+		}
+	}
+}
+
+func (c *Cache) periodicPurge() {
+	for range c.ticker.C {
+		dbstoreErr := c.dbstore.DeleteExpiredKeys()
+		if dbstoreErr != nil {
+			logger.Error(dbstoreErr.Error())
+		}
+	}
+}
+
+func checkExpiryTime(expiryTime time.Time) (bool, time.Duration) {
+	if expiryTime.IsZero() {
+		return false, 0
+	}
+
+	timeNow := time.Now().UTC()
+	logger.Debugf("Checking expiration - Current time: %s, Expiry time: %s", timeNow, expiryTime)
+
+	diff := expiryTime.Sub(timeNow)
+	return diff <= 0, diff
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore/dbstore.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore/dbstore.go
new file mode 100644
index 00000000..43a2d348
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore/dbstore.go
@@ -0,0 +1,130 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dbstore
+
+import (
+	"bytes"
+	"encoding/gob"
+	"fmt"
+	"strings"
+	"time"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/common/ledger/util/leveldbhelper"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/api"
+)
+
+var logger = flogging.MustGetLogger("transientdb")
+
+var compositeKeySep = "!"
+
+// DBStore holds the db handle and the db name
+type DBStore struct {
+	db     *leveldbhelper.DBHandle
+	dbName string
+}
+
+// newDBStore constructs an instance of db store
+func newDBStore(db *leveldbhelper.DBHandle, dbName string) *DBStore {
+	return &DBStore{db, dbName}
+}
+
+// AddKey add cache key to db
+func (s *DBStore) AddKey(key api.Key, value *api.Value) error {
+	encodeVal, err := encodeCacheVal(value)
+	if err != nil {
+		return errors.WithMessagef(err, "failed to encode transientdata value %s", value)
+	}
+	// put key in db
+	err = s.db.Put(encodeCacheKey(key, time.Time{}), encodeVal, true)
+	if err != nil {
+		return errors.Wrapf(err, "failed to save transientdata key %s in db", key)
+	}
+
+	if !value.ExpiryTime.IsZero() {
+		// put same previous key with prefix expiryTime so the clean up can remove all expired keys
+		err = s.db.Put(encodeCacheKey(key, value.ExpiryTime), []byte(""), true)
+		if err != nil {
+			return errors.Wrapf(err, "failed to save transientdata key %s in db", key)
+		}
+	}
+
+	return nil
+}
+
+// GetKey get cache key from db
+func (s *DBStore) GetKey(key api.Key) (*api.Value, error) {
+	logger.Debugf("load transientdata key %s from db", key)
+	value, err := s.db.Get(encodeCacheKey(key, time.Time{}))
+	if err != nil {
+		return nil, errors.Wrapf(err, "failed to load transientdata key %s from db", key)
+	}
+	if value != nil {
+		val, err := decodeCacheVal(value)
+		if err != nil {
+			return nil, errors.Wrapf(err, "failed to decode transientdata value %s", value)
+		}
+		return val, nil
+	}
+	return nil, nil
+}
+
+// DeleteExpiredKeys delete expired keys from db
+func (s *DBStore) DeleteExpiredKeys() error {
+	dbBatch := leveldbhelper.NewUpdateBatch()
+	itr := s.db.GetIterator(nil, []byte(fmt.Sprintf("%d%s", time.Now().UTC().UnixNano(), compositeKeySep)))
+	for itr.Next() {
+		key := string(itr.Key())
+		dbBatch.Delete([]byte(key))
+		dbBatch.Delete([]byte(key[strings.Index(key, compositeKeySep)+1:]))
+	}
+	if dbBatch.Len() > 0 {
+		err := s.db.WriteBatch(dbBatch, true)
+		if err != nil {
+			return errors.Errorf("failed to delete transient data keys %s in db %s", dbBatch.KVs, err.Error())
+		}
+		logger.Debugf("delete expired keys %s from db", dbBatch.KVs)
+	}
+
+	return nil
+}
+
+// Close db
+func (s *DBStore) Close() {
+}
+
+func encodeCacheKey(key api.Key, expiryTime time.Time) []byte {
+	var compositeKey []byte
+	if !expiryTime.IsZero() {
+		compositeKey = append(compositeKey, []byte(fmt.Sprintf("%d", expiryTime.UnixNano()))...)
+		compositeKey = append(compositeKey, compositeKeySep...)
+	}
+	compositeKey = append(compositeKey, []byte(key.Namespace)...)
+	compositeKey = append(compositeKey, compositeKeySep...)
+	compositeKey = append(compositeKey, []byte(key.Collection)...)
+	compositeKey = append(compositeKey, compositeKeySep...)
+	compositeKey = append(compositeKey, []byte(key.Key)...)
+	return compositeKey
+}
+
+func decodeCacheVal(b []byte) (*api.Value, error) {
+	decoder := gob.NewDecoder(bytes.NewBuffer(b))
+	var v *api.Value
+	if err := decoder.Decode(&v); err != nil {
+		return nil, err
+	}
+	return v, nil
+}
+
+func encodeCacheVal(v *api.Value) ([]byte, error) {
+	buf := bytes.NewBuffer(nil)
+	encoder := gob.NewEncoder(buf)
+	if err := encoder.Encode(v); err != nil {
+		return nil, err
+	}
+	return buf.Bytes(), nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore/dbstore_provider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore/dbstore_provider.go
new file mode 100644
index 00000000..1554d7ac
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore/dbstore_provider.go
@@ -0,0 +1,41 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dbstore
+
+import (
+	"github.com/hyperledger/fabric/common/ledger/util/leveldbhelper"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+)
+
+// DBProvider provides an handle to a transientdata db
+type DBProvider interface {
+	OpenDBStore(id string) (DBStore, error)
+	Close()
+}
+
+// LevelDBProvider provides an handle to a transientdata db
+type LevelDBProvider struct {
+	leveldbProvider *leveldbhelper.Provider
+}
+
+// NewDBProvider constructs new db provider
+func NewDBProvider() *LevelDBProvider {
+	dbPath := config.GetTransientDataLevelDBPath()
+	logger.Debugf("constructing DBProvider dbPath=%s", dbPath)
+	return &LevelDBProvider{leveldbhelper.NewProvider(&leveldbhelper.Conf{DBPath: dbPath})}
+
+}
+
+// OpenDBStore opens the db store
+func (p *LevelDBProvider) OpenDBStore(dbName string) (*DBStore, error) {
+	indexStore := p.leveldbProvider.GetDBHandle(dbName)
+	return newDBStore(indexStore, dbName), nil
+}
+
+// Close cleans up the Provider
+func (p *LevelDBProvider) Close() {
+	p.leveldbProvider.Close()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/tdstore.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/tdstore.go
new file mode 100644
index 00000000..49d05d2b
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/tdstore.go
@@ -0,0 +1,166 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	"time"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/rwsetutil"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	pb "github.com/hyperledger/fabric/protos/transientstore"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/cache"
+)
+
+var logger = flogging.MustGetLogger("memtransientdatastore")
+
+type store struct {
+	channelID string
+	cache     *cache.Cache
+}
+
+type db interface {
+	AddKey(api.Key, *api.Value) error
+	DeleteExpiredKeys() error
+	GetKey(key api.Key) (*api.Value, error)
+}
+
+func newStore(channelID string, cacheSize int, transientDB db) *store {
+	logger.Debugf("[%s] Creating new store - cacheSize=%d", channelID, cacheSize)
+	return &store{
+		channelID: channelID,
+		cache:     cache.New(cacheSize, transientDB),
+	}
+}
+
+// Persist persists all transient data within the private data simulation results
+func (s *store) Persist(txID string, privateSimulationResultsWithConfig *pb.TxPvtReadWriteSetWithConfigInfo) error {
+	rwSet, err := rwsetutil.TxPvtRwSetFromProtoMsg(privateSimulationResultsWithConfig.PvtRwset)
+	if err != nil {
+		return errors.WithMessage(err, "error getting pvt RW set from bytes")
+	}
+
+	for _, nsRWSet := range rwSet.NsPvtRwSet {
+		for _, collRWSet := range nsRWSet.CollPvtRwSets {
+			if err := s.persistColl(txID, nsRWSet.NameSpace, privateSimulationResultsWithConfig.CollectionConfigs, collRWSet); err != nil {
+				return err
+			}
+		}
+	}
+
+	return nil
+}
+
+// GetTransientData returns the transient data for the given key
+func (s *store) GetTransientData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return s.getTransientData(key.EndorsedAtTxID, key.Namespace, key.Collection, key.Key), nil
+}
+
+// GetTransientData returns the transient data for the given keys
+func (s *store) GetTransientDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	return s.getTransientDataMultipleKeys(key), nil
+}
+
+// Close closes the transient data store
+func (s *store) Close() {
+	if s.cache != nil {
+		logger.Debugf("[%s] Closing cache", s.channelID)
+		s.cache.Close()
+		s.cache = nil
+	}
+}
+
+func (s *store) persistColl(txID string, ns string, collConfigPkgs map[string]*common.CollectionConfigPackage, collRWSet *rwsetutil.CollPvtRwSet) error {
+	config, exists := getCollectionConfig(collConfigPkgs, ns, collRWSet.CollectionName)
+	if !exists {
+		logger.Debugf("[%s] Config for collection [%s:%s] not found in config packages", s.channelID, ns, collRWSet.CollectionName)
+		return nil
+	}
+
+	ttl, err := time.ParseDuration(config.TimeToLive)
+	if err != nil {
+		// This shouldn't happen since the config was validated before being persisted
+		return errors.Wrapf(err, "error parsing time-to-live for collection [%s]", collRWSet.CollectionName)
+	}
+
+	logger.Debugf("[%s] Collection [%s:%s] is a transient data collection", s.channelID, ns, collRWSet.CollectionName)
+
+	for _, wSet := range collRWSet.KvRwSet.Writes {
+		s.persistKVWrite(txID, ns, collRWSet.CollectionName, wSet, ttl)
+	}
+
+	return nil
+}
+
+func (s *store) persistKVWrite(txID, ns, coll string, w *kvrwset.KVWrite, ttl time.Duration) {
+	if w.IsDelete {
+		logger.Debugf("[%s] Skipping key [%s] in collection [%s] in private data rw-set since it was deleted", s.channelID, w.Key, coll)
+		return
+	}
+
+	key := api.Key{
+		Namespace:  ns,
+		Collection: coll,
+		Key:        w.Key,
+	}
+
+	if s.cache.Get(key) != nil {
+		logger.Warningf("[%s] Attempt to update transient data key [%s] in collection [%s]", s.channelID, w.Key, coll)
+		return
+	}
+
+	s.cache.PutWithExpire(key, w.Value, txID, ttl)
+}
+
+func (s *store) getTransientData(txID, ns, coll, key string) *storeapi.ExpiringValue {
+	value := s.cache.Get(api.Key{Namespace: ns, Collection: coll, Key: key})
+	if value == nil {
+		logger.Debugf("[%s] Key [%s] not found in transient store", s.channelID, key)
+		return nil
+	}
+
+	// Check if the data was stored in the current transaction. If so, ignore it or else an endorsement mismatch may result.
+	if value.TxID == txID {
+		logger.Debugf("[%s] Key [%s] skipped since it was stored in the current transaction", s.channelID, key)
+		return nil
+	}
+
+	logger.Debugf("[%s] Key [%s] found in transient store", s.channelID, key)
+
+	return &storeapi.ExpiringValue{Value: value.Value, Expiry: value.ExpiryTime}
+}
+
+func (s *store) getTransientDataMultipleKeys(mkey *storeapi.MultiKey) storeapi.ExpiringValues {
+	var values storeapi.ExpiringValues
+	for _, key := range mkey.Keys {
+		value := s.getTransientData(mkey.EndorsedAtTxID, mkey.Namespace, mkey.Collection, key)
+		if value != nil {
+			values = append(values, value)
+		}
+	}
+	return values
+}
+
+func getCollectionConfig(collConfigPkgs map[string]*common.CollectionConfigPackage, namespace, collName string) (*common.StaticCollectionConfig, bool) {
+	collConfigPkg, ok := collConfigPkgs[namespace]
+	if !ok {
+		return nil, false
+	}
+
+	for _, collConfig := range collConfigPkg.Config {
+		transientConfig := collConfig.GetStaticCollectionConfig()
+		if transientConfig != nil && transientConfig.Type == common.CollectionType_COL_TRANSIENT && transientConfig.Name == collName {
+			return transientConfig, true
+		}
+	}
+
+	return nil, false
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/tdstoreprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/tdstoreprovider.go
new file mode 100644
index 00000000..7e38c6de
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/tdstoreprovider.go
@@ -0,0 +1,67 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package storeprovider
+
+import (
+	"sync"
+
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/api"
+	"github.com/trustbloc/fabric-peer-ext/pkg/collections/transientdata/storeprovider/store/dbstore"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+)
+
+// New returns a new transient data store provider
+func New() *StoreProvider {
+	return &StoreProvider{
+		stores:     make(map[string]*store),
+		dbProvider: dbstore.NewDBProvider(),
+	}
+}
+
+// StoreProvider is a transient data store provider
+type StoreProvider struct {
+	stores     map[string]*store
+	dbProvider *dbstore.LevelDBProvider
+	sync.RWMutex
+}
+
+// StoreForChannel returns the transient data store for the given channel
+func (sp *StoreProvider) StoreForChannel(channelID string) api.Store {
+	sp.RLock()
+	defer sp.RUnlock()
+	return sp.stores[channelID]
+}
+
+// OpenStore opens the transient data store for the given channel
+func (sp *StoreProvider) OpenStore(channelID string) (api.Store, error) {
+	sp.Lock()
+	defer sp.Unlock()
+
+	_, ok := sp.stores[channelID]
+	if ok {
+		return nil, errors.Errorf("a store for channel [%s] already exists", channelID)
+	}
+
+	db, err := sp.dbProvider.OpenDBStore(channelID)
+	if err != nil {
+		return nil, err
+	}
+
+	store := newStore(channelID, config.GetTransientDataCacheSize(), db)
+	sp.stores[channelID] = store
+
+	return store, nil
+}
+
+// Close shuts down all of the stores
+func (sp *StoreProvider) Close() {
+	for _, s := range sp.stores {
+		s.Close()
+	}
+	sp.dbProvider.Close()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/common.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/common.go
new file mode 100644
index 00000000..1e338ab3
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/common.go
@@ -0,0 +1,88 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package common
+
+import (
+	"reflect"
+	"time"
+
+	"github.com/golang/protobuf/ptypes/timestamp"
+)
+
+// Values contains a slice of values
+type Values []interface{}
+
+// IsEmpty returns true if all of the values are nil
+func (v Values) IsEmpty() bool {
+	for _, value := range v {
+		if !IsNil(value) {
+			return false
+		}
+	}
+	return true
+}
+
+// AllSet returns true if all of the values are not nil
+func (v Values) AllSet() bool {
+	for _, value := range v {
+		if IsNil(value) {
+			return false
+		}
+	}
+	return true
+}
+
+// Merge merges this set of values with the given set
+// and returns the new set
+func (v Values) Merge(other Values) Values {
+	var max int
+	if len(other) < len(v) {
+		max = len(v)
+	} else {
+		max = len(other)
+	}
+
+	retVal := make(Values, max)
+	copy(retVal, v)
+
+	for i, o := range other {
+		if IsNil(retVal[i]) {
+			retVal[i] = o
+		}
+	}
+
+	return retVal
+}
+
+// IsNil returns true if the given value is nil
+func IsNil(p interface{}) bool {
+	if p == nil {
+		return true
+	}
+
+	v := reflect.ValueOf(p)
+
+	switch {
+	case v.Kind() == reflect.Ptr:
+		return v.IsNil()
+	case v.Kind() == reflect.Array || v.Kind() == reflect.Slice:
+		return v.Len() == 0
+	default:
+		return false
+	}
+}
+
+// ToTimestamp converts the Time into Timestamp
+func ToTimestamp(t time.Time) *timestamp.Timestamp {
+	now := time.Now().UTC()
+	return &(timestamp.Timestamp{Seconds: now.Unix()})
+}
+
+// FromTimestamp converts the Timestamp into Time
+func FromTimestamp(ts *timestamp.Timestamp) time.Time {
+	return time.Unix(ts.Seconds, 0)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/discovery.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/discovery.go
new file mode 100644
index 00000000..b139fefb
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/discovery.go
@@ -0,0 +1,123 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package discovery
+
+import (
+	"sync"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/gossip/api"
+	"github.com/hyperledger/fabric/gossip/common"
+	"github.com/hyperledger/fabric/gossip/discovery"
+	proto "github.com/hyperledger/fabric/protos/gossip"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+)
+
+var logger = flogging.MustGetLogger("discovery")
+
+// Discovery provides functions to retrieve info about the local peer and other peers in a given channel
+type Discovery struct {
+	channelID string
+	gossip    gossipAdapter
+	self      *Member
+	selfInit  sync.Once
+}
+
+// New returns a new Discovery
+func New(channelID string, gossip gossipAdapter) *Discovery {
+	return &Discovery{
+		channelID: channelID,
+		gossip:    gossip,
+	}
+}
+
+type filter func(m *Member) bool
+
+type gossipAdapter interface {
+	PeersOfChannel(common.ChainID) []discovery.NetworkMember
+	SelfMembershipInfo() discovery.NetworkMember
+	IdentityInfo() api.PeerIdentitySet
+}
+
+// Self returns the local peer
+func (r *Discovery) Self() *Member {
+	r.selfInit.Do(func() {
+		r.self = getSelf(r.channelID, r.gossip)
+	})
+	return r.self
+}
+
+// ChannelID returns the channel ID
+func (r *Discovery) ChannelID() string {
+	return r.channelID
+}
+
+// GetMembers returns members filtered by the given filter
+func (r *Discovery) GetMembers(accept filter) []*Member {
+	identityInfo := r.gossip.IdentityInfo()
+	mapByID := identityInfo.ByID()
+
+	var peers []*Member
+	for _, m := range r.gossip.PeersOfChannel(common.ChainID(r.channelID)) {
+		identity, ok := mapByID[string(m.PKIid)]
+		if !ok {
+			logger.Warningf("[%s] Not adding peer [%s] as a validator since unable to determine MSP ID from PKIID for [%s]", r.channelID, m.Endpoint)
+			continue
+		}
+
+		m := &Member{
+			NetworkMember: m,
+			MSPID:         string(identity.Organization),
+		}
+
+		if accept(m) {
+			peers = append(peers, m)
+		}
+	}
+
+	if accept(r.Self()) {
+		peers = append(peers, r.Self())
+	}
+
+	return peers
+}
+
+// GetMSPID gets the MSP id
+func (r *Discovery) GetMSPID(pkiID common.PKIidType) (string, bool) {
+	identityInfo := r.gossip.IdentityInfo()
+	mapByID := identityInfo.ByID()
+
+	identity, ok := mapByID[string(pkiID)]
+	if !ok {
+		return "", false
+	}
+	return string(identity.Organization), true
+}
+
+func getSelf(channelID string, gossip gossipAdapter) *Member {
+	self := gossip.SelfMembershipInfo()
+	self.Properties = &proto.Properties{
+		Roles: roles.AsString(),
+	}
+
+	identityInfo := gossip.IdentityInfo()
+	mapByID := identityInfo.ByID()
+
+	var mspID string
+	selfIdentity, ok := mapByID[string(self.PKIid)]
+	if ok {
+		mspID = string(selfIdentity.Organization)
+	} else {
+		logger.Warningf("[%s] Unable to determine MSP ID from PKIID for self", channelID)
+	}
+
+	return &Member{
+		NetworkMember: self,
+		MSPID:         mspID,
+		Local:         true,
+	}
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/member.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/member.go
new file mode 100644
index 00000000..8ef8cd8f
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/member.go
@@ -0,0 +1,38 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package discovery
+
+import (
+	"github.com/hyperledger/fabric/gossip/discovery"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+)
+
+// Member wraps a NetworkMember and provides additional info
+type Member struct {
+	discovery.NetworkMember
+	ChannelID string
+	MSPID     string
+	Local     bool // Indicates whether this member is the local peer
+}
+
+func (m *Member) String() string {
+	return m.Endpoint
+}
+
+// Roles returns the roles of the peer
+func (m *Member) Roles() roles.Roles {
+	if m.Properties == nil {
+		logger.Debugf("[%s] Peer [%s] does not have any properties", m.ChannelID, m.Endpoint)
+		return nil
+	}
+	return roles.FromStrings(m.Properties.Roles...)
+}
+
+// HasRole returns true if the member has the given role
+func (m *Member) HasRole(role roles.Role) bool {
+	return m.Roles().Contains(role)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/peergroup.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/peergroup.go
new file mode 100644
index 00000000..944996f5
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/discovery/peergroup.go
@@ -0,0 +1,136 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package discovery
+
+import (
+	"math/rand"
+	"sort"
+)
+
+// PeerGroup is a group of peers
+type PeerGroup []*Member
+
+// ContainsLocal return true if one of the peers in the group is the local peer
+func (g PeerGroup) ContainsLocal() bool {
+	for _, p := range g {
+		if p.Local {
+			return true
+		}
+	}
+	return false
+}
+
+func (g PeerGroup) String() string {
+	s := "["
+	for i, p := range g {
+		s += p.String()
+		if i+1 < len(g) {
+			s += ", "
+		}
+	}
+	s += "]"
+	return s
+}
+
+// Sort sorts the peer group by endpoint
+func (g PeerGroup) Sort() PeerGroup {
+	sort.Sort(g)
+	return g
+}
+
+// ContainsAll returns true if ALL of the peers within the given peer group are contained within this peer group
+func (g PeerGroup) ContainsAll(peerGroup PeerGroup) bool {
+	for _, p := range peerGroup {
+		if !g.Contains(p) {
+			return false
+		}
+	}
+	return true
+}
+
+// ContainsAny returns true if ANY of the peers within the given peer group are contained within this peer group
+func (g PeerGroup) ContainsAny(peerGroup PeerGroup) bool {
+	for _, p := range peerGroup {
+		if g.Contains(p) {
+			return true
+		}
+	}
+	return false
+}
+
+// Contains returns true if the given peer is contained within this peer group
+func (g PeerGroup) Contains(peer *Member) bool {
+	for _, p := range g {
+		if p.Endpoint == peer.Endpoint {
+			return true
+		}
+	}
+	return false
+}
+
+// ContainsPeer returns true if the given peer is contained within this peer group
+func (g PeerGroup) ContainsPeer(endpoint string) bool {
+	for _, p := range g {
+		if p.Endpoint == endpoint {
+			return true
+		}
+	}
+	return false
+}
+
+func (g PeerGroup) Len() int {
+	return len(g)
+}
+
+func (g PeerGroup) Less(i, j int) bool {
+	return g[i].Endpoint < g[j].Endpoint
+}
+
+func (g PeerGroup) Swap(i, j int) {
+	g[i], g[j] = g[j], g[i]
+}
+
+// Local returns the local peer from the group
+func (g PeerGroup) Local() (*Member, bool) {
+	for _, p := range g {
+		if p.Local {
+			return p, true
+		}
+	}
+	return nil, false
+}
+
+// Remote returns a PeerGroup subset that only includes remote peers
+func (g PeerGroup) Remote() PeerGroup {
+	var pg PeerGroup
+	for _, p := range g {
+		if !p.Local {
+			pg = append(pg, p)
+		}
+	}
+	return pg
+}
+
+// Shuffle returns a randomly shuffled PeerGroup
+func (g PeerGroup) Shuffle() PeerGroup {
+	var pg PeerGroup
+	for _, i := range rand.Perm(len(g)) {
+		pg = append(pg, g[i])
+	}
+
+	return pg
+}
+
+// Merge adds the given peers to the group if they don't already exist
+func Merge(g PeerGroup, peers ...*Member) PeerGroup {
+	for _, p := range peers {
+		if !g.Contains(p) {
+			g = append(g, p)
+		}
+	}
+	return g
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/multirequest/multirequest.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/multirequest/multirequest.go
new file mode 100644
index 00000000..9843e581
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/multirequest/multirequest.go
@@ -0,0 +1,105 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package multirequest
+
+import (
+	"context"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common"
+)
+
+var logger = flogging.MustGetLogger("ext_multirequest")
+
+// Request is the request to execute
+type Request func(ctxt context.Context) (common.Values, error)
+
+type req struct {
+	id      string
+	execute Request
+}
+
+type res struct {
+	id     string
+	values common.Values
+	err    error
+}
+
+// Response contains the response for a given request ID
+type Response struct {
+	RequestID string
+	Values    common.Values
+}
+
+// MultiRequest executes multiple requests and returns the first, non-error response
+type MultiRequest struct {
+	requests []*req
+}
+
+// New returns a new MultiRequest
+func New() *MultiRequest {
+	return &MultiRequest{}
+}
+
+// Add adds a request function
+func (r *MultiRequest) Add(id string, execute Request) {
+	r.requests = append(r.requests, &req{id: id, execute: execute})
+}
+
+// Execute executes the requests concurrently and returns the responses.
+func (r *MultiRequest) Execute(ctxt context.Context) *Response {
+	respChan := make(chan *res, len(r.requests)+1)
+
+	cctxt, cancel := context.WithCancel(ctxt)
+	defer cancel()
+
+	for _, request := range r.requests {
+		go func(r *req) {
+			ccctxt, cancelReq := context.WithCancel(cctxt)
+			defer cancelReq()
+			values, err := r.execute(ccctxt)
+			respChan <- &res{id: r.id, values: values, err: err}
+		}(request)
+	}
+
+	resp := &Response{}
+	done := false
+
+	// Wait for all responses
+	for range r.requests {
+		response := <-respChan
+
+		if done {
+			continue
+		}
+
+		if handleResponse(response, resp) {
+			done = true
+			cancel()
+		}
+	}
+
+	return resp
+}
+
+func handleResponse(response *res, resp *Response) bool {
+	if response.err != nil {
+		logger.Debugf("Error response was received from [%s]: %s", response.id, response.err)
+		return false
+	}
+
+	resp.RequestID = response.id
+	resp.Values = resp.Values.Merge(response.values)
+
+	if response.values.AllSet() {
+		logger.Debugf("All values were received from [%s]", response.id)
+		return true
+	}
+
+	logger.Debugf("One or more values are missing in response from [%s]", response.id)
+	return false
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/requestmgr/requestmgr.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/requestmgr/requestmgr.go
new file mode 100644
index 00000000..25f69a1f
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/requestmgr/requestmgr.go
@@ -0,0 +1,207 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package requestmgr
+
+import (
+	"context"
+	"sync"
+	"sync/atomic"
+	"time"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/pkg/errors"
+)
+
+var logger = flogging.MustGetLogger("ext_requestmgr")
+
+// Element contains transient data for a single key
+type Element struct {
+	Namespace  string
+	Collection string
+	Key        string
+	Value      []byte
+	Expiry     time.Time
+}
+
+// Elements is a slice of Element
+type Elements []*Element
+
+// Get returns the Element matching the given namespace, collection, and key.
+func (e Elements) Get(ns, coll, key string) (*Element, bool) {
+	for _, element := range e {
+		if element.Namespace == ns && element.Collection == coll && element.Key == key {
+			return element, true
+		}
+	}
+	return nil, false
+}
+
+// Response is the response from a remote peer for a collection of transient data keys
+type Response struct {
+	Endpoint  string   // The endpoint of the peer that sent the response
+	MSPID     string   // The MSP ID of the peer that sent the response
+	Signature []byte   // The signature of the peer that provided the data
+	Identity  []byte   // The identity of the peer that sent the response
+	Data      Elements // The transient data
+}
+
+// Request is an interface to get the response
+type Request interface {
+	ID() uint64
+	GetResponse(context context.Context) (*Response, error)
+	Cancel()
+}
+
+// RequestMgr is an interface to create a new request and to respond to the request
+type RequestMgr interface {
+	Respond(reqID uint64, response *Response)
+	NewRequest() Request
+}
+
+type requestMgr struct {
+	mutex sync.RWMutex
+	mgrs  map[string]*channelMgr
+}
+
+var mgr = newRequestMgr()
+
+// Get returns the RequestMgr for the given channel
+func Get(channelID string) RequestMgr {
+	return mgr.forChannel(channelID)
+}
+
+func newRequestMgr() *requestMgr {
+	return &requestMgr{
+		mgrs: make(map[string]*channelMgr),
+	}
+}
+
+func (m *requestMgr) forChannel(channelID string) RequestMgr {
+	m.mutex.RLock()
+	cm, ok := m.mgrs[channelID]
+	m.mutex.RUnlock()
+
+	if ok {
+		return cm
+	}
+
+	m.mutex.Lock()
+	defer m.mutex.Unlock()
+
+	cm = newChannelMgr(channelID)
+	m.mgrs[channelID] = cm
+	return cm
+}
+
+type channelMgr struct {
+	mutex         sync.RWMutex
+	channelID     string
+	requests      map[uint64]*request
+	nextRequestID uint64
+}
+
+func newChannelMgr(channelID string) *channelMgr {
+	logger.Debugf("[%s] Creating new channel request manager", channelID)
+	return &channelMgr{
+		channelID:     channelID,
+		requests:      make(map[uint64]*request),
+		nextRequestID: 1000000000,
+	}
+}
+
+func (c *channelMgr) NewRequest() Request {
+	c.mutex.Lock()
+	defer c.mutex.Unlock()
+
+	reqID := c.newRequestID()
+
+	logger.Debugf("[%s] Subscribing to transient data request %d", c.channelID, reqID)
+
+	s := newRequest(reqID, c.channelID, c.remove)
+	c.requests[reqID] = s
+
+	return s
+}
+
+func (c *channelMgr) Respond(reqID uint64, response *Response) {
+	c.mutex.RLock()
+	defer c.mutex.RUnlock()
+
+	s, ok := c.requests[reqID]
+	if !ok {
+		logger.Debugf("[%s] No transient data requests for %d", c.channelID, reqID)
+		return
+	}
+
+	logger.Debugf("[%s] Publishing transient data response %d", c.channelID, reqID)
+	s.respond(response)
+}
+
+func (c *channelMgr) remove(reqID uint64) {
+	c.mutex.Lock()
+	defer c.mutex.Unlock()
+
+	if _, ok := c.requests[reqID]; !ok {
+		return
+	}
+
+	delete(c.requests, reqID)
+	logger.Debugf("[%s] Unsubscribed from transient data request %d", c.channelID, reqID)
+}
+
+func (c *channelMgr) newRequestID() uint64 {
+	return atomic.AddUint64(&c.nextRequestID, 1)
+}
+
+type request struct {
+	reqID     uint64
+	channelID string
+	remove    func(reqID uint64)
+	respChan  chan *Response
+	done      bool
+}
+
+func newRequest(reqID uint64, channelID string, remove func(reqID uint64)) *request {
+	return &request{
+		reqID:     reqID,
+		channelID: channelID,
+		respChan:  make(chan *Response, 1),
+		remove:    remove,
+	}
+}
+
+func (r *request) ID() uint64 {
+	return r.reqID
+}
+
+func (r *request) GetResponse(ctxt context.Context) (*Response, error) {
+	if r.done {
+		return nil, errors.New("request has already completed")
+	}
+
+	logger.Debugf("[%s] Waiting for response to request %d", r.channelID, r.ID())
+
+	defer r.Cancel()
+
+	select {
+	case <-ctxt.Done():
+		logger.Debugf("[%s] Request %d was timed out or cancelled", r.channelID, r.ID())
+		return nil, ctxt.Err()
+	case item := <-r.respChan:
+		logger.Debugf("[%s] Got response for request %d", r.channelID, r.ID())
+		return item, nil
+	}
+}
+
+func (r *request) Cancel() {
+	r.remove(r.reqID)
+	r.done = true
+}
+
+func (r *request) respond(res *Response) {
+	r.respChan <- res
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/support/collconfigretriever.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/support/collconfigretriever.go
new file mode 100644
index 00000000..e5a19151
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/support/collconfigretriever.go
@@ -0,0 +1,206 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package support
+
+import (
+	"fmt"
+	"reflect"
+
+	"github.com/bluele/gcache"
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/core/ledger"
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	mspmgmt "github.com/hyperledger/fabric/msp/mgmt"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/pkg/errors"
+)
+
+type peerLedger interface {
+	// NewQueryExecutor gives handle to a query executor.
+	// A client can obtain more than one 'QueryExecutor's for parallel execution.
+	// Any synchronization should be performed at the implementation level if required
+	NewQueryExecutor() (ledger.QueryExecutor, error)
+}
+
+// CollectionConfigRetriever loads and caches collection configuration and policies
+type CollectionConfigRetriever struct {
+	channelID string
+	ledger    peerLedger
+	cache     gcache.Cache
+}
+
+type blockPublisher interface {
+	AddCCUpgradeHandler(handler gossipapi.ChaincodeUpgradeHandler)
+}
+
+// NewCollectionConfigRetriever returns a new collection configuration retriever
+func NewCollectionConfigRetriever(channelID string, ledger peerLedger, blockPublisher blockPublisher) *CollectionConfigRetriever {
+	r := &CollectionConfigRetriever{
+		channelID: channelID,
+		ledger:    ledger,
+	}
+
+	r.cache = gcache.New(0).Simple().LoaderFunc(
+		func(key interface{}) (interface{}, error) {
+			ccID := key.(string)
+			configs, err := r.loadConfigAndPolicy(ccID)
+			if err != nil {
+				logger.Debugf("Error loading collection configs for chaincode [%s]: %s", ccID, err)
+				return nil, err
+			}
+			return configs, nil
+		}).Build()
+
+	// Add a handler to remove the collection configs from cache when the chaincode is upgraded
+	blockPublisher.AddCCUpgradeHandler(func(blockNum uint64, txID string, chaincodeName string) error {
+		if r.cache.Remove(chaincodeName) {
+			logger.Infof("Chaincode [%s] was upgraded. Removed collection configs from cache.", chaincodeName)
+		}
+		return nil
+	})
+
+	return r
+}
+
+type cacheItem struct {
+	config *common.StaticCollectionConfig
+	policy privdata.CollectionAccessPolicy
+}
+
+type cacheItems []*cacheItem
+
+func (c cacheItems) get(coll string) (*cacheItem, error) {
+	for _, item := range c {
+		if item.config.Name == coll {
+			return item, nil
+		}
+	}
+	return nil, errors.Errorf("configuration not found for collection [%s]", coll)
+}
+
+func (c cacheItems) config(coll string) (*common.StaticCollectionConfig, error) {
+	item, err := c.get(coll)
+	if err != nil {
+		return nil, err
+	}
+	return item.config, nil
+}
+
+func (c cacheItems) policy(coll string) (privdata.CollectionAccessPolicy, error) {
+	item, err := c.get(coll)
+	if err != nil {
+		return nil, err
+	}
+	return item.policy, nil
+}
+
+// Config returns the configuration for the given collection
+func (s *CollectionConfigRetriever) Config(ns, coll string) (*common.StaticCollectionConfig, error) {
+	logger.Debugf("[%s] Retrieving collection configuration for chaincode [%s]", s.channelID, ns)
+	item, err := s.cache.Get(ns)
+	if err != nil {
+		return nil, err
+	}
+
+	configs, ok := item.(cacheItems)
+	if !ok {
+		panic(fmt.Sprintf("unexpected type in cache: %s", reflect.TypeOf(item)))
+	}
+
+	return configs.config(coll)
+}
+
+// Policy returns the collection access policy
+func (s *CollectionConfigRetriever) Policy(ns, coll string) (privdata.CollectionAccessPolicy, error) {
+	logger.Debugf("[%s] Retrieving collection policy for chaincode [%s]", s.channelID, ns)
+	item, err := s.cache.Get(ns)
+	if err != nil {
+		return nil, err
+	}
+
+	configs, ok := item.(cacheItems)
+	if !ok {
+		panic(fmt.Sprintf("unexpected type in cache: %s", reflect.TypeOf(item)))
+	}
+
+	return configs.policy(coll)
+}
+
+func (s *CollectionConfigRetriever) loadConfigAndPolicy(ns string) (cacheItems, error) {
+	configs, err := s.loadConfigs(ns)
+	if err != nil {
+		return nil, err
+	}
+
+	var items []*cacheItem
+	for _, config := range configs {
+		policy, err := s.loadPolicy(ns, config)
+		if err != nil {
+			return nil, err
+		}
+		items = append(items, &cacheItem{
+			config: config,
+			policy: policy,
+		})
+	}
+
+	return items, nil
+}
+
+func (s *CollectionConfigRetriever) loadConfigs(ns string) ([]*common.StaticCollectionConfig, error) {
+	logger.Debugf("[%s] Loading collection configs for chaincode [%s]", s.channelID, ns)
+
+	cpBytes, err := s.getCCPBytes(ns)
+	if err != nil {
+		return nil, errors.Wrapf(err, "error retrieving collection config for chaincode [%s]", ns)
+	}
+	if cpBytes == nil {
+		return nil, errors.Errorf("no collection config for chaincode [%s]", ns)
+	}
+
+	cp := &common.CollectionConfigPackage{}
+	err = proto.Unmarshal(cpBytes, cp)
+	if err != nil {
+		return nil, errors.Wrapf(err, "invalid collection configuration for [%s]", ns)
+	}
+
+	var configs []*common.StaticCollectionConfig
+	for _, collConfig := range cp.Config {
+		config := collConfig.GetStaticCollectionConfig()
+		logger.Debugf("[%s] Checking collection config for [%s:%+v]", s.channelID, ns, config)
+		if config == nil {
+			logger.Warningf("[%s] No config found for a collection in namespace [%s]", s.channelID, ns)
+			continue
+		}
+		configs = append(configs, config)
+	}
+
+	return configs, nil
+}
+
+func (s *CollectionConfigRetriever) loadPolicy(ns string, config *common.StaticCollectionConfig) (privdata.CollectionAccessPolicy, error) {
+	logger.Debugf("[%s] Loading collection policy for [%s:%s]", s.channelID, ns, config.Name)
+
+	colAP := &privdata.SimpleCollection{}
+	err := colAP.Setup(config, mspmgmt.GetIdentityDeserializer(s.channelID))
+	if err != nil {
+		return nil, errors.Wrapf(err, "error setting up collection policy %s", config.Name)
+	}
+
+	return colAP, nil
+}
+
+func (s *CollectionConfigRetriever) getCCPBytes(ns string) ([]byte, error) {
+	qe, err := s.ledger.NewQueryExecutor()
+	if err != nil {
+		return nil, err
+	}
+	defer qe.Done()
+
+	return qe.GetState("lscc", privdata.BuildCollectionKVSKey(ns))
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/support/support.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/support/support.go
new file mode 100644
index 00000000..cfd20299
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/common/support/support.go
@@ -0,0 +1,66 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package support
+
+import (
+	"github.com/bluele/gcache"
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/core/ledger"
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	"github.com/hyperledger/fabric/protos/common"
+)
+
+var logger = flogging.MustGetLogger("ext_support")
+
+type ledgerProvider func(channelID string) ledger.PeerLedger
+type blockPublisherProvider func(channelID string) gossipapi.BlockPublisher
+
+// Support holds the ledger provider and the cache
+type Support struct {
+	getLedger              ledgerProvider
+	configRetrieverCache   gcache.Cache
+	blockPublisherProvider blockPublisherProvider
+}
+
+// New creates a new Support using the ledger provider
+func New(ledgerProvider ledgerProvider, blockPublisherProvider blockPublisherProvider) *Support {
+	s := &Support{
+		getLedger:              ledgerProvider,
+		blockPublisherProvider: blockPublisherProvider,
+	}
+	s.configRetrieverCache = gcache.New(0).Simple().LoaderFunc(
+		func(key interface{}) (interface{}, error) {
+			channelID := key.(string)
+			logger.Debugf("[%s] Creating collection config retriever", channelID)
+			return NewCollectionConfigRetriever(channelID, s.getLedger(channelID), blockPublisherProvider(channelID)), nil
+		}).Build()
+	return s
+}
+
+// Config returns the configuration for the given collection
+func (s *Support) Config(channelID, ns, coll string) (*common.StaticCollectionConfig, error) {
+	ccRetriever, err := s.configRetrieverCache.Get(channelID)
+	if err != nil {
+		return nil, err
+	}
+	return ccRetriever.(*CollectionConfigRetriever).Config(ns, coll)
+}
+
+// Policy returns the collection access policy for the given collection
+func (s *Support) Policy(channelID, ns, coll string) (privdata.CollectionAccessPolicy, error) {
+	ccRetriever, err := s.configRetrieverCache.Get(channelID)
+	if err != nil {
+		return nil, err
+	}
+	return ccRetriever.(*CollectionConfigRetriever).Policy(ns, coll)
+}
+
+// BlockPublisher returns the block publisher for the given channel
+func (s *Support) BlockPublisher(channelID string) gossipapi.BlockPublisher {
+	return s.blockPublisherProvider(channelID)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/config/config.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/config/config.go
new file mode 100644
index 00000000..85d942a5
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/config/config.go
@@ -0,0 +1,141 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package config
+
+import (
+	"path/filepath"
+	"time"
+
+	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
+	"github.com/spf13/viper"
+)
+
+const (
+	confRoles            = "ledger.roles"
+	confPvtDataCacheSize = "ledger.blockchain.pvtDataStorage.cacheSize"
+
+	confTransientDataLeveldb             = "transientDataLeveldb"
+	confTransientDataCleanupIntervalTime = "coll.transientdata.cleanupExpired.Interval"
+	confTransientDataCacheSize           = "coll.transientdata.cacheSize"
+	confTransientDataPullTimeout         = "peer.gossip.transientData.pullTimeout"
+
+	confOLCollLeveldb              = "offLedgerLeveldb"
+	confOLCollCleanupIntervalTime  = "coll.offledger.cleanupExpired.Interval"
+	confOLCollMaxPeersForRetrieval = "coll.offledger.maxpeers"
+	confOLCollCacheSize            = "coll.offledger.cacheSize"
+	confOLCollPullTimeout          = "coll.offledger.gossip.pullTimeout"
+
+	confBlockPublisherBufferSize = "blockpublisher.buffersize"
+
+	defaultTransientDataCleanupIntervalTime = 5 * time.Second
+	defaultTransientDataCacheSize           = 100000
+	defaultTransientDataPullTimeout         = 5 * time.Second
+
+	defaultOLCollCleanupIntervalTime  = 5 * time.Second
+	defaultOLCollMaxPeersForRetrieval = 2
+	defaultOLCollCacheSize            = 10000
+	defaultOLCollPullTimeout          = 5 * time.Second
+
+	defaultBlockPublisherBufferSize = 100
+)
+
+// GetRoles returns the roles of the peer. Empty return value indicates that the peer has all roles.
+func GetRoles() string {
+	return viper.GetString(confRoles)
+}
+
+// GetPvtDataCacheSize returns the number of pvt data per block to keep the in the cache
+func GetPvtDataCacheSize() int {
+	pvtDataCacheSize := viper.GetInt(confPvtDataCacheSize)
+	if !viper.IsSet(confPvtDataCacheSize) {
+		pvtDataCacheSize = 10
+	}
+	return pvtDataCacheSize
+}
+
+// GetTransientDataLevelDBPath returns the filesystem path that is used to maintain the transient data level db
+func GetTransientDataLevelDBPath() string {
+	return filepath.Join(ledgerconfig.GetRootPath(), confTransientDataLeveldb)
+}
+
+// GetTransientDataExpiredIntervalTime is time when background routine check expired transient data in db to cleanup.
+func GetTransientDataExpiredIntervalTime() time.Duration {
+	timeout := viper.GetDuration(confTransientDataCleanupIntervalTime)
+	if timeout == 0 {
+		return defaultTransientDataCleanupIntervalTime
+	}
+	return timeout
+}
+
+// GetTransientDataCacheSize returns the size of the transient data cache
+func GetTransientDataCacheSize() int {
+	size := viper.GetInt(confTransientDataCacheSize)
+	if size <= 0 {
+		return defaultTransientDataCacheSize
+	}
+	return size
+}
+
+// GetOLCollLevelDBPath returns the filesystem path that is used to maintain the off-ledger level db
+func GetOLCollLevelDBPath() string {
+	return filepath.Join(ledgerconfig.GetRootPath(), confOLCollLeveldb)
+}
+
+// GetOLCollExpirationCheckInterval is time when the background routine checks expired collection data in db to cleanup.
+func GetOLCollExpirationCheckInterval() time.Duration {
+	timeout := viper.GetDuration(confOLCollCleanupIntervalTime)
+	if timeout == 0 {
+		return defaultOLCollCleanupIntervalTime
+	}
+	return timeout
+}
+
+// GetTransientDataPullTimeout is the amount of time a peer waits for a response from another peer for transient data.
+func GetTransientDataPullTimeout() time.Duration {
+	timeout := viper.GetDuration(confTransientDataPullTimeout)
+	if timeout == 0 {
+		timeout = defaultTransientDataPullTimeout
+	}
+	return timeout
+}
+
+// GetBlockPublisherBufferSize returns the size of the block publisher channel buffer for various block events
+func GetBlockPublisherBufferSize() int {
+	size := viper.GetInt(confBlockPublisherBufferSize)
+	if size == 0 {
+		return defaultBlockPublisherBufferSize
+	}
+	return size
+}
+
+// GetOLCollMaxPeersForRetrieval returns the number of peers that should be messaged
+// to retrieve collection data that is not stored locally.
+func GetOLCollMaxPeersForRetrieval() int {
+	maxPeers := viper.GetInt(confOLCollMaxPeersForRetrieval)
+	if maxPeers <= 0 {
+		maxPeers = defaultOLCollMaxPeersForRetrieval
+	}
+	return maxPeers
+}
+
+// GetOLCollCacheSize returns the size of the off-ledger cache
+func GetOLCollCacheSize() int {
+	size := viper.GetInt(confOLCollCacheSize)
+	if size <= 0 {
+		return defaultOLCollCacheSize
+	}
+	return size
+}
+
+// GetOLCollPullTimeout is the amount of time a peer waits for a response from another peer for transient data.
+func GetOLCollPullTimeout() time.Duration {
+	timeout := viper.GetDuration(confOLCollPullTimeout)
+	if timeout == 0 {
+		timeout = defaultOLCollPullTimeout
+	}
+	return timeout
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/endorser/endorser.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/endorser/endorser.go
new file mode 100644
index 00000000..db3a6056
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/endorser/endorser.go
@@ -0,0 +1,112 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package endorser
+
+import (
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/pkg/errors"
+)
+
+var endorserLogger = flogging.MustGetLogger("ext_endorser")
+
+// FilterPubSimulationResults filters out all off-ledger (including transient data) read-write sets from the simulation results
+// so that they won't be included in the block.
+func FilterPubSimulationResults(collConfigs map[string]*common.CollectionConfigPackage, pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error) {
+	if collConfigs != nil {
+		// Filter out all off-ledger hashed read/write sets
+		return newFilter(collConfigs).filter(pubSimulationResults)
+	}
+
+	endorserLogger.Debugf("No collection r/w sets.")
+	return pubSimulationResults, nil
+}
+
+type collRWSetFilter struct {
+	collConfigs map[string]*common.CollectionConfigPackage
+}
+
+func newFilter(collConfigs map[string]*common.CollectionConfigPackage) *collRWSetFilter {
+	return &collRWSetFilter{
+		collConfigs: collConfigs,
+	}
+}
+
+func (f *collRWSetFilter) filter(pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error) {
+	endorserLogger.Debugf("Filtering off-ledger collection types...")
+	filteredResults := &rwset.TxReadWriteSet{
+		DataModel: pubSimulationResults.DataModel,
+	}
+
+	// Filter out off-ledger collections from read/write sets
+	for _, rwSet := range pubSimulationResults.NsRwset {
+		endorserLogger.Debugf("Checking chaincode [%s] for off-ledger collection types...", rwSet.Namespace)
+
+		filteredRWSet, err := f.filterNamespace(rwSet)
+		if err != nil {
+			return nil, err
+		}
+
+		if len(filteredRWSet.Rwset) > 0 || len(filteredRWSet.CollectionHashedRwset) > 0 {
+			endorserLogger.Debugf("Adding rw-set for [%s]", rwSet.Namespace)
+			filteredResults.NsRwset = append(filteredResults.NsRwset, filteredRWSet)
+		} else {
+			endorserLogger.Debugf("Not adding rw-set for [%s] since everything has been filtered out", rwSet.Namespace)
+		}
+	}
+
+	return filteredResults, nil
+}
+
+func (f *collRWSetFilter) filterNamespace(nsRWSet *rwset.NsReadWriteSet) (*rwset.NsReadWriteSet, error) {
+	var filteredCollRWSets []*rwset.CollectionHashedReadWriteSet
+	for _, collRWSet := range nsRWSet.CollectionHashedRwset {
+		endorserLogger.Debugf("Checking collection [%s:%s] to see if it is an off-ledger type...", nsRWSet.Namespace, collRWSet.CollectionName)
+		offLedger, err := f.isOffLedger(nsRWSet.Namespace, collRWSet.CollectionName)
+		if err != nil {
+			return nil, err
+		}
+		if !offLedger {
+			endorserLogger.Debugf("... adding hashed rw-set for collection [%s:%s] since it IS NOT an off-ledger type", nsRWSet.Namespace, collRWSet.CollectionName)
+			filteredCollRWSets = append(filteredCollRWSets, collRWSet)
+		} else {
+			endorserLogger.Debugf("... removing hashed rw-set for collection [%s:%s] since it IS an off-ledger type", nsRWSet.Namespace, collRWSet.CollectionName)
+		}
+	}
+
+	return &rwset.NsReadWriteSet{
+		Namespace:             nsRWSet.Namespace,
+		Rwset:                 nsRWSet.Rwset,
+		CollectionHashedRwset: filteredCollRWSets,
+	}, nil
+}
+
+func (f *collRWSetFilter) isOffLedger(ns, coll string) (bool, error) {
+	collConfig, ok := f.collConfigs[ns]
+	if !ok {
+		return false, errors.Errorf("config for collection [%s:%s] not found", ns, coll)
+	}
+
+	for _, config := range collConfig.Config {
+		staticConfig := config.GetStaticCollectionConfig()
+		if staticConfig == nil {
+			return false, errors.Errorf("config for collection [%s:%s] not found", ns, coll)
+		}
+		if staticConfig.Name == coll {
+			return isCollOffLedger(staticConfig), nil
+		}
+	}
+
+	return false, errors.Errorf("config for collection [%s:%s] not found", ns, coll)
+}
+
+func isCollOffLedger(collConfig *common.StaticCollectionConfig) bool {
+	return collConfig.Type == common.CollectionType_COL_TRANSIENT ||
+		collConfig.Type == common.CollectionType_COL_OFFLEDGER ||
+		collConfig.Type == common.CollectionType_COL_DCAS
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher/blockpublisher.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher/blockpublisher.go
new file mode 100644
index 00000000..a9189e63
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher/blockpublisher.go
@@ -0,0 +1,514 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package blockpublisher
+
+import (
+	"sync"
+	"sync/atomic"
+
+	"github.com/bluele/gcache"
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/rwsetutil"
+	ledgerutil "github.com/hyperledger/fabric/core/ledger/util"
+	"github.com/hyperledger/fabric/extensions/gossip/api"
+	cb "github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	pb "github.com/hyperledger/fabric/protos/peer"
+	"github.com/hyperledger/fabric/protoutil"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+)
+
+const (
+	lsccID       = "lscc"
+	upgradeEvent = "upgrade"
+)
+
+var logger = flogging.MustGetLogger("ext_blockpublisher")
+
+type write struct {
+	blockNum  uint64
+	txID      string
+	namespace string
+	w         *kvrwset.KVWrite
+}
+
+type read struct {
+	blockNum  uint64
+	txID      string
+	namespace string
+	r         *kvrwset.KVRead
+}
+
+type ccEvent struct {
+	blockNum uint64
+	txID     string
+	event    *pb.ChaincodeEvent
+}
+
+type configUpdate struct {
+	blockNum     uint64
+	configUpdate *cb.ConfigUpdate
+}
+
+// Provider maintains a cache of Block Publishers - one per channel
+type Provider struct {
+	cache gcache.Cache
+}
+
+// NewProvider returns a new block publisher provider
+func NewProvider() *Provider {
+	return &Provider{
+		cache: gcache.New(0).LoaderFunc(func(channelID interface{}) (interface{}, error) {
+			return New(channelID.(string)), nil
+		}).Build(),
+	}
+}
+
+// ForChannel returns the block publisher for the given channel
+func (p *Provider) ForChannel(channelID string) api.BlockPublisher {
+	publisher, err := p.cache.Get(channelID)
+	if err != nil {
+		// This should never happen
+		panic(err.Error())
+	}
+	return publisher.(*Publisher)
+}
+
+// Close closes all block publishers
+func (p *Provider) Close() {
+	for _, publisher := range p.cache.GetALL() {
+		publisher.(*Publisher).Close()
+	}
+}
+
+// Publisher traverses a block and publishes KV read, KV write, and chaincode events to registered handlers
+type Publisher struct {
+	channelID            string
+	writeHandlers        []api.WriteHandler
+	readHandlers         []api.ReadHandler
+	ccEventHandlers      []api.ChaincodeEventHandler
+	configUpdateHandlers []api.ConfigUpdateHandler
+	mutex                sync.RWMutex
+	blockChan            chan *cb.Block
+	wChan                chan *write
+	rChan                chan *read
+	ccEvtChan            chan *ccEvent
+	configUpdateChan     chan *configUpdate
+	doneChan             chan struct{}
+	closed               uint32
+}
+
+// New returns a new block Publisher for the given channel
+func New(channelID string) *Publisher {
+	bufferSize := config.GetBlockPublisherBufferSize()
+
+	p := &Publisher{
+		channelID:        channelID,
+		blockChan:        make(chan *cb.Block, bufferSize),
+		wChan:            make(chan *write, bufferSize),
+		rChan:            make(chan *read, bufferSize),
+		ccEvtChan:        make(chan *ccEvent, bufferSize),
+		configUpdateChan: make(chan *configUpdate, bufferSize),
+		doneChan:         make(chan struct{}),
+	}
+	go p.listen()
+	return p
+}
+
+// Close releases all resources associated with the Publisher. Calling this function
+// multiple times has no effect.
+func (p *Publisher) Close() {
+	if atomic.CompareAndSwapUint32(&p.closed, 0, 1) {
+		p.doneChan <- struct{}{}
+	} else {
+		logger.Debugf("[%s] Block Publisher already closed", p.channelID)
+	}
+}
+
+// AddConfigUpdateHandler adds a handler for config update events
+func (p *Publisher) AddConfigUpdateHandler(handler api.ConfigUpdateHandler) {
+	p.mutex.Lock()
+	defer p.mutex.Unlock()
+
+	logger.Debugf("[%s] Adding config update", p.channelID)
+	p.configUpdateHandlers = append(p.configUpdateHandlers, handler)
+}
+
+// AddWriteHandler adds a new handler for KV writes
+func (p *Publisher) AddWriteHandler(handler api.WriteHandler) {
+	p.mutex.Lock()
+	defer p.mutex.Unlock()
+
+	logger.Debugf("[%s] Adding write", p.channelID)
+	p.writeHandlers = append(p.writeHandlers, handler)
+}
+
+// AddReadHandler adds a new handler for KV reads
+func (p *Publisher) AddReadHandler(handler api.ReadHandler) {
+	p.mutex.Lock()
+	defer p.mutex.Unlock()
+
+	logger.Debugf("[%s] Adding read", p.channelID)
+	p.readHandlers = append(p.readHandlers, handler)
+}
+
+// AddCCEventHandler adds a new handler for chaincode events
+func (p *Publisher) AddCCEventHandler(handler api.ChaincodeEventHandler) {
+	p.mutex.Lock()
+	defer p.mutex.Unlock()
+
+	logger.Debugf("[%s] Adding chaincode event", p.channelID)
+	p.ccEventHandlers = append(p.ccEventHandlers, handler)
+}
+
+// AddCCUpgradeHandler adds a handler for chaincode upgrade events
+func (p *Publisher) AddCCUpgradeHandler(handler api.ChaincodeUpgradeHandler) {
+	logger.Debugf("[%s] Adding chaincode upgrade", p.channelID)
+	p.AddCCEventHandler(newChaincodeUpgradeHandler(p.channelID, handler))
+}
+
+// Publish publishes a block
+func (p *Publisher) Publish(block *cb.Block) {
+	newBlockEvent(p.channelID, block, p.wChan, p.rChan, p.ccEvtChan, p.configUpdateChan).publish()
+}
+
+func (p *Publisher) listen() {
+	for {
+		select {
+		case w := <-p.wChan:
+			p.handleWrite(w)
+		case r := <-p.rChan:
+			p.handleRead(r)
+		case ccEvt := <-p.ccEvtChan:
+			p.handleCCEvent(ccEvt)
+		case cu := <-p.configUpdateChan:
+			p.handleConfigUpdate(cu)
+		case <-p.doneChan:
+			logger.Debugf("[%s] Exiting block Publisher", p.channelID)
+			return
+		}
+	}
+}
+
+func (p *Publisher) handleRead(r *read) {
+	logger.Debugf("[%s] Handling read: [%s]", p.channelID, r)
+	for _, handleRead := range p.getReadHandlers() {
+		if err := handleRead(r.blockNum, r.txID, r.namespace, r.r); err != nil {
+			logger.Warningf("[%s] Error returned from KV read handler: %s", p.channelID, err)
+		}
+	}
+}
+
+func (p *Publisher) handleWrite(w *write) {
+	logger.Debugf("[%s] Handling write: [%s]", p.channelID, w)
+	for _, handleWrite := range p.getWriteHandlers() {
+		if err := handleWrite(w.blockNum, w.txID, w.namespace, w.w); err != nil {
+			logger.Warningf("[%s] Error returned from KV write handler: %s", p.channelID, err)
+		}
+	}
+}
+
+func (p *Publisher) handleCCEvent(event *ccEvent) {
+	logger.Debugf("[%s] Handling chaincode event: [%s]", p.channelID, event)
+	for _, handleCCEvent := range p.getCCEventHandlers() {
+		if err := handleCCEvent(event.blockNum, event.txID, event.event); err != nil {
+			logger.Warningf("[%s] Error returned from CC event handler: %s", p.channelID, err)
+		}
+	}
+}
+
+func (p *Publisher) handleConfigUpdate(cu *configUpdate) {
+	logger.Debugf("[%s] Handling config update [%s]", p.channelID, cu)
+	for _, handleConfigUpdate := range p.getConfigUpdateHandlers() {
+		if err := handleConfigUpdate(cu.blockNum, cu.configUpdate); err != nil {
+			logger.Warningf("[%s] Error returned from config update handler: %s", p.channelID, err)
+		}
+	}
+}
+
+func (p *Publisher) getReadHandlers() []api.ReadHandler {
+	p.mutex.RLock()
+	defer p.mutex.RUnlock()
+
+	handlers := make([]api.ReadHandler, len(p.readHandlers))
+	copy(handlers, p.readHandlers)
+	return handlers
+}
+
+func (p *Publisher) getWriteHandlers() []api.WriteHandler {
+	p.mutex.RLock()
+	defer p.mutex.RUnlock()
+
+	handlers := make([]api.WriteHandler, len(p.writeHandlers))
+	copy(handlers, p.writeHandlers)
+	return handlers
+}
+
+func (p *Publisher) getCCEventHandlers() []api.ChaincodeEventHandler {
+	p.mutex.RLock()
+	defer p.mutex.RUnlock()
+
+	handlers := make([]api.ChaincodeEventHandler, len(p.ccEventHandlers))
+	copy(handlers, p.ccEventHandlers)
+	return handlers
+}
+
+func (p *Publisher) getConfigUpdateHandlers() []api.ConfigUpdateHandler {
+	p.mutex.RLock()
+	defer p.mutex.RUnlock()
+
+	handlers := make([]api.ConfigUpdateHandler, len(p.configUpdateHandlers))
+	copy(handlers, p.configUpdateHandlers)
+	return handlers
+}
+
+type blockEvent struct {
+	channelID        string
+	block            *cb.Block
+	wChan            chan<- *write
+	rChan            chan<- *read
+	ccEvtChan        chan<- *ccEvent
+	configUpdateChan chan<- *configUpdate
+}
+
+func newBlockEvent(channelID string, block *cb.Block, wChan chan<- *write, rChan chan<- *read, ccEvtChan chan<- *ccEvent, configUpdateChan chan<- *configUpdate) *blockEvent {
+	return &blockEvent{
+		channelID:        channelID,
+		block:            block,
+		wChan:            wChan,
+		rChan:            rChan,
+		ccEvtChan:        ccEvtChan,
+		configUpdateChan: configUpdateChan,
+	}
+}
+
+func (p *blockEvent) publish() {
+	logger.Debugf("[%s] Publishing block #%d", p.channelID, p.block.Header.Number)
+	for i := range p.block.Data.Data {
+		envelope, err := protoutil.ExtractEnvelope(p.block, i)
+		if err != nil {
+			logger.Warningf("[%s] Error extracting envelope at index %d in block %d: %s", p.channelID, i, p.block.Header.Number, err)
+		} else {
+			err = p.visitEnvelope(i, envelope)
+			if err != nil {
+				logger.Warningf("[%s] Error checking envelope at index %d in block %d: %s", p.channelID, i, p.block.Header.Number, err)
+			}
+		}
+	}
+}
+
+func (p *blockEvent) visitEnvelope(i int, envelope *cb.Envelope) error {
+	payload, err := protoutil.ExtractPayload(envelope)
+	if err != nil {
+		return err
+	}
+
+	chdr, err := protoutil.UnmarshalChannelHeader(payload.Header.ChannelHeader)
+	if err != nil {
+		return err
+	}
+
+	if cb.HeaderType(chdr.Type) == cb.HeaderType_ENDORSER_TRANSACTION {
+		txFilter := ledgerutil.TxValidationFlags(p.block.Metadata.Metadata[cb.BlockMetadataIndex_TRANSACTIONS_FILTER])
+		code := txFilter.Flag(i)
+		if code != pb.TxValidationCode_VALID {
+			logger.Debugf("[%s] Transaction at index %d in block %d is not valid. Status code: %s", p.channelID, i, p.block.Header.Number, code)
+			return nil
+		}
+		tx, err := protoutil.GetTransaction(payload.Data)
+		if err != nil {
+			return err
+		}
+		newTxEvent(p.channelID, p.block.Header.Number, chdr.TxId, tx, p.wChan, p.rChan, p.ccEvtChan).publish()
+		return nil
+	}
+
+	if cb.HeaderType(chdr.Type) == cb.HeaderType_CONFIG_UPDATE {
+		envelope := &cb.ConfigUpdateEnvelope{}
+		if err := proto.Unmarshal(payload.Data, envelope); err != nil {
+			return err
+		}
+		newConfigUpdateEvent(p.channelID, p.block.Header.Number, envelope, p.configUpdateChan).publish()
+		return nil
+	}
+
+	return nil
+}
+
+type txEvent struct {
+	channelID string
+	blockNum  uint64
+	txID      string
+	tx        *pb.Transaction
+	wChan     chan<- *write
+	rChan     chan<- *read
+	ccEvtChan chan<- *ccEvent
+}
+
+func newTxEvent(channelID string, blockNum uint64, txID string, tx *pb.Transaction, wChan chan<- *write, rChan chan<- *read, ccEvtChan chan<- *ccEvent) *txEvent {
+	return &txEvent{
+		channelID: channelID,
+		blockNum:  blockNum,
+		txID:      txID,
+		tx:        tx,
+		wChan:     wChan,
+		rChan:     rChan,
+		ccEvtChan: ccEvtChan,
+	}
+}
+
+func (p *txEvent) publish() {
+	logger.Debugf("[%s] Publishing Tx %s in block #%d", p.channelID, p.txID, p.blockNum)
+	for i, action := range p.tx.Actions {
+		err := p.visitTXAction(action)
+		if err != nil {
+			logger.Warningf("[%s] Error checking TxAction at index %d: %s", p.channelID, i, err)
+		}
+	}
+}
+
+func (p *txEvent) visitTXAction(action *pb.TransactionAction) error {
+	chaPayload, err := protoutil.GetChaincodeActionPayload(action.Payload)
+	if err != nil {
+		return err
+	}
+	return p.visitChaincodeActionPayload(chaPayload)
+}
+
+func (p *txEvent) visitChaincodeActionPayload(chaPayload *pb.ChaincodeActionPayload) error {
+	cpp := &pb.ChaincodeProposalPayload{}
+	err := proto.Unmarshal(chaPayload.ChaincodeProposalPayload, cpp)
+	if err != nil {
+		return err
+	}
+
+	return p.visitAction(chaPayload.Action)
+}
+
+func (p *txEvent) visitAction(action *pb.ChaincodeEndorsedAction) error {
+	prp := &pb.ProposalResponsePayload{}
+	err := proto.Unmarshal(action.ProposalResponsePayload, prp)
+	if err != nil {
+		return err
+	}
+	return p.visitProposalResponsePayload(prp)
+}
+
+func (p *txEvent) visitProposalResponsePayload(prp *pb.ProposalResponsePayload) error {
+	chaincodeAction := &pb.ChaincodeAction{}
+	err := proto.Unmarshal(prp.Extension, chaincodeAction)
+	if err != nil {
+		return err
+	}
+	return p.visitChaincodeAction(chaincodeAction)
+}
+
+func (p *txEvent) visitChaincodeAction(chaincodeAction *pb.ChaincodeAction) error {
+	if len(chaincodeAction.Results) > 0 {
+		txRWSet := &rwsetutil.TxRwSet{}
+		if err := txRWSet.FromProtoBytes(chaincodeAction.Results); err != nil {
+			return err
+		}
+		p.visitTxReadWriteSet(txRWSet)
+	}
+
+	if len(chaincodeAction.Events) > 0 {
+		evt := &pb.ChaincodeEvent{}
+		if err := proto.Unmarshal(chaincodeAction.Events, evt); err != nil {
+			logger.Warningf("[%s] Invalid chaincode event for chaincode [%s]", p.channelID, chaincodeAction.ChaincodeId)
+			return errors.WithMessagef(err, "invalid chaincode event for chaincode [%s]", chaincodeAction.ChaincodeId)
+		}
+		p.ccEvtChan <- &ccEvent{
+			blockNum: p.blockNum,
+			txID:     p.txID,
+			event:    evt,
+		}
+	}
+
+	return nil
+}
+
+func (p *txEvent) visitTxReadWriteSet(txRWSet *rwsetutil.TxRwSet) {
+	for _, nsRWSet := range txRWSet.NsRwSets {
+		p.visitNsReadWriteSet(nsRWSet)
+	}
+}
+
+func (p *txEvent) visitNsReadWriteSet(nsRWSet *rwsetutil.NsRwSet) {
+	for _, r := range nsRWSet.KvRwSet.Reads {
+		p.rChan <- &read{
+			blockNum:  p.blockNum,
+			txID:      p.txID,
+			namespace: nsRWSet.NameSpace,
+			r:         r,
+		}
+	}
+	for _, w := range nsRWSet.KvRwSet.Writes {
+		p.wChan <- &write{
+			blockNum:  p.blockNum,
+			txID:      p.txID,
+			namespace: nsRWSet.NameSpace,
+			w:         w,
+		}
+	}
+}
+
+type configUpdateEvent struct {
+	channelID        string
+	blockNum         uint64
+	envelope         *cb.ConfigUpdateEnvelope
+	configUpdateChan chan<- *configUpdate
+}
+
+func newConfigUpdateEvent(channelID string, blockNum uint64, envelope *cb.ConfigUpdateEnvelope, configUpdateChan chan<- *configUpdate) *configUpdateEvent {
+	return &configUpdateEvent{
+		channelID:        channelID,
+		blockNum:         blockNum,
+		envelope:         envelope,
+		configUpdateChan: configUpdateChan,
+	}
+}
+
+func (p *configUpdateEvent) publish() {
+	cu := &cb.ConfigUpdate{}
+	if err := proto.Unmarshal(p.envelope.ConfigUpdate, cu); err != nil {
+		logger.Warningf("[%s] Error unmarshalling config update: %s", p.channelID, err)
+		return
+	}
+
+	logger.Debugf("[%s] Publishing Config Update [%s] in block #%d", p.channelID, cu, p.blockNum)
+
+	p.configUpdateChan <- &configUpdate{
+		blockNum:     p.blockNum,
+		configUpdate: cu,
+	}
+}
+
+func newChaincodeUpgradeHandler(channelID string, handleUpgrade api.ChaincodeUpgradeHandler) api.ChaincodeEventHandler {
+	return func(blockNum uint64, txID string, event *pb.ChaincodeEvent) error {
+		logger.Debugf("[%s] Handling chaincode event: %s", channelID, event)
+		if event.ChaincodeId != lsccID {
+			logger.Debugf("[%s] Chaincode event is not from 'lscc'", channelID)
+			return nil
+		}
+		if event.EventName != upgradeEvent {
+			logger.Debugf("[%s] Chaincode event from 'lscc' is not an upgrade event", channelID)
+			return nil
+		}
+
+		ccData := &pb.LifecycleEvent{}
+		err := proto.Unmarshal(event.Payload, ccData)
+		if err != nil {
+			return errors.WithMessage(err, "error unmarshalling chaincode upgrade event")
+		}
+
+		logger.Debugf("[%s] Handling chaincode upgrade of chaincode [%s]", channelID, ccData.ChaincodeName)
+		return handleUpgrade(blockNum, txID, ccData.ChaincodeName)
+	}
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/dispatcher/dispatcher.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/dispatcher/dispatcher.go
new file mode 100644
index 00000000..f409b7ec
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/dispatcher/dispatcher.go
@@ -0,0 +1,268 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package dispatcher
+
+import (
+	"time"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/extensions/collections/api/store"
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	extgossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	ledgerconfig "github.com/hyperledger/fabric/extensions/roles"
+	gossipapi "github.com/hyperledger/fabric/gossip/api"
+	gcommon "github.com/hyperledger/fabric/gossip/common"
+	gdiscovery "github.com/hyperledger/fabric/gossip/discovery"
+	"github.com/hyperledger/fabric/gossip/protoext"
+	cb "github.com/hyperledger/fabric/protos/common"
+	gproto "github.com/hyperledger/fabric/protos/gossip"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/discovery"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/requestmgr"
+	supp "github.com/trustbloc/fabric-peer-ext/pkg/common/support"
+	"go.uber.org/zap/zapcore"
+)
+
+var logger = flogging.MustGetLogger("kevlar_gossip_state")
+
+type gossipAdapter interface {
+	PeersOfChannel(gcommon.ChainID) []gdiscovery.NetworkMember
+	SelfMembershipInfo() gdiscovery.NetworkMember
+	IdentityInfo() gossipapi.PeerIdentitySet
+}
+
+type blockPublisher interface {
+	AddCCUpgradeHandler(handler extgossipapi.ChaincodeUpgradeHandler)
+}
+
+type ccRetriever interface {
+	Config(ns, coll string) (*cb.StaticCollectionConfig, error)
+	Policy(ns, coll string) (privdata.CollectionAccessPolicy, error)
+}
+
+// isEndorser should only be overridden for unit testing
+var isEndorser = func() bool {
+	return ledgerconfig.IsEndorser()
+}
+
+// New returns a new Gossip message dispatcher
+func New(
+	channelID string,
+	dataStore storeapi.Store,
+	gossipAdapter gossipAdapter,
+	ledger ledger.PeerLedger,
+	blockPublisher blockPublisher) *Dispatcher {
+	return &Dispatcher{
+		ccRetriever: supp.NewCollectionConfigRetriever(channelID, ledger, blockPublisher),
+		channelID:   channelID,
+		reqMgr:      requestmgr.Get(channelID),
+		dataStore:   dataStore,
+		discovery:   discovery.New(channelID, gossipAdapter),
+	}
+}
+
+// Dispatcher is a Gossip message dispatcher
+type Dispatcher struct {
+	ccRetriever
+	channelID string
+	reqMgr    requestmgr.RequestMgr
+	dataStore storeapi.Store
+	discovery *discovery.Discovery
+}
+
+// Dispatch handles the message and returns true if the message was handled; false if the message is unrecognized
+func (s *Dispatcher) Dispatch(msg protoext.ReceivedMessage) bool {
+	switch {
+	case msg.GetGossipMessage().GetCollDataReq() != nil:
+		logger.Debug("Handling collection data request message")
+		s.handleDataRequest(msg)
+		return true
+	case msg.GetGossipMessage().GetCollDataRes() != nil:
+		logger.Debug("Handling collection data response message")
+		s.handleDataResponse(msg)
+		return true
+	default:
+		logger.Debug("Not handling msg")
+		return false
+	}
+}
+
+func (s *Dispatcher) handleDataRequest(msg protoext.ReceivedMessage) {
+	if logger.IsEnabledFor(zapcore.DebugLevel) {
+		logger.Debugf("[ENTER] -> handleDataRequest")
+		defer logger.Debug("[EXIT] ->  handleDataRequest")
+	}
+
+	if !isEndorser() {
+		logger.Warningf("Non-endorser should not be receiving collection data request messages")
+		return
+	}
+
+	req := msg.GetGossipMessage().GetCollDataReq()
+	if len(req.Digests) == 0 {
+		logger.Warning("Got nil digests in CollDataRequestMsg")
+		return
+	}
+
+	reqMSPID, ok := s.discovery.GetMSPID(msg.GetConnectionInfo().ID)
+	if !ok {
+		logger.Warningf("Unable to get MSP ID from PKI ID of remote endpoint [%s]", msg.GetConnectionInfo().Endpoint)
+		return
+	}
+
+	responses, err := s.getRequestData(reqMSPID, req)
+	if err != nil {
+		logger.Warningf("[%s] Error processing request for data: %s", s.channelID, err.Error())
+		return
+	}
+
+	logger.Debugf("[%s] Responding with collection data for request %d", s.channelID, req.Nonce)
+
+	msg.Respond(&gproto.GossipMessage{
+		// Copy nonce field from the request, so it will be possible to match response
+		Nonce:   msg.GetGossipMessage().Nonce,
+		Tag:     gproto.GossipMessage_CHAN_ONLY,
+		Channel: []byte(s.channelID),
+		Content: &gproto.GossipMessage_CollDataRes{
+			CollDataRes: &gproto.RemoteCollDataResponse{
+				Nonce:    req.Nonce,
+				Elements: responses,
+			},
+		},
+	})
+}
+
+func (s *Dispatcher) handleDataResponse(msg protoext.ReceivedMessage) {
+	if logger.IsEnabledFor(zapcore.DebugLevel) {
+		logger.Debug("[ENTER] -> handleDataResponse")
+		defer logger.Debug("[EXIT] ->  handleDataResponse")
+	}
+
+	mspID, ok := s.discovery.GetMSPID(msg.GetConnectionInfo().ID)
+	if !ok {
+		logger.Errorf("Unable to get MSP ID from PKI ID")
+		return
+	}
+
+	res := msg.GetGossipMessage().GetCollDataRes()
+
+	s.reqMgr.Respond(
+		res.Nonce,
+		&requestmgr.Response{
+			Endpoint: msg.GetConnectionInfo().Endpoint,
+			MSPID:    mspID,
+			// FIXME: Should the message be signed?
+			//Signature:   element.Signature,
+			//Identity:    element.Identity,
+			Data: s.getResponseData(res),
+		},
+	)
+}
+
+func (s *Dispatcher) getRequestData(reqMSPID string, req *gproto.RemoteCollDataRequest) ([]*gproto.CollDataElement, error) {
+	var responses []*gproto.CollDataElement
+	for _, digest := range req.Digests {
+		if digest == nil {
+			return nil, errors.New("got nil digest in CollDataRequestMsg")
+		}
+		e, err := s.getRequestDataElement(reqMSPID, digest)
+		if err != nil {
+			return nil, err
+		}
+		responses = append(responses, e)
+	}
+	return responses, nil
+}
+
+func (s *Dispatcher) getRequestDataElement(reqMSPID string, digest *gproto.CollDataDigest) (*gproto.CollDataElement, error) {
+	key := store.NewKey(digest.EndorsedAtTxID, digest.Namespace, digest.Collection, digest.Key)
+
+	logger.Debugf("[%s] Getting data for key [%s]", s.channelID, key)
+	value, err := s.getDataForKey(key)
+	if err != nil {
+		return nil, errors.WithMessagef(err, "error getting data for [%s]", key)
+	}
+
+	e := &gproto.CollDataElement{
+		Digest: digest,
+	}
+
+	authorized, err := s.isAuthorized(reqMSPID, digest.Namespace, digest.Collection)
+	if err != nil {
+		return nil, err
+	}
+
+	if !authorized {
+		logger.Infof("[%s] Requesting MSP [%s] is not authorized to read data for [%s]", s.channelID, reqMSPID, key)
+	} else if value != nil {
+		e.Value = value.Value
+		e.ExpiryTime = common.ToTimestamp(value.Expiry)
+	}
+
+	return e, nil
+}
+
+func (s *Dispatcher) getResponseData(res *gproto.RemoteCollDataResponse) []*requestmgr.Element {
+	var elements []*requestmgr.Element
+	for _, e := range res.Elements {
+		d := e.Digest
+		logger.Debugf("[%s] Coll data response for request %d - [%s:%s:%s] received", s.channelID, res.Nonce, d.Namespace, d.Collection, d.Key)
+
+		element := &requestmgr.Element{
+			Namespace:  d.Namespace,
+			Collection: d.Collection,
+			Key:        d.Key,
+			Value:      e.Value,
+		}
+
+		if e.ExpiryTime != nil {
+			element.Expiry = time.Unix(e.ExpiryTime.Seconds, 0)
+		}
+		elements = append(elements, element)
+	}
+	return elements
+}
+
+func (s *Dispatcher) getDataForKey(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	logger.Debugf("[%s] Getting config for [%s:%s]", s.channelID, key.Namespace, key.Collection)
+	config, err := s.Config(key.Namespace, key.Collection)
+	if err != nil {
+		return nil, err
+	}
+
+	switch config.Type {
+	case cb.CollectionType_COL_TRANSIENT:
+		logger.Debugf("[%s] Getting transient data for key [%s]", s.channelID, key)
+		return s.dataStore.GetTransientData(key)
+	case cb.CollectionType_COL_DCAS:
+		fallthrough
+	case cb.CollectionType_COL_OFFLEDGER:
+		logger.Debugf("[%s] Getting off-ledger data for key [%s]", s.channelID, key)
+		return s.dataStore.GetData(key)
+	default:
+		return nil, errors.Errorf("unsupported collection type: [%s]", config.Type)
+	}
+}
+
+// isAuthorized determines whether the given MSP ID is authorized to read data from the given collection
+func (s *Dispatcher) isAuthorized(mspID string, ns, coll string) (bool, error) {
+	policy, err := s.Policy(ns, coll)
+	if err != nil {
+		return false, errors.WithMessagef(err, "unable to get policy for collection [%s:%s]", ns, coll)
+	}
+
+	for _, memberMSPID := range policy.MemberOrgs() {
+		if memberMSPID == mspID {
+			return true, nil
+		}
+	}
+
+	return false, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/couchdoc_conv.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/couchdoc_conv.go
new file mode 100644
index 00000000..ad44d700
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/couchdoc_conv.go
@@ -0,0 +1,142 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package idstore
+
+import (
+	"bytes"
+	"encoding/json"
+	"fmt"
+
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/pkg/errors"
+)
+
+const (
+	idField                    = "_id"
+	underConstructionLedgerKey = "under_construction"
+	ledgerKeyPrefix            = "ledger_"
+	metadataKey                = "metadata"
+	blockAttachmentName        = "genesis_block"
+	inventoryTypeField         = "type"
+	inventoryTypeIndexName     = "by_type"
+	inventoryTypeIndexDoc      = "indexMetadataInventory"
+	inventoryNameLedgerIDField = "ledger_id"
+	typeLedgerName             = "ledger"
+)
+
+const inventoryTypeIndexDef = `
+	{
+		"index": {
+			"fields": ["` + inventoryTypeField + `"]
+		},
+		"name": "` + inventoryTypeIndexName + `",
+		"ddoc": "` + inventoryTypeIndexDoc + `",
+		"type": "json"
+	}`
+
+type jsonValue map[string]interface{}
+
+func (v jsonValue) toBytes() ([]byte, error) {
+	return json.Marshal(v)
+}
+
+func ledgerToCouchDoc(ledgerID string, gb *common.Block) (*couchdb.CouchDoc, error) {
+	jsonMap := make(jsonValue)
+
+	jsonMap[idField] = ledgerIDToKey(ledgerID)
+	jsonMap[inventoryTypeField] = typeLedgerName
+	jsonMap[inventoryNameLedgerIDField] = ledgerID
+
+	jsonBytes, err := jsonMap.toBytes()
+	if err != nil {
+		return nil, err
+	}
+
+	couchDoc := couchdb.CouchDoc{JSONValue: jsonBytes}
+
+	attachment, err := blockToAttachment(gb)
+	if err != nil {
+		return nil, err
+	}
+
+	attachments := append([]*couchdb.AttachmentInfo{}, attachment)
+	couchDoc.Attachments = attachments
+
+	return &couchDoc, nil
+}
+
+func createMetadataDoc(constructionLedger string) (*couchdb.CouchDoc, error) {
+	jsonMap := make(jsonValue)
+
+	jsonMap[idField] = metadataKey
+	jsonMap[underConstructionLedgerKey] = constructionLedger
+
+	jsonBytes, err := jsonMap.toBytes()
+	if err != nil {
+		return nil, err
+	}
+
+	couchDoc := couchdb.CouchDoc{JSONValue: jsonBytes}
+
+	return &couchDoc, nil
+}
+
+func ledgerIDToKey(ledgerID string) string {
+	return fmt.Sprintf(ledgerKeyPrefix+"%s", ledgerID)
+}
+
+func blockToAttachment(block *common.Block) (*couchdb.AttachmentInfo, error) {
+	blockBytes, err := proto.Marshal(block)
+	if err != nil {
+		return nil, errors.Wrap(err, "marshaling block failed")
+	}
+
+	attachment := &couchdb.AttachmentInfo{}
+	attachment.AttachmentBytes = blockBytes
+	attachment.ContentType = "application/octet-stream"
+	attachment.Name = blockAttachmentName
+
+	return attachment, nil
+}
+
+func couchDocToJSON(doc *couchdb.CouchDoc) (jsonValue, error) {
+	return couchValueToJSON(doc.JSONValue)
+}
+
+func couchValueToJSON(value []byte) (jsonValue, error) {
+	// create a generic map unmarshal the json
+	jsonResult := make(map[string]interface{})
+	decoder := json.NewDecoder(bytes.NewBuffer(value))
+	decoder.UseNumber()
+
+	err := decoder.Decode(&jsonResult)
+	if err != nil {
+		return nil, errors.Wrap(err, "result from DB is not JSON encoded")
+	}
+
+	return jsonResult, nil
+}
+
+func queryInventory(db *couchdb.CouchDatabase, inventoryType string) ([]*couchdb.QueryResult, error) {
+	const queryFmt = `
+	{
+		"selector": {
+			"` + inventoryTypeField + `": {
+				"$eq": "%s"
+			}
+		},
+		"use_index": ["_design/` + inventoryTypeIndexDoc + `", "` + inventoryTypeIndexName + `"]
+	}`
+
+	results, _, err := db.QueryDocuments(fmt.Sprintf(queryFmt, inventoryType))
+	if err != nil {
+		return nil, err
+	}
+	return results, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/store_impl.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/store_impl.go
new file mode 100644
index 00000000..2cd4f6d0
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/store_impl.go
@@ -0,0 +1,268 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package idstore
+
+import (
+	"fmt"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/common/metrics/disabled"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/idstore"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+)
+
+var logger = flogging.MustGetLogger("idstore")
+
+const (
+	systemID      = "fabric_system_"
+	inventoryName = "inventory"
+)
+
+//Store contain couchdb instance
+type Store struct {
+	db               *couchdb.CouchDatabase
+	couchMetadataRev string
+}
+
+//OpenIDStore return id store
+func OpenIDStore(path string) idstore.IDStore {
+	couchInstance, err := createCouchInstance()
+	if err != nil {
+		logger.Errorf("create couchdb instance failed %s", err.Error())
+		return nil
+	}
+
+	inventoryDBName := couchdb.ConstructBlockchainDBName(systemID, inventoryName)
+	if roles.IsCommitter() {
+		return newCommitterStore(couchInstance, inventoryDBName)
+	}
+	s, err := newStore(couchInstance, inventoryDBName)
+	if err != nil {
+		logger.Error(err.Error())
+		return nil
+	}
+	return s
+}
+
+func newStore(couchInstance *couchdb.CouchInstance, dbName string) (idstore.IDStore, error) {
+	db, err := couchdb.NewCouchDatabase(couchInstance, dbName)
+	if err != nil {
+		return nil, errors.WithMessagef(err, "create new couchdb database called [%s] failed", dbName)
+	}
+
+	dbExists, err := db.ExistsWithRetry()
+	if err != nil {
+		return nil, errors.WithMessagef(err, "check couchdb [%s] exist failed", dbName)
+	}
+	if !dbExists {
+		return nil, errors.New(fmt.Sprintf("DB not found: [%s]", dbName))
+	}
+
+	indexExists, err := db.IndexDesignDocExistsWithRetry(inventoryTypeIndexDoc)
+	if err != nil {
+		return nil, errors.WithMessagef(err, "check couchdb [%s] index exist failed", dbName)
+
+	}
+	if !indexExists {
+		return nil, errors.New(fmt.Sprintf("DB index not found: [%s]", db.DBName))
+	}
+
+	s := Store{db, ""}
+	return &s, nil
+}
+
+func newCommitterStore(couchInstance *couchdb.CouchInstance, dbName string) idstore.IDStore {
+	db, err := couchdb.CreateCouchDatabase(couchInstance, dbName)
+	if err != nil {
+		logger.Errorf("create new couchdb database failed %s", err.Error())
+		return nil
+	}
+
+	err = createIndices(db)
+	if err != nil {
+		logger.Errorf("create couchdb index failed %s", err.Error())
+		return nil
+	}
+
+	s := Store{db, ""}
+
+	return &s
+}
+
+func createIndices(db *couchdb.CouchDatabase) error {
+	err := db.CreateNewIndexWithRetry(inventoryTypeIndexDef, inventoryTypeIndexDoc)
+	if err != nil {
+		return errors.WithMessagef(err, "creation of inventory metadata index failed for [%s]", db.DBName)
+	}
+	return nil
+}
+
+func createCouchInstance() (*couchdb.CouchInstance, error) {
+	logger.Debugf("constructing CouchDB block storage provider")
+	couchDBDef := couchdb.GetCouchDBDefinition()
+	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	if err != nil {
+		return nil, errors.WithMessage(err, "obtaining CouchDB instance failed")
+	}
+
+	return couchInstance, nil
+}
+
+//SetUnderConstructionFlag set under construction flag
+func (s *Store) SetUnderConstructionFlag(ledgerID string) error {
+	doc, err := createMetadataDoc(ledgerID)
+	if err != nil {
+		return err
+	}
+
+	rev, err := s.db.SaveDoc(metadataKey, s.couchMetadataRev, doc)
+	if err != nil {
+		return errors.WithMessage(err, "update of metadata in CouchDB failed")
+	}
+
+	s.couchMetadataRev = rev
+
+	logger.Debugf("updated metadata in CouchDB inventory [%s]", rev)
+	return nil
+}
+
+//UnsetUnderConstructionFlag unset under construction flag
+func (s *Store) UnsetUnderConstructionFlag() error {
+	doc, err := createMetadataDoc("")
+	if err != nil {
+		return err
+	}
+
+	rev, err := s.db.SaveDoc(metadataKey, s.couchMetadataRev, doc)
+	if err != nil {
+		return errors.WithMessage(err, "update of metadata in CouchDB failed")
+	}
+
+	s.couchMetadataRev = rev
+
+	logger.Debugf("updated metadata in CouchDB inventory [%s]", rev)
+	return nil
+}
+
+//GetUnderConstructionFlag get under construction flag
+func (s *Store) GetUnderConstructionFlag() (string, error) {
+	doc, _, err := s.db.ReadDoc(metadataKey)
+	if err != nil {
+		return "", errors.WithMessage(err, "retrieval of metadata from CouchDB inventory failed")
+	}
+
+	// if metadata does not exist, assume that there is nothing under construction.
+	if doc == nil {
+		return "", nil
+	}
+
+	metadata, err := couchDocToJSON(doc)
+	if err != nil {
+		return "", errors.WithMessage(err, "metadata in CouchDB inventory is invalid")
+	}
+
+	constructionLedgerUT := metadata[underConstructionLedgerKey]
+	constructionLedger, ok := constructionLedgerUT.(string)
+	if !ok {
+		return "", errors.New("metadata under construction key in CouchDB inventory is invalid")
+	}
+
+	return constructionLedger, nil
+}
+
+//CreateLedgerID create ledger id
+func (s *Store) CreateLedgerID(ledgerID string, gb *common.Block) error {
+	exists, err := s.LedgerIDExists(ledgerID)
+	if err != nil {
+		return err
+	}
+
+	if exists {
+		return errors.Errorf("ledger already exists [%s]", ledgerID)
+	}
+
+	doc, err := ledgerToCouchDoc(ledgerID, gb)
+	if err != nil {
+		return err
+	}
+
+	rev, err := s.db.BatchUpdateDocuments([]*couchdb.CouchDoc{doc})
+	if err != nil {
+		return errors.WithMessagef(err, "creation of ledger failed [%s]", ledgerID)
+	}
+
+	err = s.UnsetUnderConstructionFlag()
+	if err != nil {
+		return err
+	}
+
+	logger.Debugf("created ledger in CouchDB inventory [%s, %s]", ledgerID, rev)
+	return nil
+}
+
+//LedgerIDExists check ledger id exists
+func (s *Store) LedgerIDExists(ledgerID string) (bool, error) {
+	doc, _, err := s.db.ReadDoc(ledgerIDToKey(ledgerID))
+	if err != nil {
+		return false, err
+	}
+
+	exists := doc != nil
+	return exists, nil
+}
+
+//GetLedgeIDValue get ledger id value
+func (s *Store) GetLedgeIDValue(ledgerID string) ([]byte, error) {
+	doc, _, err := s.db.ReadDoc(ledgerIDToKey(ledgerID))
+	if err != nil {
+		return nil, err
+	}
+	for _, v := range doc.Attachments {
+		if v.Name == blockAttachmentName {
+			return v.AttachmentBytes, nil
+		}
+	}
+	return nil, nil
+}
+
+//GetAllLedgerIds get all ledger ids
+func (s *Store) GetAllLedgerIds() ([]string, error) {
+	results, err := queryInventory(s.db, typeLedgerName)
+	if err != nil {
+		return nil, err
+	}
+
+	ledgers := make([]string, 0)
+	for _, r := range results {
+		ledgerJSON, err := couchValueToJSON(r.Value)
+		if err != nil {
+			return nil, err
+		}
+
+		ledgerIDUT, ok := ledgerJSON[inventoryNameLedgerIDField]
+		if !ok {
+			return nil, errors.Errorf("ledger inventory document is invalid [%s]", r.ID)
+		}
+
+		ledgerID, ok := ledgerIDUT.(string)
+		if !ok {
+			return nil, errors.Errorf("ledger inventory document value is invalid [%s]", r.ID)
+		}
+
+		ledgers = append(ledgers, ledgerID)
+	}
+
+	return ledgers, nil
+}
+
+//Close the store
+func (s *Store) Close() {
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/test_exports.go
new file mode 100644
index 00000000..e33be838
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/test_exports.go
@@ -0,0 +1,59 @@
+/*
+Copyright IBM Corp. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package idstore
+
+import (
+	"os"
+	"testing"
+
+	"github.com/hyperledger/fabric/common/metrics/disabled"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/idstore"
+	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+)
+
+// StoreEnv provides the  store env for testing
+type StoreEnv struct {
+	t          testing.TB
+	TestStore  idstore.IDStore
+	ledgerid   string
+	couchDBDef *couchdb.CouchDBDef
+}
+
+// NewTestStoreEnv construct a StoreEnv for testing
+func NewTestStoreEnv(t *testing.T, ledgerid string, couchDBDef *couchdb.CouchDBDef) *StoreEnv {
+	removeStorePath()
+	testStore := OpenIDStore(ledgerid)
+	s := &StoreEnv{t, testStore, ledgerid, couchDBDef}
+	return s
+}
+
+//Cleanup env test
+func (env *StoreEnv) Cleanup(ledgerid string) {
+	//create a new connection
+	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBDef.URL, env.couchDBDef.Username, env.couchDBDef.Password,
+		env.couchDBDef.MaxRetries, env.couchDBDef.MaxRetriesOnStartup, env.couchDBDef.RequestTimeout, env.couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	if err != nil {
+		panic(err.Error())
+	}
+	pvtDataStoreDBName := couchdb.ConstructBlockchainDBName(systemID, inventoryName)
+	db := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: pvtDataStoreDBName}
+	//drop the test database
+	if _, err := db.DropDatabase(); err != nil {
+		panic(err.Error())
+	}
+	env.TestStore.Close()
+
+	removeStorePath()
+}
+
+func removeStorePath() {
+	dbPath := ledgerconfig.GetPvtdataStorePath()
+	if err := os.RemoveAll(dbPath); err != nil {
+		panic(err.Error())
+	}
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockaccesspolicy.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockaccesspolicy.go
new file mode 100644
index 00000000..63925f19
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockaccesspolicy.go
@@ -0,0 +1,61 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"github.com/hyperledger/fabric/core/common/privdata"
+	"github.com/hyperledger/fabric/protoutil"
+)
+
+// MockAccessPolicy implements a mock CollectionAccessPolicy
+type MockAccessPolicy struct {
+	ReqPeerCount int
+	MaxPeerCount int
+	Orgs         []string
+	OnlyRead     bool
+	OnlyWrite    bool
+	Filter       privdata.Filter
+}
+
+// AccessFilter returns a member filter function for a collection
+func (m *MockAccessPolicy) AccessFilter() privdata.Filter {
+	if m.Filter == nil {
+		return func(protoutil.SignedData) bool { return true }
+	}
+	return m.Filter
+}
+
+// RequiredPeerCount The minimum number of peers private data will be sent to upon
+// endorsement. The endorsement would fail if dissemination to at least
+// this number of peers is not achieved.
+func (m *MockAccessPolicy) RequiredPeerCount() int {
+	return m.ReqPeerCount
+}
+
+// MaximumPeerCount The maximum number of peers that private data will be sent to
+// upon endorsement. This number has to be bigger than RequiredPeerCount().
+func (m *MockAccessPolicy) MaximumPeerCount() int {
+	return m.MaxPeerCount
+}
+
+// MemberOrgs returns the collection's members as MSP IDs. This serves as
+// a human-readable way of quickly identifying who is part of a collection.
+func (m *MockAccessPolicy) MemberOrgs() []string {
+	return m.Orgs
+}
+
+// IsMemberOnlyRead returns a true if only collection members can read
+// the private data
+func (m *MockAccessPolicy) IsMemberOnlyRead() bool {
+	return m.OnlyRead
+}
+
+// IsMemberOnlyWrite returns a true if only collection members can write
+// the private data
+func (m *MockAccessPolicy) IsMemberOnlyWrite() bool {
+	return m.OnlyWrite
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockbuilder.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockbuilder.go
new file mode 100644
index 00000000..fce275ff
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockbuilder.go
@@ -0,0 +1,367 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"crypto/sha256"
+	"time"
+
+	"github.com/golang/protobuf/proto"
+	"github.com/golang/protobuf/ptypes/timestamp"
+	cutil "github.com/hyperledger/fabric/common/util"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/rwsetutil"
+	ledger_util "github.com/hyperledger/fabric/core/ledger/util"
+	cb "github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	pb "github.com/hyperledger/fabric/protos/peer"
+	"github.com/hyperledger/fabric/protoutil"
+)
+
+// BlockBuilder builds a mock Block
+type BlockBuilder struct {
+	channelID    string
+	blockNum     uint64
+	previousHash []byte
+	configUpdate *ConfigUpdateBuilder
+	transactions []*TxBuilder
+}
+
+// NewBlockBuilder returns a new mock BlockBuilder
+func NewBlockBuilder(channelID string, blockNum uint64) *BlockBuilder {
+	return &BlockBuilder{
+		channelID: channelID,
+		blockNum:  blockNum,
+	}
+}
+
+// Build builds the block
+func (b *BlockBuilder) Build() *cb.Block {
+	block := &cb.Block{}
+	block.Header = &cb.BlockHeader{}
+	block.Header.Number = b.blockNum
+	block.Header.PreviousHash = b.previousHash
+	block.Data = &cb.BlockData{}
+
+	var metadataContents [][]byte
+	for i := 0; i < len(cb.BlockMetadataIndex_name); i++ {
+		metadataContents = append(metadataContents, []byte{})
+	}
+	block.Metadata = &cb.BlockMetadata{Metadata: metadataContents}
+
+	if b.configUpdate != nil {
+		block.Data.Data = append(block.Data.Data, b.configUpdate.Build())
+	} else {
+		var txValidationCodes []uint8
+		for _, tx := range b.transactions {
+			txBytes, txValidationCode := tx.Build()
+			block.Data.Data = append(block.Data.Data, txBytes)
+			txValidationCodes = append(txValidationCodes, uint8(txValidationCode))
+		}
+		txsfltr := ledger_util.NewTxValidationFlags(len(block.Data.Data))
+		for i := 0; i < len(block.Data.Data); i++ {
+			txsfltr[i] = txValidationCodes[i]
+		}
+		block.Metadata.Metadata[cb.BlockMetadataIndex_TRANSACTIONS_FILTER] = txsfltr
+	}
+
+	blockbytes := cutil.ConcatenateBytes(block.Data.Data...)
+	block.Header.DataHash = computeSHA256(blockbytes)
+
+	return block
+}
+
+// ConfigUpdate adds a config update
+func (b *BlockBuilder) ConfigUpdate() *ConfigUpdateBuilder {
+	if len(b.transactions) > 0 {
+		panic("Cannot mix config updates with endorsement transactions")
+	}
+	cb := NewConfigUpdateBuilder(b.channelID)
+	b.configUpdate = cb
+	return cb
+}
+
+// ConfigUpdateBuilder builds a mock config update envelope
+type ConfigUpdateBuilder struct {
+	channelID string
+}
+
+// NewConfigUpdateBuilder returns a new mock ConfigUpdateBuilder
+func NewConfigUpdateBuilder(channelID string) *ConfigUpdateBuilder {
+	return &ConfigUpdateBuilder{
+		channelID: channelID,
+	}
+}
+
+// Build builds a config update envelope
+func (b *ConfigUpdateBuilder) Build() []byte {
+	chdr := &cb.ChannelHeader{
+		Type:    int32(cb.HeaderType_CONFIG_UPDATE),
+		Version: 1,
+		Timestamp: &timestamp.Timestamp{
+			Seconds: time.Now().Unix(),
+			Nanos:   0,
+		},
+		ChannelId: b.channelID}
+	hdr := &cb.Header{ChannelHeader: protoutil.MarshalOrPanic(chdr)}
+	payload := &cb.Payload{Header: hdr}
+
+	env := &cb.Envelope{}
+
+	var err error
+	env.Payload, err = protoutil.GetBytesPayload(payload)
+	if err != nil {
+		panic(err.Error())
+	}
+	ebytes, err := protoutil.GetBytesEnvelope(env)
+	if err != nil {
+		panic(err.Error())
+	}
+
+	return ebytes
+}
+
+// Transaction adds a new transaction
+func (b *BlockBuilder) Transaction(txID string, validationCode pb.TxValidationCode) *TxBuilder {
+	if b.configUpdate != nil {
+		panic("Cannot mix config updates with endorsement transactions")
+	}
+	tx := NewTxBuilder(b.channelID, txID, validationCode)
+	b.transactions = append(b.transactions, tx)
+	return tx
+}
+
+// TxBuilder builds a mock Transaction
+type TxBuilder struct {
+	channelID        string
+	txID             string
+	validationCode   pb.TxValidationCode
+	chaincodeActions []*ChaincodeActionBuilder
+}
+
+// NewTxBuilder returns a new mock TxBuilder
+func NewTxBuilder(channelID, txID string, validationCode pb.TxValidationCode) *TxBuilder {
+	return &TxBuilder{
+		channelID:      channelID,
+		txID:           txID,
+		validationCode: validationCode,
+	}
+}
+
+// Build builds a transaction
+func (b *TxBuilder) Build() ([]byte, pb.TxValidationCode) {
+	chdr := &cb.ChannelHeader{
+		Type:    int32(cb.HeaderType_ENDORSER_TRANSACTION),
+		Version: 1,
+		Timestamp: &timestamp.Timestamp{
+			Seconds: time.Now().Unix(),
+			Nanos:   0,
+		},
+		ChannelId: b.channelID,
+		TxId:      b.txID}
+	hdr := &cb.Header{ChannelHeader: protoutil.MarshalOrPanic(chdr)}
+	payload := &cb.Payload{Header: hdr}
+
+	env := &cb.Envelope{}
+
+	tx := &pb.Transaction{}
+
+	for _, ccAction := range b.chaincodeActions {
+		tx.Actions = append(tx.Actions, &pb.TransactionAction{
+			Payload: ccAction.Build(),
+		})
+	}
+
+	var err error
+	payload.Data, err = protoutil.GetBytesTransaction(tx)
+	if err != nil {
+		panic(err.Error())
+	}
+	env.Payload, err = protoutil.GetBytesPayload(payload)
+	if err != nil {
+		panic(err.Error())
+	}
+	ebytes, err := protoutil.GetBytesEnvelope(env)
+	if err != nil {
+		panic(err.Error())
+	}
+
+	return ebytes, b.validationCode
+}
+
+// ChaincodeAction adds a chaincode action to the transaction
+func (b *TxBuilder) ChaincodeAction(ccID string) *ChaincodeActionBuilder {
+	cc := NewChaincodeActionBuilder(ccID, b.txID)
+	b.chaincodeActions = append(b.chaincodeActions, cc)
+	return cc
+}
+
+// ChaincodeActionBuilder builds a mock Chaincode Action
+type ChaincodeActionBuilder struct {
+	ccID         string
+	txID         string
+	response     *pb.Response
+	ccEvent      *pb.ChaincodeEvent
+	nsRWSet      *NamespaceRWSetBuilder
+	collNSRWSets []*NamespaceRWSetBuilder
+}
+
+// NewChaincodeActionBuilder returns a new ChaincodeActionBuilder
+func NewChaincodeActionBuilder(ccID, txID string) *ChaincodeActionBuilder {
+	return &ChaincodeActionBuilder{
+		ccID:    ccID,
+		txID:    txID,
+		nsRWSet: NewNamespaceRWSetBuilder(ccID),
+	}
+}
+
+// Build builds the chaincode action
+func (b *ChaincodeActionBuilder) Build() []byte {
+	ccID := &pb.ChaincodeID{
+		Name: b.ccID,
+	}
+
+	var ccEventBytes []byte
+	if b.ccEvent != nil {
+		var err error
+		ccEventBytes, err = proto.Marshal(b.ccEvent)
+		if err != nil {
+			panic(err.Error())
+		}
+	}
+
+	txRWSet := &rwsetutil.TxRwSet{}
+	txRWSet.NsRwSets = append(txRWSet.NsRwSets, b.nsRWSet.Build())
+	for _, collRWSet := range b.collNSRWSets {
+		txRWSet.NsRwSets = append(txRWSet.NsRwSets, collRWSet.Build())
+	}
+
+	nsRWSetBytes, err := txRWSet.ToProtoBytes()
+	if err != nil {
+		panic(err.Error())
+	}
+
+	proposalResponsePayload, err := protoutil.GetBytesProposalResponsePayload(
+		[]byte("proposal_hash"), b.response, nsRWSetBytes, ccEventBytes, ccID)
+	if err != nil {
+		panic(err.Error())
+	}
+
+	ccaPayload := &pb.ChaincodeActionPayload{
+		Action: &pb.ChaincodeEndorsedAction{
+			ProposalResponsePayload: proposalResponsePayload,
+		},
+	}
+
+	payload, err := protoutil.GetBytesChaincodeActionPayload(ccaPayload)
+	if err != nil {
+		panic(err.Error())
+	}
+	return payload
+}
+
+// Response sets the chaincode response
+func (b *ChaincodeActionBuilder) Response(response *pb.Response) *ChaincodeActionBuilder {
+	b.response = response
+	return b
+}
+
+// Read adds a KV read to the read/write set
+func (b *ChaincodeActionBuilder) Read(key string, version *kvrwset.Version) *ChaincodeActionBuilder {
+	b.nsRWSet.Read(key, version)
+	return b
+}
+
+// Write adds a KV write to the read/write set
+func (b *ChaincodeActionBuilder) Write(key string, value []byte) *ChaincodeActionBuilder {
+	b.nsRWSet.Write(key, value)
+	return b
+}
+
+// Delete adds a KV write (with delete=true) to the read/write set
+func (b *ChaincodeActionBuilder) Delete(key string) *ChaincodeActionBuilder {
+	b.nsRWSet.Delete(key)
+	return b
+}
+
+// ChaincodeEvent adds a chaincode event to the chaincode action
+func (b *ChaincodeActionBuilder) ChaincodeEvent(eventName string, payload []byte) *ChaincodeActionBuilder {
+	b.ccEvent = &pb.ChaincodeEvent{
+		ChaincodeId: b.ccID,
+		TxId:        b.txID,
+		EventName:   eventName,
+		Payload:     payload,
+	}
+	return b
+}
+
+// Collection starts a new collection read/write set
+func (b *ChaincodeActionBuilder) Collection(coll string) *NamespaceRWSetBuilder {
+	nsRWSetBuilder := NewNamespaceRWSetBuilder(b.ccID + "~" + coll)
+	b.collNSRWSets = append(b.collNSRWSets, nsRWSetBuilder)
+	return nsRWSetBuilder
+}
+
+// NamespaceRWSetBuilder builds a mock read/write set for a given namespace
+type NamespaceRWSetBuilder struct {
+	namespace string
+	reads     []*kvrwset.KVRead
+	writes    []*kvrwset.KVWrite
+}
+
+// NewNamespaceRWSetBuilder returns a new namespace read/write set builder
+func NewNamespaceRWSetBuilder(ns string) *NamespaceRWSetBuilder {
+	return &NamespaceRWSetBuilder{
+		namespace: ns,
+	}
+}
+
+// Build builds a namespace read/write set
+func (b *NamespaceRWSetBuilder) Build() *rwsetutil.NsRwSet {
+	return &rwsetutil.NsRwSet{
+		NameSpace: b.namespace,
+		KvRwSet: &kvrwset.KVRWSet{
+			Reads:  b.reads,
+			Writes: b.writes,
+		},
+	}
+}
+
+// Read adds a KV read to the read/write set
+func (b *NamespaceRWSetBuilder) Read(key string, version *kvrwset.Version) *NamespaceRWSetBuilder {
+	b.reads = append(b.reads, &kvrwset.KVRead{
+		Key:     key,
+		Version: version,
+	})
+	return b
+}
+
+// Write adds a KV write to the read/write set
+func (b *NamespaceRWSetBuilder) Write(key string, value []byte) *NamespaceRWSetBuilder {
+	b.writes = append(b.writes, &kvrwset.KVWrite{
+		Key:   key,
+		Value: value,
+	})
+	return b
+}
+
+// Delete adds a KV write (with delete=true) to the read/write set
+func (b *NamespaceRWSetBuilder) Delete(key string) *NamespaceRWSetBuilder {
+	b.writes = append(b.writes, &kvrwset.KVWrite{
+		Key:      key,
+		IsDelete: true,
+	})
+	return b
+}
+
+func computeSHA256(data []byte) (hash []byte) {
+	h := sha256.New()
+	_, err := h.Write(data)
+	if err != nil {
+		panic("unable to create digest")
+	}
+	return h.Sum(nil)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockhandler.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockhandler.go
new file mode 100644
index 00000000..29058842
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockhandler.go
@@ -0,0 +1,91 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"sync/atomic"
+
+	cb "github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	pb "github.com/hyperledger/fabric/protos/peer"
+)
+
+// MockBlockHandler is a mock block handler
+type MockBlockHandler struct {
+	numReads           int32
+	numWrites          int32
+	numCCEvents        int32
+	numCCUpgradeEvents int32
+	numConfigUpdates   int32
+	err                error
+}
+
+// NewMockBlockHandler returns a mock Block Handler
+func NewMockBlockHandler() *MockBlockHandler {
+	return &MockBlockHandler{}
+}
+
+// WithError sets an error
+func (m *MockBlockHandler) WithError(err error) *MockBlockHandler {
+	m.err = err
+	return m
+}
+
+// NumReads returns the number of reads handled
+func (m *MockBlockHandler) NumReads() int {
+	return int(atomic.LoadInt32(&m.numReads))
+}
+
+// NumWrites returns the number of writes handled
+func (m *MockBlockHandler) NumWrites() int {
+	return int(atomic.LoadInt32(&m.numWrites))
+}
+
+// NumCCEvents returns the number of chaincode events handled
+func (m *MockBlockHandler) NumCCEvents() int {
+	return int(atomic.LoadInt32(&m.numCCEvents))
+}
+
+// NumCCUpgradeEvents returns the number of chaincode upgrades handled
+func (m *MockBlockHandler) NumCCUpgradeEvents() int {
+	return int(atomic.LoadInt32(&m.numCCUpgradeEvents))
+}
+
+// NumConfigUpdates returns the number of configuration updates handled
+func (m *MockBlockHandler) NumConfigUpdates() int {
+	return int(atomic.LoadInt32(&m.numConfigUpdates))
+}
+
+// HandleRead handles a read event by incrementing the read counter
+func (m *MockBlockHandler) HandleRead(blockNum uint64, txID string, namespace string, kvRead *kvrwset.KVRead) error {
+	atomic.AddInt32(&m.numReads, 1)
+	return m.err
+}
+
+// HandleWrite handles a write event by incrementing the write counter
+func (m *MockBlockHandler) HandleWrite(blockNum uint64, txID string, namespace string, kvWrite *kvrwset.KVWrite) error {
+	atomic.AddInt32(&m.numWrites, 1)
+	return m.err
+}
+
+// HandleChaincodeEvent handle a chaincode event by incrementing the CC event counter
+func (m *MockBlockHandler) HandleChaincodeEvent(blockNum uint64, txID string, event *pb.ChaincodeEvent) error {
+	atomic.AddInt32(&m.numCCEvents, 1)
+	return m.err
+}
+
+// HandleChaincodeUpgradeEvent handles a chaincode upgrade event by incrementing the chaincode upgrade counter
+func (m *MockBlockHandler) HandleChaincodeUpgradeEvent(blockNum uint64, txID string, chaincodeName string) error {
+	atomic.AddInt32(&m.numCCUpgradeEvents, 1)
+	return m.err
+}
+
+// HandleConfigUpdate handles a config update by incrementing the config update counter
+func (m *MockBlockHandler) HandleConfigUpdate(blockNum uint64, configUpdate *cb.ConfigUpdate) error {
+	atomic.AddInt32(&m.numConfigUpdates, 1)
+	return m.err
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockpublisher.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockpublisher.go
new file mode 100644
index 00000000..e9d33b65
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockpublisher.go
@@ -0,0 +1,56 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	"github.com/hyperledger/fabric/protos/common"
+)
+
+// MockBlockPublisher is a mock block publisher
+type MockBlockPublisher struct {
+	HandleUpgrade      gossipapi.ChaincodeUpgradeHandler
+	HandleConfigUpdate gossipapi.ConfigUpdateHandler
+	HandleWrite        gossipapi.WriteHandler
+	HandleRead         gossipapi.ReadHandler
+	HandleCCEvent      gossipapi.ChaincodeEventHandler
+}
+
+// NewBlockPublisher returns a mock block publisher
+func NewBlockPublisher() *MockBlockPublisher {
+	return &MockBlockPublisher{}
+}
+
+// AddCCUpgradeHandler adds a chaincode upgrade handler
+func (m *MockBlockPublisher) AddCCUpgradeHandler(handler gossipapi.ChaincodeUpgradeHandler) {
+	m.HandleUpgrade = handler
+}
+
+// AddConfigUpdateHandler adds a config update handler
+func (m *MockBlockPublisher) AddConfigUpdateHandler(handler gossipapi.ConfigUpdateHandler) {
+	m.HandleConfigUpdate = handler
+}
+
+// AddWriteHandler adds a write handler
+func (m *MockBlockPublisher) AddWriteHandler(handler gossipapi.WriteHandler) {
+	m.HandleWrite = handler
+}
+
+// AddReadHandler adds a read handler
+func (m *MockBlockPublisher) AddReadHandler(handler gossipapi.ReadHandler) {
+	m.HandleRead = handler
+}
+
+// AddCCEventHandler adds a chaincode event handler
+func (m *MockBlockPublisher) AddCCEventHandler(handler gossipapi.ChaincodeEventHandler) {
+	m.HandleCCEvent = handler
+}
+
+// Publish is not implemented and panics if invoked
+func (m *MockBlockPublisher) Publish(block *common.Block) {
+	panic("not implemented")
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockdataprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockdataprovider.go
new file mode 100644
index 00000000..a90e5ad5
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockdataprovider.go
@@ -0,0 +1,91 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"context"
+
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+)
+
+// DataProvider is a mock transient data provider
+type DataProvider struct {
+	data map[storeapi.Key]*storeapi.ExpiringValue
+	err  error
+}
+
+// NewDataProvider returns a new Data Provider
+func NewDataProvider() *DataProvider {
+	return &DataProvider{
+		data: make(map[storeapi.Key]*storeapi.ExpiringValue),
+	}
+}
+
+// WithData sets the data to be returned by the retriever
+func (p *DataProvider) WithData(key *storeapi.Key, value *storeapi.ExpiringValue) *DataProvider {
+	p.data[*key] = value
+	return p
+}
+
+// WithError sets the error to be returned by the retriever
+func (p *DataProvider) WithError(err error) *DataProvider {
+	p.err = err
+	return p
+}
+
+// RetrieverForChannel returns the retriever for the given channel
+func (p *DataProvider) RetrieverForChannel(channel string) storeapi.Retriever {
+	return &dataRetriever{
+		err:  p.err,
+		data: p.data,
+	}
+}
+
+type dataRetriever struct {
+	err  error
+	data map[storeapi.Key]*storeapi.ExpiringValue
+}
+
+// GetTransientData returns the transient data for the given context and key
+func (m *dataRetriever) GetTransientData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	if m.err != nil {
+		return nil, m.err
+	}
+	return m.data[*key], nil
+}
+
+// GetTransientDataMultipleKeys returns the transient data with multiple keys for the given context and key
+func (m *dataRetriever) GetTransientDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	if m.err != nil {
+		return nil, m.err
+	}
+	values := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		values[i] = m.data[*storeapi.NewKey(key.EndorsedAtTxID, key.Namespace, key.Collection, k)]
+	}
+	return values, nil
+}
+
+// GetData returns the data for the given context and key
+func (m *dataRetriever) GetData(ctxt context.Context, key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	if m.err != nil {
+		return nil, m.err
+	}
+	return m.data[*key], nil
+}
+
+// GetDataMultipleKeys returns the  data with multiple keys for the given context and key
+func (m *dataRetriever) GetDataMultipleKeys(ctxt context.Context, key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	if m.err != nil {
+		return nil, m.err
+	}
+	values := make(storeapi.ExpiringValues, len(key.Keys))
+	for i, k := range key.Keys {
+		values[i] = m.data[*storeapi.NewKey(key.EndorsedAtTxID, key.Namespace, key.Collection, k)]
+	}
+	return values, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockdatastore.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockdatastore.go
new file mode 100644
index 00000000..7410c46d
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockdatastore.go
@@ -0,0 +1,101 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	storeapi "github.com/hyperledger/fabric/extensions/collections/api/store"
+	cb "github.com/hyperledger/fabric/protos/common"
+	proto "github.com/hyperledger/fabric/protos/transientstore"
+)
+
+// DataStore implements a mock data store
+type DataStore struct {
+	transientData map[storeapi.Key]*storeapi.ExpiringValue
+	olData        map[storeapi.Key]*storeapi.ExpiringValue
+	err           error
+}
+
+// NewDataStore returns a mock transient data store
+func NewDataStore() *DataStore {
+	return &DataStore{
+		transientData: make(map[storeapi.Key]*storeapi.ExpiringValue),
+		olData:        make(map[storeapi.Key]*storeapi.ExpiringValue),
+	}
+}
+
+// TransientData sets the transient data for the given key
+func (m *DataStore) TransientData(key *storeapi.Key, value *storeapi.ExpiringValue) *DataStore {
+	m.transientData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}] = value
+	return m
+}
+
+// Data sets the data for the given key
+func (m *DataStore) Data(key *storeapi.Key, value *storeapi.ExpiringValue) *DataStore {
+	m.olData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}] = value
+	return m
+}
+
+// Error sets an err
+func (m *DataStore) Error(err error) *DataStore {
+	m.err = err
+	return m
+}
+
+// Persist stores the private write set of a transaction along with the collection config
+// in the transient store based on txid and the block height the private data was received at
+func (m *DataStore) Persist(txid string, privateSimulationResultsWithConfig *proto.TxPvtReadWriteSetWithConfigInfo) error {
+	return m.err
+}
+
+// GetTransientData gets the value for the given transient data item
+func (m *DataStore) GetTransientData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return m.transientData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}], m.err
+}
+
+// GetTransientDataMultipleKeys gets the values for the multiple transient data items in a single call
+func (m *DataStore) GetTransientDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	var values storeapi.ExpiringValues
+	for _, k := range key.Keys {
+		value, err := m.GetTransientData(&storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: k})
+		if err != nil {
+			return nil, err
+		}
+		values = append(values, value)
+	}
+	return values, m.err
+}
+
+// PutData stores the key/value
+func (m *DataStore) PutData(config *cb.StaticCollectionConfig, key *storeapi.Key, value *storeapi.ExpiringValue) error {
+	if m.err != nil {
+		return m.err
+	}
+	m.olData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}] = value
+	return nil
+}
+
+// GetData gets the value for the given DCAS item
+func (m *DataStore) GetData(key *storeapi.Key) (*storeapi.ExpiringValue, error) {
+	return m.olData[storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: key.Key}], m.err
+}
+
+// GetDataMultipleKeys gets the values for the multiple DCAS items in a single call
+func (m *DataStore) GetDataMultipleKeys(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	var values storeapi.ExpiringValues
+	for _, k := range key.Keys {
+		value, err := m.GetData(&storeapi.Key{Namespace: key.Namespace, Collection: key.Collection, Key: k})
+		if err != nil {
+			return nil, err
+		}
+		values = append(values, value)
+	}
+	return values, m.err
+}
+
+// Close closes the store
+func (m *DataStore) Close() {
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockgossipadapter.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockgossipadapter.go
new file mode 100644
index 00000000..a337d037
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockgossipadapter.go
@@ -0,0 +1,96 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	gossipapi "github.com/hyperledger/fabric/gossip/api"
+	"github.com/hyperledger/fabric/gossip/comm"
+	"github.com/hyperledger/fabric/gossip/common"
+	"github.com/hyperledger/fabric/gossip/discovery"
+	gossipproto "github.com/hyperledger/fabric/protos/gossip"
+)
+
+// MessageHandler defines a function that handles a gossip message.
+type MessageHandler func(msg *gossipproto.GossipMessage)
+
+// MockGossipAdapter is the gossip adapter
+type MockGossipAdapter struct {
+	self        discovery.NetworkMember
+	members     []discovery.NetworkMember
+	identitySet gossipapi.PeerIdentitySet
+	handler     MessageHandler
+}
+
+// NewMockGossipAdapter returns the adapter
+func NewMockGossipAdapter() *MockGossipAdapter {
+	return &MockGossipAdapter{}
+}
+
+// Self discovers a network member
+func (m *MockGossipAdapter) Self(mspID string, self discovery.NetworkMember) *MockGossipAdapter {
+	m.self = self
+	m.identitySet = append(m.identitySet, gossipapi.PeerIdentityInfo{
+		PKIId:        self.PKIid,
+		Organization: []byte(mspID),
+	})
+	return m
+}
+
+// Member adds the network member
+func (m *MockGossipAdapter) Member(mspID string, member discovery.NetworkMember) *MockGossipAdapter {
+	m.members = append(m.members, member)
+	m.identitySet = append(m.identitySet, gossipapi.PeerIdentityInfo{
+		PKIId:        member.PKIid,
+		Organization: []byte(mspID),
+	})
+	return m
+}
+
+// MemberWithNoPKIID appends the member
+func (m *MockGossipAdapter) MemberWithNoPKIID(mspID string, member discovery.NetworkMember) *MockGossipAdapter {
+	m.members = append(m.members, member)
+	return m
+}
+
+// MessageHandler sets the handler
+func (m *MockGossipAdapter) MessageHandler(handler MessageHandler) *MockGossipAdapter {
+	m.handler = handler
+	return m
+}
+
+// PeersOfChannel returns the members
+func (m *MockGossipAdapter) PeersOfChannel(common.ChainID) []discovery.NetworkMember {
+	return m.members
+}
+
+// SelfMembershipInfo returns self
+func (m *MockGossipAdapter) SelfMembershipInfo() discovery.NetworkMember {
+	return m.self
+}
+
+// IdentityInfo returns the identitySet of this adapter
+func (m *MockGossipAdapter) IdentityInfo() gossipapi.PeerIdentitySet {
+	return m.identitySet
+}
+
+// Send sends a message to remote peers
+func (m *MockGossipAdapter) Send(msg *gossipproto.GossipMessage, peers ...*comm.RemotePeer) {
+	if m.handler != nil {
+		go m.handler(msg)
+	}
+}
+
+// NewMember creates a new network member
+func NewMember(endpoint string, pkiID []byte, roles ...string) discovery.NetworkMember {
+	return discovery.NetworkMember{
+		Endpoint: endpoint,
+		PKIid:    pkiID,
+		Properties: &gossipproto.Properties{
+			Roles: roles,
+		},
+	}
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockgossipmsg.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockgossipmsg.go
new file mode 100644
index 00000000..565b430f
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockgossipmsg.go
@@ -0,0 +1,130 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"github.com/hyperledger/fabric/extensions/collections/api/store"
+	"github.com/hyperledger/fabric/gossip/discovery"
+	"github.com/hyperledger/fabric/gossip/protoext"
+	gproto "github.com/hyperledger/fabric/protos/gossip"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common"
+)
+
+// KeyVal stores a key and a value
+type KeyVal struct {
+	*store.Key
+	*store.ExpiringValue
+}
+
+// NewKeyValue creates a new KeyVal
+func NewKeyValue(key *store.Key, value *store.ExpiringValue) *KeyVal {
+	return &KeyVal{
+		Key:           key,
+		ExpiringValue: value,
+	}
+}
+
+// NewCollDataReqMsg returns a mock collection data request message
+func NewCollDataReqMsg(channelID string, reqID uint64, keys ...*store.Key) *protoext.SignedGossipMessage {
+	var digests []*gproto.CollDataDigest
+	for _, key := range keys {
+		digests = append(digests, &gproto.CollDataDigest{
+			Namespace:      key.Namespace,
+			Collection:     key.Collection,
+			Key:            key.Key,
+			EndorsedAtTxID: key.EndorsedAtTxID,
+		})
+	}
+
+	msg, _ := protoext.NoopSign(&gproto.GossipMessage{
+		Tag:     gproto.GossipMessage_CHAN_ONLY,
+		Channel: []byte(channelID),
+		Content: &gproto.GossipMessage_CollDataReq{
+			CollDataReq: &gproto.RemoteCollDataRequest{
+				Nonce:   reqID,
+				Digests: digests,
+			},
+		},
+	})
+	return msg
+}
+
+// NewCollDataResMsg returns a mock collection data response message
+func NewCollDataResMsg(channelID string, reqID uint64, keyVals ...*KeyVal) *protoext.SignedGossipMessage {
+	var elements []*gproto.CollDataElement
+	for _, kv := range keyVals {
+		elements = append(elements, &gproto.CollDataElement{
+			Digest: &gproto.CollDataDigest{
+				Namespace:      kv.Namespace,
+				Collection:     kv.Collection,
+				Key:            kv.Key.Key,
+				EndorsedAtTxID: kv.EndorsedAtTxID,
+			},
+			Value:      kv.Value,
+			ExpiryTime: common.ToTimestamp(kv.Expiry),
+		})
+	}
+
+	msg, _ := protoext.NoopSign(&gproto.GossipMessage{
+		Tag:     gproto.GossipMessage_CHAN_ONLY,
+		Channel: []byte(channelID),
+		Content: &gproto.GossipMessage_CollDataRes{
+			CollDataRes: &gproto.RemoteCollDataResponse{
+				Nonce:    reqID,
+				Elements: elements,
+			},
+		},
+	})
+	return msg
+}
+
+// NewDataMsg returns a mock data message
+func NewDataMsg(channelID string) *protoext.SignedGossipMessage {
+	msg, _ := protoext.NoopSign(&gproto.GossipMessage{
+		Tag:     gproto.GossipMessage_CHAN_ONLY,
+		Channel: []byte(channelID),
+		Content: &gproto.GossipMessage_DataMsg{},
+	})
+	return msg
+}
+
+// MockReceivedMessage mocks the Gossip received message
+type MockReceivedMessage struct {
+	Message   *protoext.SignedGossipMessage
+	RespondTo func(msg *gproto.GossipMessage)
+	Member    discovery.NetworkMember
+}
+
+// Respond responds to the given request
+func (m *MockReceivedMessage) Respond(msg *gproto.GossipMessage) {
+	if m.RespondTo != nil {
+		m.RespondTo(msg)
+	}
+}
+
+// GetGossipMessage returns the mock signed gossip message
+func (m *MockReceivedMessage) GetGossipMessage() *protoext.SignedGossipMessage {
+	return m.Message
+}
+
+// GetSourceEnvelope is not implemented
+func (m *MockReceivedMessage) GetSourceEnvelope() *gproto.Envelope {
+	panic("not implemented")
+}
+
+// GetConnectionInfo returns the connection information of the source of the message
+func (m *MockReceivedMessage) GetConnectionInfo() *protoext.ConnectionInfo {
+	return &protoext.ConnectionInfo{
+		ID:       m.Member.PKIid,
+		Endpoint: m.Member.Endpoint,
+	}
+}
+
+// Ack is a noop
+func (m *MockReceivedMessage) Ack(err error) {
+	// Nothing to do
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockledger.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockledger.go
new file mode 100644
index 00000000..366caf27
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockledger.go
@@ -0,0 +1,107 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"github.com/hyperledger/fabric/common/ledger"
+	ledger2 "github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/peer"
+)
+
+// Ledger is a struct which is used to retrieve data using query
+type Ledger struct {
+	QueryExecutor  *QueryExecutor
+	TxSimulator    *TxSimulator
+	BlockchainInfo *common.BlockchainInfo
+	Error          error
+	BcInfoError    error
+}
+
+// GetConfigHistoryRetriever returns the config history retriever
+func (m *Ledger) GetConfigHistoryRetriever() (ledger2.ConfigHistoryRetriever, error) {
+	panic("not implemented")
+}
+
+// GetBlockchainInfo returns the block chain info
+func (m *Ledger) GetBlockchainInfo() (*common.BlockchainInfo, error) {
+	return m.BlockchainInfo, m.BcInfoError
+}
+
+// GetBlockByNumber returns the block by number
+func (m *Ledger) GetBlockByNumber(blockNumber uint64) (*common.Block, error) {
+	panic("not implemented")
+}
+
+// GetBlocksIterator returns the block iterator
+func (m *Ledger) GetBlocksIterator(startBlockNumber uint64) (ledger.ResultsIterator, error) {
+	panic("not implemented")
+}
+
+// Close closes the ledger
+func (m *Ledger) Close() {
+}
+
+// GetTransactionByID gets the transaction by id
+func (m *Ledger) GetTransactionByID(txID string) (*peer.ProcessedTransaction, error) {
+	panic("not implemented")
+}
+
+// GetBlockByHash returns the block by hash
+func (m *Ledger) GetBlockByHash(blockHash []byte) (*common.Block, error) {
+	panic("not implemented")
+}
+
+// GetBlockByTxID gets the block by transaction id
+func (m *Ledger) GetBlockByTxID(txID string) (*common.Block, error) {
+	panic("not implemented")
+}
+
+// GetTxValidationCodeByTxID gets the validation code
+func (m *Ledger) GetTxValidationCodeByTxID(txID string) (peer.TxValidationCode, error) {
+	panic("not implemented")
+}
+
+// NewTxSimulator returns the transaction simulator
+func (m *Ledger) NewTxSimulator(txid string) (ledger2.TxSimulator, error) {
+	return m.TxSimulator, m.Error
+}
+
+// NewQueryExecutor returns the query executor
+func (m *Ledger) NewQueryExecutor() (ledger2.QueryExecutor, error) {
+	return m.QueryExecutor, m.Error
+}
+
+// NewHistoryQueryExecutor returns the history query executor
+func (m *Ledger) NewHistoryQueryExecutor() (ledger2.HistoryQueryExecutor, error) {
+	panic("not implemented")
+}
+
+// GetPvtDataAndBlockByNum gets private data and block by block number
+func (m *Ledger) GetPvtDataAndBlockByNum(blockNum uint64, filter ledger2.PvtNsCollFilter) (*ledger2.BlockAndPvtData, error) {
+	panic("not implemented")
+}
+
+// GetPvtDataByNum gets private data by number
+func (m *Ledger) GetPvtDataByNum(blockNum uint64, filter ledger2.PvtNsCollFilter) ([]*ledger2.TxPvtData, error) {
+	panic("not implemented")
+}
+
+// CommitWithPvtData commits the private data
+func (m *Ledger) CommitWithPvtData(blockAndPvtdata *ledger2.BlockAndPvtData) error {
+	panic("not implemented")
+}
+
+// CommitPvtDataOfOldBlocks commits the private data of old blocks
+func (m *Ledger) CommitPvtDataOfOldBlocks(blockPvtData []*ledger2.BlockPvtData) ([]*ledger2.PvtdataHashMismatch, error) {
+	panic("not implemented")
+}
+
+// GetMissingPvtDataTracker returns the private data tracker
+func (m *Ledger) GetMissingPvtDataTracker() (ledger2.MissingPvtDataTracker, error) {
+	panic("not implemented")
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockqueryexecutor.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockqueryexecutor.go
new file mode 100644
index 00000000..5ee75fdb
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockqueryexecutor.go
@@ -0,0 +1,124 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"fmt"
+
+	commonledger "github.com/hyperledger/fabric/common/ledger"
+	"github.com/hyperledger/fabric/core/ledger"
+)
+
+// QueryExecutor is a mock query executor
+type QueryExecutor struct {
+	State map[string]map[string][]byte
+	Error error
+}
+
+// NewQueryExecutor returns a new mock query executor
+func NewQueryExecutor(state map[string]map[string][]byte) *QueryExecutor {
+	return &QueryExecutor{
+		State: state,
+	}
+}
+
+// WithError injects an error to the mock executor
+func (m *QueryExecutor) WithError(err error) *QueryExecutor {
+	m.Error = err
+	return m
+}
+
+// GetState returns the mock state for the given namespace and key
+func (m *QueryExecutor) GetState(namespace string, key string) ([]byte, error) {
+	if m.Error != nil {
+		return nil, m.Error
+	}
+
+	ns := m.State[namespace]
+	if ns == nil {
+		return nil, fmt.Errorf("Could not retrieve namespace %s", namespace)
+	}
+
+	return ns[key], nil
+}
+
+// GetStateMultipleKeys returns the mock state for the given namespace and keys
+func (m *QueryExecutor) GetStateMultipleKeys(namespace string, keys []string) ([][]byte, error) {
+	values := make([][]byte, len(keys))
+	for i, k := range keys {
+		v, err := m.GetState(namespace, k)
+		if err != nil {
+			return nil, err
+		}
+		values[i] = v
+	}
+	return values, nil
+}
+
+// GetStateRangeScanIterator is not currently implemented and will panic if called
+func (m *QueryExecutor) GetStateRangeScanIterator(namespace string, startKey string, endKey string) (commonledger.ResultsIterator, error) {
+	panic("not implemented")
+}
+
+// GetStateRangeScanIteratorWithMetadata is not currently implemented and will panic if called
+func (m *QueryExecutor) GetStateRangeScanIteratorWithMetadata(namespace string, startKey, endKey string, metadata map[string]interface{}) (ledger.QueryResultsIterator, error) {
+	panic("not implemented")
+}
+
+// ExecuteQuery is not currently implemented and will panic if called
+func (m *QueryExecutor) ExecuteQuery(namespace, query string) (commonledger.ResultsIterator, error) {
+	panic("not implemented")
+}
+
+// ExecuteQueryWithMetadata is not currently implemented and will panic if called
+func (m *QueryExecutor) ExecuteQueryWithMetadata(namespace, query string, metadata map[string]interface{}) (ledger.QueryResultsIterator, error) {
+	panic("not implemented")
+}
+
+// GetPrivateData returns the private data for the given namespace, collection, and key
+func (m *QueryExecutor) GetPrivateData(namespace, collection, key string) ([]byte, error) {
+	return m.GetState(namespace+"$"+collection, key)
+}
+
+// GetPrivateDataHash is not currently implemented and will panic if called
+func (m *QueryExecutor) GetPrivateDataHash(namespace, collection, key string) ([]byte, error) {
+	panic("not implemented")
+}
+
+// GetPrivateDataMetadataByHash is not currently implemented and will panic if called
+func (m *QueryExecutor) GetPrivateDataMetadataByHash(namespace, collection string, keyhash []byte) (map[string][]byte, error) {
+	panic("not implemented")
+}
+
+// GetPrivateDataMultipleKeys returns the private data for the given namespace, collection, and keys
+func (m *QueryExecutor) GetPrivateDataMultipleKeys(namespace, collection string, keys []string) ([][]byte, error) {
+	return m.GetStateMultipleKeys(namespace+"$"+collection, keys)
+}
+
+// GetPrivateDataRangeScanIterator is not currently implemented and will panic if called
+func (m *QueryExecutor) GetPrivateDataRangeScanIterator(namespace, collection, startKey, endKey string) (commonledger.ResultsIterator, error) {
+	panic("not implemented")
+}
+
+// ExecuteQueryOnPrivateData is not currently implemented and will panic if called
+func (m *QueryExecutor) ExecuteQueryOnPrivateData(namespace, collection, query string) (commonledger.ResultsIterator, error) {
+	panic("not implemented")
+}
+
+// Done does nothing
+func (m *QueryExecutor) Done() {
+}
+
+// GetStateMetadata is not currently implemented and will panic if called
+func (m *QueryExecutor) GetStateMetadata(namespace, key string) (map[string][]byte, error) {
+	panic("not implemented")
+}
+
+// GetPrivateDataMetadata is not currently implemented and will panic if called
+func (m *QueryExecutor) GetPrivateDataMetadata(namespace, collection, key string) (map[string][]byte, error) {
+	panic("not implemented")
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockrwsetbuilder.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockrwsetbuilder.go
new file mode 100644
index 00000000..45cc4357
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockrwsetbuilder.go
@@ -0,0 +1,345 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/common/cauthdsl"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	"github.com/hyperledger/fabric/protos/transientstore"
+)
+
+// ReadWriteSetBuilder is a utility that builds a TxReadWriteSet for unit testing
+type ReadWriteSetBuilder struct {
+	namespaces []*NamespaceBuilder
+}
+
+// NewReadWriteSetBuilder returns a new ReadWriteSetBuilder
+func NewReadWriteSetBuilder() *ReadWriteSetBuilder {
+	return &ReadWriteSetBuilder{}
+}
+
+// Namespace returns a new NamespaceBuilder
+func (b *ReadWriteSetBuilder) Namespace(name string) *NamespaceBuilder {
+	ns := NewNamespaceBuilder(name)
+	b.namespaces = append(b.namespaces, ns)
+	return ns
+}
+
+// Build builds the read-write sets
+func (b *ReadWriteSetBuilder) Build() *rwset.TxReadWriteSet {
+	txRWSet := &rwset.TxReadWriteSet{
+		DataModel: rwset.TxReadWriteSet_KV,
+	}
+
+	for _, ns := range b.namespaces {
+		txRWSet.NsRwset = append(txRWSet.NsRwset,
+			&rwset.NsReadWriteSet{
+				Namespace:             ns.name,
+				Rwset:                 ns.BuildNSReadWriteSets(),
+				CollectionHashedRwset: ns.BuildCollectionHashedRWSets(),
+			},
+		)
+	}
+
+	return txRWSet
+}
+
+// PvtReadWriteSetBuilder is a utility that builds a TxPvtReadWriteSetWithConfigInfo for unit testing
+type PvtReadWriteSetBuilder struct {
+	namespaces []*NamespaceBuilder
+}
+
+// NewPvtReadWriteSetBuilder returns a new PvtReadWriteSetBuilder
+func NewPvtReadWriteSetBuilder() *PvtReadWriteSetBuilder {
+	return &PvtReadWriteSetBuilder{}
+}
+
+// Namespace returns a new NamespaceBuilder
+func (b *PvtReadWriteSetBuilder) Namespace(name string) *NamespaceBuilder {
+	ns := NewNamespaceBuilder(name)
+	b.namespaces = append(b.namespaces, ns)
+	return ns
+}
+
+// Build builds a TxPvtReadWriteSetWithConfigInfo
+func (b *PvtReadWriteSetBuilder) Build() *transientstore.TxPvtReadWriteSetWithConfigInfo {
+	return &transientstore.TxPvtReadWriteSetWithConfigInfo{
+		PvtRwset:          b.BuildReadWriteSet(),
+		CollectionConfigs: b.BuildCollectionConfigs(),
+	}
+}
+
+// BuildReadWriteSet builds the private read-write sets
+func (b *PvtReadWriteSetBuilder) BuildReadWriteSet() *rwset.TxPvtReadWriteSet {
+	pvtWriteSet := &rwset.TxPvtReadWriteSet{
+		DataModel: rwset.TxReadWriteSet_KV,
+	}
+
+	for _, ns := range b.namespaces {
+		pvtWriteSet.NsPvtRwset = append(pvtWriteSet.NsPvtRwset,
+			&rwset.NsPvtReadWriteSet{
+				Namespace:          ns.name,
+				CollectionPvtRwset: ns.BuildReadWriteSets(),
+			},
+		)
+	}
+
+	return pvtWriteSet
+}
+
+// BuildCollectionConfigs builds the collection config package
+func (b *PvtReadWriteSetBuilder) BuildCollectionConfigs() map[string]*common.CollectionConfigPackage {
+	configs := make(map[string]*common.CollectionConfigPackage)
+	for _, ns := range b.namespaces {
+		configs[ns.name] = ns.BuildCollectionConfig()
+	}
+	return configs
+}
+
+// NamespaceBuilder is a utility that builds a CollectionPvtReadWriteSet and CollectionConfigPackage for unit testing
+type NamespaceBuilder struct {
+	name        string
+	reads       map[string]*kvrwset.Version
+	writes      map[string][]byte
+	collections []*CollectionBuilder
+	marshalErr  bool
+}
+
+// NewNamespaceBuilder returns a new namespace builder
+func NewNamespaceBuilder(name string) *NamespaceBuilder {
+	return &NamespaceBuilder{
+		name:   name,
+		reads:  make(map[string]*kvrwset.Version),
+		writes: make(map[string][]byte),
+	}
+}
+
+// Read adds a new read to the namespace
+func (b *NamespaceBuilder) Read(key string, blockNum uint64, txIdx uint64) *NamespaceBuilder {
+	b.reads[key] = &kvrwset.Version{BlockNum: blockNum, TxNum: txIdx}
+	return b
+}
+
+// Write adds a new write to the namespace
+func (b *NamespaceBuilder) Write(key string, value []byte) *NamespaceBuilder {
+	b.writes[key] = value
+	return b
+}
+
+// Delete adds a new write with 'IsDelete=true' to the namespace
+func (b *NamespaceBuilder) Delete(key string) *NamespaceBuilder {
+	b.writes[key] = nil
+	return b
+}
+
+// Collection adds a new collection
+func (b *NamespaceBuilder) Collection(name string) *CollectionBuilder {
+	cb := NewPvtReadWriteSetCollectionBuilder(name)
+	b.collections = append(b.collections, cb)
+	return cb
+}
+
+// WithMarshalError simulates a marshalling error
+func (b *NamespaceBuilder) WithMarshalError() *NamespaceBuilder {
+	b.marshalErr = true
+	return b
+}
+
+// BuildReadWriteSets builds the collection read-write sets for the namespace
+func (b *NamespaceBuilder) BuildReadWriteSets() []*rwset.CollectionPvtReadWriteSet {
+	var rwSets []*rwset.CollectionPvtReadWriteSet
+	for _, coll := range b.collections {
+		rwSets = append(rwSets, coll.Build())
+	}
+	return rwSets
+}
+
+// BuildNSReadWriteSets builds the read-write sets
+func (b *NamespaceBuilder) BuildNSReadWriteSets() []byte {
+	kvRWSet := &kvrwset.KVRWSet{}
+	for key, version := range b.reads {
+		kvRWSet.Reads = append(kvRWSet.Reads, &kvrwset.KVRead{Key: key, Version: version})
+	}
+	for key, value := range b.writes {
+		kvRWSet.Writes = append(kvRWSet.Writes, &kvrwset.KVWrite{Key: key, Value: value, IsDelete: value == nil})
+	}
+
+	if b.marshalErr {
+		return []byte("invalid proto buf")
+	}
+
+	bytes, err := proto.Marshal(kvRWSet)
+	if err != nil {
+		panic(err.Error())
+	}
+	return bytes
+}
+
+// BuildCollectionHashedRWSets builds the collection-hashed read-write sets
+func (b *NamespaceBuilder) BuildCollectionHashedRWSets() []*rwset.CollectionHashedReadWriteSet {
+	var collHashedRWSets []*rwset.CollectionHashedReadWriteSet
+	for _, coll := range b.collections {
+		collHashedRWSets = append(collHashedRWSets, &rwset.CollectionHashedReadWriteSet{
+			CollectionName: coll.name,
+			HashedRwset:    []byte("hashed-rw-set"),
+			PvtRwsetHash:   []byte("pvt-rw-set-hash"),
+		})
+	}
+	return collHashedRWSets
+}
+
+// BuildCollectionConfig builds the collection config package for the namespace
+func (b *NamespaceBuilder) BuildCollectionConfig() *common.CollectionConfigPackage {
+	cp := &common.CollectionConfigPackage{}
+	for _, coll := range b.collections {
+		config := coll.buildConfig()
+		cp.Config = append(cp.Config, config)
+	}
+	return cp
+}
+
+// CollectionBuilder is a utility that builds a CollectionConfig and private data read/write sets for unit testing
+type CollectionBuilder struct {
+	name              string
+	reads             map[string]*kvrwset.Version
+	writes            map[string][]byte
+	policy            string
+	requiredPeerCount int32
+	maximumPeerCount  int32
+	blocksToLive      uint64
+	collType          common.CollectionType
+	marshalErr        bool
+	ttl               string
+}
+
+// NewPvtReadWriteSetCollectionBuilder returns a new private read-write set collection builder
+func NewPvtReadWriteSetCollectionBuilder(name string) *CollectionBuilder {
+	return &CollectionBuilder{
+		name:   name,
+		reads:  make(map[string]*kvrwset.Version),
+		writes: make(map[string][]byte),
+	}
+}
+
+// Read adds a new read to the collection
+func (c *CollectionBuilder) Read(key string, blockNum uint64, txIdx uint64) *CollectionBuilder {
+	c.reads[key] = &kvrwset.Version{BlockNum: blockNum, TxNum: txIdx}
+	return c
+}
+
+// Write adds a new write to the collection
+func (c *CollectionBuilder) Write(key string, value []byte) *CollectionBuilder {
+	c.writes[key] = value
+	return c
+}
+
+// Delete adds a new write with 'IsDelete=true' to the collection
+func (c *CollectionBuilder) Delete(key string) *CollectionBuilder {
+	c.writes[key] = nil
+	return c
+}
+
+// TransientConfig sets the transient collection config
+func (c *CollectionBuilder) TransientConfig(policy string, requiredPeerCount, maximumPeerCount int32, ttl string) *CollectionBuilder {
+	c.policy = policy
+	c.requiredPeerCount = requiredPeerCount
+	c.maximumPeerCount = maximumPeerCount
+	c.collType = common.CollectionType_COL_TRANSIENT
+	c.ttl = ttl
+	return c
+}
+
+// StaticConfig sets the static collection config
+func (c *CollectionBuilder) StaticConfig(policy string, requiredPeerCount, maximumPeerCount int32, btl uint64) *CollectionBuilder {
+	c.policy = policy
+	c.requiredPeerCount = requiredPeerCount
+	c.maximumPeerCount = maximumPeerCount
+	c.blocksToLive = btl
+	return c
+}
+
+// OffLedgerConfig sets the off-ledger collection config
+func (c *CollectionBuilder) OffLedgerConfig(policy string, requiredPeerCount, maximumPeerCount int32, ttl string) *CollectionBuilder {
+	c.policy = policy
+	c.requiredPeerCount = requiredPeerCount
+	c.maximumPeerCount = maximumPeerCount
+	c.collType = common.CollectionType_COL_OFFLEDGER
+	c.ttl = ttl
+	return c
+}
+
+// DCASConfig sets the DCAS collection config
+func (c *CollectionBuilder) DCASConfig(policy string, requiredPeerCount, maximumPeerCount int32, ttl string) *CollectionBuilder {
+	c.policy = policy
+	c.requiredPeerCount = requiredPeerCount
+	c.maximumPeerCount = maximumPeerCount
+	c.collType = common.CollectionType_COL_DCAS
+	c.ttl = ttl
+	return c
+}
+
+// WithMarshalError simulates a marshalling error
+func (c *CollectionBuilder) WithMarshalError() *CollectionBuilder {
+	c.marshalErr = true
+	return c
+}
+
+// Build builds the collection private read-write set
+func (c *CollectionBuilder) Build() *rwset.CollectionPvtReadWriteSet {
+	return &rwset.CollectionPvtReadWriteSet{
+		CollectionName: c.name,
+		Rwset:          c.buildReadWriteSet(),
+	}
+}
+
+func (c *CollectionBuilder) buildReadWriteSet() []byte {
+	kvRWSet := &kvrwset.KVRWSet{}
+	for key, version := range c.reads {
+		kvRWSet.Reads = append(kvRWSet.Reads, &kvrwset.KVRead{Key: key, Version: version})
+	}
+	for key, value := range c.writes {
+		kvRWSet.Writes = append(kvRWSet.Writes, &kvrwset.KVWrite{Key: key, Value: value, IsDelete: value == nil})
+	}
+
+	if c.marshalErr {
+		return []byte("invalid proto buf")
+	}
+
+	bytes, err := proto.Marshal(kvRWSet)
+	if err != nil {
+		panic(err.Error())
+	}
+	return bytes
+}
+
+func (c *CollectionBuilder) buildConfig() *common.CollectionConfig {
+	signaturePolicyEnvelope, err := cauthdsl.FromString(c.policy)
+	if err != nil {
+		panic(err.Error())
+	}
+
+	return &common.CollectionConfig{
+		Payload: &common.CollectionConfig_StaticCollectionConfig{
+			StaticCollectionConfig: &common.StaticCollectionConfig{
+				Type: c.collType,
+				Name: c.name,
+				MemberOrgsPolicy: &common.CollectionPolicyConfig{
+					Payload: &common.CollectionPolicyConfig_SignaturePolicy{
+						SignaturePolicy: signaturePolicyEnvelope,
+					},
+				},
+				RequiredPeerCount: c.requiredPeerCount,
+				MaximumPeerCount:  c.maximumPeerCount,
+				BlockToLive:       c.blocksToLive,
+				TimeToLive:        c.ttl,
+			},
+		},
+	}
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mocksupport.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mocksupport.go
new file mode 100644
index 00000000..2f1b9946
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mocksupport.go
@@ -0,0 +1,61 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	"github.com/hyperledger/fabric/core/common/privdata"
+	gossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+	cb "github.com/hyperledger/fabric/protos/common"
+	"github.com/pkg/errors"
+)
+
+// MockSupport is a holder of policy, config and error
+type MockSupport struct {
+	CollPolicy  privdata.CollectionAccessPolicy
+	CollConfigs []*cb.StaticCollectionConfig
+	Err         error
+	Publisher   *MockBlockPublisher
+}
+
+// NewMockSupport returns a new MockSupport
+func NewMockSupport() *MockSupport {
+	return &MockSupport{
+		Publisher: NewBlockPublisher(),
+	}
+}
+
+// CollectionPolicy sets the collection access policy for the given collection
+func (s *MockSupport) CollectionPolicy(collPolicy privdata.CollectionAccessPolicy) *MockSupport {
+	s.CollPolicy = collPolicy
+	return s
+}
+
+// CollectionConfig sets the collection config for the given collection
+func (s *MockSupport) CollectionConfig(collConfig *cb.StaticCollectionConfig) *MockSupport {
+	s.CollConfigs = append(s.CollConfigs, collConfig)
+	return s
+}
+
+// Policy returns the collection access policy for the given collection
+func (s *MockSupport) Policy(channelID, ns, coll string) (privdata.CollectionAccessPolicy, error) {
+	return s.CollPolicy, s.Err
+}
+
+// Config returns the collection config for the given collection
+func (s *MockSupport) Config(channelID, ns, coll string) (*cb.StaticCollectionConfig, error) {
+	for _, config := range s.CollConfigs {
+		if config.Name == coll {
+			return config, nil
+		}
+	}
+	return nil, errors.Errorf("config not found for collection: %s", coll)
+}
+
+// BlockPublisher returns a mock block publisher for the given channel
+func (s *MockSupport) BlockPublisher(channelID string) gossipapi.BlockPublisher {
+	return s.Publisher
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mocktxsim.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mocktxsim.go
new file mode 100644
index 00000000..26eec58d
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mocktxsim.go
@@ -0,0 +1,80 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package mocks
+
+import (
+	ledgermocks "github.com/hyperledger/fabric/common/mocks/ledger"
+	"github.com/hyperledger/fabric/core/ledger"
+)
+
+// TxSimulator implements a mock transaction simulator
+type TxSimulator struct {
+	ledgermocks.MockQueryExecutor
+	SimulationResults *ledger.TxSimulationResults
+	Error             error
+	SimError          error
+}
+
+// SetState is not currently implemented and will panic if called
+func (m *TxSimulator) SetState(namespace string, key string, value []byte) error {
+	panic("not implemented")
+}
+
+// DeleteState is not currently implemented and will panic if called
+func (m *TxSimulator) DeleteState(namespace string, key string) error {
+	panic("not implemented")
+}
+
+// SetStateMultipleKeys is not currently implemented and will panic if called
+func (m *TxSimulator) SetStateMultipleKeys(namespace string, kvs map[string][]byte) error {
+	panic("not implemented")
+}
+
+// ExecuteUpdate is not currently implemented and will panic if called
+func (m *TxSimulator) ExecuteUpdate(query string) error {
+	panic("not implemented")
+}
+
+// GetTxSimulationResults returns the mock simulation results
+func (m *TxSimulator) GetTxSimulationResults() (*ledger.TxSimulationResults, error) {
+	return m.SimulationResults, m.SimError
+}
+
+// DeletePrivateData is not currently implemented and will panic if called
+func (m *TxSimulator) DeletePrivateData(namespace, collection, key string) error {
+	panic("not implemented")
+}
+
+// SetPrivateData is not currently implemented and will panic if called
+func (m *TxSimulator) SetPrivateData(namespace, collection, key string, value []byte) error {
+	panic("not implemented")
+}
+
+// SetPrivateDataMultipleKeys currently does nothing except return the mock error (if any)
+func (m *TxSimulator) SetPrivateDataMultipleKeys(namespace, collection string, kvs map[string][]byte) error {
+	return m.Error
+}
+
+// SetStateMetadata is not currently implemented and will panic if called
+func (m *TxSimulator) SetStateMetadata(namespace, key string, metadata map[string][]byte) error {
+	panic("not implemented")
+}
+
+// DeleteStateMetadata is not currently implemented and will panic if called
+func (m *TxSimulator) DeleteStateMetadata(namespace, key string) error {
+	panic("not implemented")
+}
+
+// SetPrivateDataMetadata is not currently implemented and will panic if called
+func (m *TxSimulator) SetPrivateDataMetadata(namespace, collection, key string, metadata map[string][]byte) error {
+	panic("not implemented")
+}
+
+// DeletePrivateDataMetadata is not currently implemented and will panic if called
+func (m *TxSimulator) DeletePrivateDataMetadata(namespace, collection, key string) error {
+	panic("not implemented")
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore/store_impl.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore/store_impl.go
new file mode 100644
index 00000000..fd42f469
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore/store_impl.go
@@ -0,0 +1,285 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cachedpvtdatastore
+
+import (
+	"fmt"
+
+	"github.com/pkg/errors"
+
+	"github.com/bluele/gcache"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+	"github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+)
+
+var logger = flogging.MustGetLogger("cachedpvtdatastore")
+
+type provider struct {
+}
+
+type store struct {
+	ledgerid           string
+	btlPolicy          pvtdatapolicy.BTLPolicy
+	cache              gcache.Cache
+	lastCommittedBlock uint64
+	pendingPvtData     *pendingPvtData
+	isEmpty            bool
+}
+
+type pendingPvtData struct {
+	batchPending bool
+	dataEntries  []*common.DataEntry
+}
+
+//////// Provider functions  /////////////
+//////////////////////////////////////////
+
+// NewProvider instantiates a private data storage provider backed by cache
+func NewProvider() pvtdatastorage.Provider {
+	logger.Debugf("constructing cached private data storage provider")
+	return &provider{}
+}
+
+// OpenStore returns a handle to a store
+func (p *provider) OpenStore(ledgerid string) (pvtdatastorage.Store, error) {
+	s := &store{cache: gcache.New(config.GetPvtDataCacheSize()).ARC().Build(), ledgerid: ledgerid,
+		pendingPvtData:     &pendingPvtData{batchPending: false},
+		isEmpty:            true,
+		lastCommittedBlock: 0,
+	}
+
+	logger.Debugf("Pvtdata cache store opened. Initial state: isEmpty [%t], lastCommittedBlock [%d]",
+		s.isEmpty, s.lastCommittedBlock)
+
+	return s, nil
+}
+
+// Close closes the store
+func (p *provider) Close() {
+}
+
+//////// store functions  ////////////////
+//////////////////////////////////////////
+
+func (s *store) Init(btlPolicy pvtdatapolicy.BTLPolicy) {
+	s.btlPolicy = btlPolicy
+}
+
+// Prepare implements the function in the interface `Store`
+func (s *store) Prepare(blockNum uint64, pvtData []*ledger.TxPvtData, missingPvtData ledger.TxMissingPvtDataMap) error {
+	if !roles.IsCommitter() {
+		panic("calling Prepare on a peer that is not a committer")
+	}
+
+	if s.pendingPvtData.batchPending {
+		return pvtdatastorage.NewErrIllegalCall(`A pending batch exists as as result of last invoke to "Prepare" call. Invoke "Commit" or "Rollback" on the pending batch before invoking "Prepare" function`)
+	}
+
+	expectedBlockNum := s.nextBlockNum()
+	if expectedBlockNum != blockNum {
+		return pvtdatastorage.NewErrIllegalCall(fmt.Sprintf("Expected block number=%d, received block number=%d", expectedBlockNum, blockNum))
+	}
+
+	storeEntries, err := common.PrepareStoreEntries(blockNum, pvtData, s.btlPolicy, missingPvtData)
+	if err != nil {
+		return err
+	}
+
+	s.pendingPvtData = &pendingPvtData{batchPending: true}
+	if len(storeEntries.DataEntries) > 0 {
+		s.pendingPvtData.dataEntries = storeEntries.DataEntries
+	}
+	logger.Debugf("Saved %d private data write sets for block [%d]", len(pvtData), blockNum)
+	return nil
+}
+
+// Commit implements the function in the interface `Store`
+func (s *store) Commit() error {
+	if !roles.IsCommitter() {
+		panic("calling Commit on a peer that is not a committer")
+	}
+
+	committingBlockNum := s.nextBlockNum()
+	logger.Debugf("Committing private data for block [%d]", committingBlockNum)
+
+	if s.pendingPvtData.dataEntries != nil {
+		err := s.cache.Set(committingBlockNum, s.pendingPvtData.dataEntries)
+		if err != nil {
+			return errors.WithMessage(err, fmt.Sprintf("writing private data to cache failed [%d]", committingBlockNum))
+		}
+	}
+
+	s.pendingPvtData = &pendingPvtData{batchPending: false}
+	s.isEmpty = false
+	s.lastCommittedBlock = committingBlockNum
+
+	logger.Debugf("Committed private data for block [%d]", committingBlockNum)
+	return nil
+}
+
+// Rollback implements the function in the interface `Store`
+func (s *store) Rollback() error {
+	if !roles.IsCommitter() {
+		panic("calling Rollback on a peer that is not a committer")
+	}
+
+	s.pendingPvtData = &pendingPvtData{batchPending: false}
+	return nil
+}
+
+// CommitPvtDataOfOldBlocks implements the function in the interface `Store`
+func (s *store) CommitPvtDataOfOldBlocks(blocksPvtData map[uint64][]*ledger.TxPvtData) error {
+	return errors.New("not supported")
+}
+
+// GetLastUpdatedOldBlocksPvtData implements the function in the interface `Store`
+func (s *store) GetLastUpdatedOldBlocksPvtData() (map[uint64][]*ledger.TxPvtData, error) {
+	return nil, errors.New("not supported")
+}
+
+// ResetLastUpdatedOldBlocksList implements the function in the interface `Store`
+func (s *store) ResetLastUpdatedOldBlocksList() error {
+	return errors.New("not supported")
+}
+
+// GetPvtDataByBlockNum implements the function in the interface `Store`.
+// If the store is empty or the last committed block number is smaller then the
+// requested block number, an 'ErrOutOfRange' is thrown
+func (s *store) GetPvtDataByBlockNum(blockNum uint64, filter ledger.PvtNsCollFilter) ([]*ledger.TxPvtData, error) {
+	logger.Debugf("Get private data for block [%d], filter=%#v", blockNum, filter)
+	if s.isEmpty {
+		return nil, pvtdatastorage.NewErrOutOfRange("The store is empty")
+	}
+	if blockNum > s.lastCommittedBlock {
+		return nil, pvtdatastorage.NewErrOutOfRange(fmt.Sprintf("Last committed block=%d, block requested=%d", s.lastCommittedBlock, blockNum))
+	}
+
+	value, err := s.cache.Get(blockNum)
+	if err != nil {
+		if err != gcache.KeyNotFoundError {
+			panic(fmt.Sprintf("Get must never return an error other than KeyNotFoundError err:%s", err))
+		}
+		return nil, nil
+	}
+
+	dataEntries := value.([]*common.DataEntry)
+
+	return s.getBlockPvtData(dataEntries, filter, blockNum)
+
+}
+
+// ProcessCollsEligibilityEnabled implements the function in the interface `Store`
+func (s *store) ProcessCollsEligibilityEnabled(committingBlk uint64, nsCollMap map[string][]string) error {
+	return errors.New("not supported")
+}
+
+//GetMissingPvtDataInfoForMostRecentBlocks implements the function in the interface `Store`
+func (s *store) GetMissingPvtDataInfoForMostRecentBlocks(maxBlock int) (ledger.MissingPvtDataInfo, error) {
+	return nil, errors.New("not supported")
+}
+
+// LastCommittedBlockHeight implements the function in the interface `Store`
+func (s *store) LastCommittedBlockHeight() (uint64, error) {
+	if s.isEmpty {
+		return 0, nil
+	}
+	return s.lastCommittedBlock + 1, nil
+}
+
+// HasPendingBatch implements the function in the interface `Store`
+func (s *store) HasPendingBatch() (bool, error) {
+	return s.pendingPvtData.batchPending, nil
+}
+
+// IsEmpty implements the function in the interface `Store`
+func (s *store) IsEmpty() (bool, error) {
+	return s.isEmpty, nil
+}
+
+// InitLastCommittedBlock implements the function in the interface `Store`
+func (s *store) InitLastCommittedBlock(blockNum uint64) error {
+	if !(s.isEmpty && !s.pendingPvtData.batchPending) {
+		return pvtdatastorage.NewErrIllegalCall("The private data store is not empty. InitLastCommittedBlock() function call is not allowed")
+	}
+	s.isEmpty = false
+	s.lastCommittedBlock = blockNum
+
+	logger.Debugf("InitLastCommittedBlock set to block [%d]", blockNum)
+	return nil
+}
+
+// Shutdown implements the function in the interface `Store`
+func (s *store) Shutdown() {
+	// do nothing
+}
+
+func v11RetrievePvtdata(dataEntries []*common.DataEntry, filter ledger.PvtNsCollFilter) ([]*ledger.TxPvtData, error) {
+	var blkPvtData []*ledger.TxPvtData
+	for _, dataEntry := range dataEntries {
+		value, err := common.EncodeDataValue(dataEntry.Value)
+		if err != nil {
+			return nil, err
+		}
+		pvtDatum, err := common.V11DecodeKV(common.EncodeDataKey(dataEntry.Key), value, filter)
+		if err != nil {
+			return nil, err
+		}
+		blkPvtData = append(blkPvtData, pvtDatum)
+	}
+	return blkPvtData, nil
+}
+
+func (s *store) nextBlockNum() uint64 {
+	if s.isEmpty {
+		return 0
+	}
+	return s.lastCommittedBlock + 1
+}
+
+func (s *store) getBlockPvtData(dataEntries []*common.DataEntry, filter ledger.PvtNsCollFilter, blockNum uint64) ([]*ledger.TxPvtData, error) {
+	var blockPvtdata []*ledger.TxPvtData
+	var currentTxNum uint64
+	var currentTxWsetAssember *common.TxPvtdataAssembler
+	firstItr := true
+
+	for _, dataEntry := range dataEntries {
+		dataKeyBytes := common.EncodeDataKey(dataEntry.Key)
+		if common.V11Format(dataKeyBytes) {
+			return v11RetrievePvtdata(dataEntries, filter)
+		}
+		expired, err := common.IsExpired(dataEntry.Key.NsCollBlk, s.btlPolicy, s.lastCommittedBlock)
+		if err != nil {
+			return nil, err
+		}
+		if expired || !common.PassesFilter(dataEntry.Key, filter) {
+			continue
+		}
+
+		if firstItr {
+			currentTxNum = dataEntry.Key.TxNum
+			currentTxWsetAssember = common.NewTxPvtdataAssembler(blockNum, currentTxNum)
+			firstItr = false
+		}
+
+		if dataEntry.Key.TxNum != currentTxNum {
+			blockPvtdata = append(blockPvtdata, currentTxWsetAssember.GetTxPvtdata())
+			currentTxNum = dataEntry.Key.TxNum
+			currentTxWsetAssember = common.NewTxPvtdataAssembler(blockNum, currentTxNum)
+		}
+		currentTxWsetAssember.Add(dataEntry.Key.Ns, dataEntry.Value)
+	}
+	if currentTxWsetAssember != nil {
+		blockPvtdata = append(blockPvtdata, currentTxWsetAssember.GetTxPvtdata())
+	}
+	return blockPvtdata, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore/test_exports.go
new file mode 100644
index 00000000..32554b24
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore/test_exports.go
@@ -0,0 +1,46 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package cachedpvtdatastore
+
+import (
+	"testing"
+
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	"github.com/stretchr/testify/require"
+)
+
+// StoreEnv provides the  store env for testing
+type StoreEnv struct {
+	t                 testing.TB
+	TestStoreProvider pvtdatastorage.Provider
+	TestStore         pvtdatastorage.Store
+	ledgerid          string
+	btlPolicy         pvtdatapolicy.BTLPolicy
+}
+
+// NewTestStoreEnv construct a StoreEnv for testing
+func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLPolicy) *StoreEnv {
+	req := require.New(t)
+	testStoreProvider := NewProvider()
+	testStore, err := testStoreProvider.OpenStore(ledgerid)
+	req.NoError(err)
+	testStore.Init(btlPolicy)
+	s := &StoreEnv{t, testStoreProvider, testStore, ledgerid, btlPolicy}
+	return s
+}
+
+// CloseAndReopen closes and opens the store provider
+func (env *StoreEnv) CloseAndReopen() {
+	var err error
+	env.TestStoreProvider.Close()
+	env.TestStoreProvider = NewProvider()
+	require.NoError(env.t, err)
+	env.TestStore, err = env.TestStoreProvider.OpenStore(env.ledgerid)
+	env.TestStore.Init(env.btlPolicy)
+	require.NoError(env.t, err)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/couchdb_conv.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/couchdb_conv.go
new file mode 100644
index 00000000..24a3166c
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/couchdb_conv.go
@@ -0,0 +1,277 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatastorage
+
+import (
+	"encoding/hex"
+	"encoding/json"
+	"fmt"
+	"strconv"
+
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common"
+)
+
+const (
+	idField                       = "_id"
+	revField                      = "_rev"
+	dataField                     = "data"
+	expiryField                   = "expiry"
+	expiringBlkNumsField          = "expiringBlkNums"
+	expiringBlockNumbersIndexName = "by_expiring_block_numbers"
+	expiringBlockNumbersIndexDoc  = "indexExpiringBlockNumbers"
+	blockKeyPrefix                = ""
+	lastCommittedBlockID          = "lastCommittedBlock"
+	lastCommittedBlockData        = "data"
+)
+
+type blockPvtDataResponse struct {
+	ID              string            `json:"_id"`
+	Rev             string            `json:"_rev"`
+	Data            map[string][]byte `json:"data"`
+	Expiry          map[string][]byte `json:"expiry"`
+	Deleted         bool              `json:"_deleted"`
+	ExpiringBlkNums []string          `json:"expiringBlkNums"`
+}
+
+type lastCommittedBlockResponse struct {
+	ID   string `json:"_id"`
+	Rev  string `json:"_rev"`
+	Data string `json:"data"`
+}
+
+const expiringBlockNumbersIndexDef = `
+	{
+		"index": {
+			"fields": ["` + expiringBlkNumsField + `"]
+		},
+		"name": "` + expiringBlockNumbersIndexName + `",
+		"ddoc": "` + expiringBlockNumbersIndexDoc + `",
+		"type": "json"
+	}`
+
+type jsonValue map[string]interface{}
+
+func (v jsonValue) toBytes() ([]byte, error) {
+	return json.Marshal(v)
+}
+
+func createPvtDataCouchDoc(storeEntries *common.StoreEntries, blockNumber uint64, rev string) (*couchdb.CouchDoc, error) {
+	if len(storeEntries.DataEntries) <= 0 && len(storeEntries.ExpiryEntries) <= 0 {
+		return nil, nil
+	}
+	jsonMap := make(jsonValue)
+	jsonMap[idField] = blockNumberToKey(blockNumber)
+
+	if rev != "" {
+		jsonMap[revField] = rev
+	}
+
+	dataEntriesJSON, err := dataEntriesToJSONValue(storeEntries.DataEntries)
+	if err != nil {
+		return nil, err
+	}
+	jsonMap[dataField] = dataEntriesJSON
+
+	expiryEntriesJSON, expiringBlkNums, err := expiryEntriesToJSONValue(storeEntries.ExpiryEntries)
+	if err != nil {
+		return nil, err
+	}
+	jsonMap[expiryField] = expiryEntriesJSON
+
+	jsonMap[expiringBlkNumsField] = expiringBlkNums
+
+	jsonBytes, err := jsonMap.toBytes()
+	if err != nil {
+		return nil, err
+	}
+
+	couchDoc := couchdb.CouchDoc{JSONValue: jsonBytes}
+
+	return &couchDoc, nil
+
+}
+
+func createLastCommittedBlockDoc(committingBlockNum uint64, rev string) (*couchdb.CouchDoc, error) {
+	jsonMap := make(jsonValue)
+	jsonMap[idField] = lastCommittedBlockID
+	if rev != "" {
+		jsonMap[revField] = rev
+	}
+	jsonMap[lastCommittedBlockData] = strconv.FormatUint(committingBlockNum, 10)
+	jsonBytes, err := jsonMap.toBytes()
+	if err != nil {
+		return nil, err
+	}
+
+	couchDoc := couchdb.CouchDoc{JSONValue: jsonBytes}
+
+	return &couchDoc, nil
+
+}
+
+func lookupLastBlock(db *couchdb.CouchDatabase) (uint64, string, error) {
+	v, _, err := db.ReadDoc(lastCommittedBlockID)
+	if err != nil {
+		return 0, "", err
+	}
+	if v != nil {
+		var lastBlockResponse lastCommittedBlockResponse
+		if err = json.Unmarshal(v.JSONValue, &lastBlockResponse); err != nil {
+			return 0, "", err
+		}
+		lastBlockNum, err := strconv.ParseInt(lastBlockResponse.Data, 10, 64)
+		if err != nil {
+			return 0, "", err
+		}
+		return uint64(lastBlockNum), lastBlockResponse.Rev, nil
+	}
+	return 0, "", nil
+}
+
+func dataEntriesToJSONValue(dataEntries []*common.DataEntry) (jsonValue, error) {
+	data := make(jsonValue)
+
+	for _, dataEntry := range dataEntries {
+		keyBytes := common.EncodeDataKey(dataEntry.Key)
+		valBytes, err := common.EncodeDataValue(dataEntry.Value)
+		if err != nil {
+			return nil, err
+		}
+
+		keyBytesHex := hex.EncodeToString(keyBytes)
+		data[keyBytesHex] = valBytes
+	}
+
+	return data, nil
+}
+
+func expiryEntriesToJSONValue(expiryEntries []*common.ExpiryEntry) (jsonValue, []string, error) {
+	data := make(jsonValue)
+	expiringBlkNums := make([]string, 0)
+
+	for _, expEntry := range expiryEntries {
+		keyBytes := common.EncodeExpiryKey(expEntry.Key)
+		valBytes, err := common.EncodeExpiryValue(expEntry.Value)
+		if err != nil {
+			return nil, nil, err
+		}
+		expiringBlkNums = append(expiringBlkNums, blockNumberToKey(expEntry.Key.ExpiringBlk))
+		keyBytesHex := hex.EncodeToString(keyBytes)
+		data[keyBytesHex] = valBytes
+	}
+
+	return data, expiringBlkNums, nil
+}
+
+func createPvtDataCouchDB(couchInstance *couchdb.CouchInstance, dbName string) (*couchdb.CouchDatabase, error) {
+	db, err := couchdb.CreateCouchDatabase(couchInstance, dbName)
+	if err != nil {
+		return nil, err
+	}
+	err = db.CreateNewIndexWithRetry(expiringBlockNumbersIndexDef, expiringBlockNumbersIndexDoc)
+	if err != nil {
+		return nil, errors.WithMessage(err, "creation of purge block number index failed")
+	}
+	return db, err
+}
+
+func getPvtDataCouchInstance(couchInstance *couchdb.CouchInstance, dbName string) (*couchdb.CouchDatabase, error) {
+	db, err := couchdb.NewCouchDatabase(couchInstance, dbName)
+	if err != nil {
+		return nil, err
+	}
+
+	dbExists, err := db.ExistsWithRetry()
+	if err != nil {
+		return nil, err
+	}
+	if !dbExists {
+		return nil, errors.Errorf("DB not found: [%s]", db.DBName)
+	}
+
+	indexExists, err := db.IndexDesignDocExistsWithRetry(expiringBlockNumbersIndexDoc)
+	if err != nil {
+		return nil, err
+	}
+	if !indexExists {
+		return nil, errors.Errorf("DB index not found: [%s]", db.DBName)
+	}
+	return db, nil
+}
+
+func retrieveBlockPvtData(db *couchdb.CouchDatabase, id string) (*blockPvtDataResponse, error) {
+	doc, _, err := db.ReadDoc(id)
+	if err != nil {
+		return nil, err
+	}
+
+	if doc == nil {
+		return nil, NewErrNotFoundInIndex()
+	}
+
+	var blockPvtData blockPvtDataResponse
+	err = json.Unmarshal(doc.JSONValue, &blockPvtData)
+	if err != nil {
+		return nil, errors.Wrapf(err, "result from DB is not JSON encoded")
+	}
+
+	return &blockPvtData, nil
+}
+
+func retrieveBlockExpiryData(db *couchdb.CouchDatabase, id string) ([]*blockPvtDataResponse, error) {
+	const queryFmt = `
+	{
+		"selector": {
+			"` + expiringBlkNumsField + `": {
+				"$elemMatch": {
+					"$lte": "%s"
+				}
+			}
+		},
+		"use_index": ["_design/` + expiringBlockNumbersIndexDoc + `", "` + expiringBlockNumbersIndexName + `"]
+	}`
+
+	results, _, err := db.QueryDocuments(fmt.Sprintf(queryFmt, id))
+	if err != nil {
+		return nil, err
+	}
+
+	if len(results) == 0 {
+		return nil, nil
+	}
+
+	var responses []*blockPvtDataResponse
+	for _, result := range results {
+		var blockPvtData blockPvtDataResponse
+		err = json.Unmarshal(result.Value, &blockPvtData)
+		if err != nil {
+			return nil, errors.Wrapf(err, "result from DB is not JSON encoded")
+		}
+		responses = append(responses, &blockPvtData)
+	}
+
+	return responses, nil
+}
+
+func blockNumberToKey(blockNum uint64) string {
+	return fmt.Sprintf("%064s", blockKeyPrefix+strconv.FormatUint(blockNum, 10))
+}
+
+// NotFoundInIndexErr is used to indicate missing entry in the index
+type NotFoundInIndexErr struct {
+}
+
+// NewErrNotFoundInIndex creates an missing entry in the index error
+func NewErrNotFoundInIndex() *NotFoundInIndexErr {
+	return &NotFoundInIndexErr{}
+}
+
+func (err *NotFoundInIndexErr) Error() string {
+	return "Entry not found in index"
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/store_impl.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/store_impl.go
new file mode 100644
index 00000000..1309be6c
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/store_impl.go
@@ -0,0 +1,850 @@
+/*
+Copyright IBM Corp, SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatastorage
+
+import (
+	"encoding/hex"
+	"encoding/json"
+	"fmt"
+	"sort"
+	"strings"
+	"sync"
+
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/common/ledger/util/leveldbhelper"
+	"github.com/hyperledger/fabric/common/metrics/disabled"
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+	"github.com/willf/bitset"
+)
+
+var logger = flogging.MustGetLogger("cdbpvtdatastore")
+
+const (
+	pvtDataStoreName = "pvtdata"
+)
+
+type provider struct {
+	couchInstance            *couchdb.CouchInstance
+	missingKeysIndexProvider *leveldbhelper.Provider
+}
+
+type store struct {
+	ledgerid           string
+	btlPolicy          pvtdatapolicy.BTLPolicy
+	db                 *couchdb.CouchDatabase
+	lastCommittedBlock uint64
+	purgerLock         *sync.Mutex
+	pendingPvtData     *pendingPvtData
+	collElgProc        *common.CollElgProc
+	// missing keys db
+	missingKeysIndexDB *leveldbhelper.DBHandle
+	isEmpty            bool
+	// After committing the pvtdata of old blocks,
+	// the `isLastUpdatedOldBlocksSet` is set to true.
+	// Once the stateDB is updated with these pvtdata,
+	// the `isLastUpdatedOldBlocksSet` is set to false.
+	// isLastUpdatedOldBlocksSet is mainly used during the
+	// recovery process. During the peer startup, if the
+	// isLastUpdatedOldBlocksSet is set to true, the pvtdata
+	// in the stateDB needs to be updated before finishing the
+	// recovery operation.
+	isLastUpdatedOldBlocksSet bool
+}
+
+type pendingPvtData struct {
+	PvtDataDoc         *couchdb.CouchDoc `json:"pvtDataDoc"`
+	MissingDataEntries map[string]string `json:"missingDataEntries"`
+	BatchPending       bool              `json:"batchPending"`
+}
+
+// lastUpdatedOldBlocksList keeps the list of last updated blocks
+// and is stored as the value of lastUpdatedOldBlocksKey (defined in kv_encoding.go)
+type lastUpdatedOldBlocksList []uint64
+
+//////// Provider functions  /////////////
+//////////////////////////////////////////
+
+// NewProvider instantiates a private data storage provider backed by CouchDB
+func NewProvider() (pvtdatastorage.Provider, error) {
+	logger.Debugf("constructing CouchDB private data storage provider")
+	couchDBDef := couchdb.GetCouchDBDefinition()
+
+	return newProviderWithDBDef(couchDBDef)
+}
+
+func newProviderWithDBDef(couchDBDef *couchdb.CouchDBDef) (pvtdatastorage.Provider, error) {
+	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	if err != nil {
+		return nil, errors.WithMessage(err, "obtaining CouchDB instance failed")
+	}
+
+	dbPath := ledgerconfig.GetPvtdataStorePath()
+	missingKeysIndexProvider := leveldbhelper.NewProvider(&leveldbhelper.Conf{DBPath: dbPath})
+
+	return &provider{couchInstance, missingKeysIndexProvider}, nil
+}
+
+// OpenStore returns a handle to a store
+func (p *provider) OpenStore(ledgerid string) (pvtdatastorage.Store, error) {
+	// Create couchdb
+	pvtDataStoreDBName := couchdb.ConstructBlockchainDBName(strings.ToLower(ledgerid), pvtDataStoreName)
+	var db *couchdb.CouchDatabase
+	var err error
+	if roles.IsCommitter() {
+		db, err = createPvtDataCouchDB(p.couchInstance, pvtDataStoreDBName)
+		if err != nil {
+			return nil, err
+		}
+		// Create missing pvt keys index in leveldb
+		missingKeysIndexDB := p.missingKeysIndexProvider.GetDBHandle(ledgerid)
+
+		purgerLock := &sync.Mutex{}
+		s := &store{db: db, ledgerid: ledgerid,
+			collElgProc:        common.NewCollElgProc(purgerLock, missingKeysIndexDB),
+			purgerLock:         purgerLock,
+			missingKeysIndexDB: missingKeysIndexDB,
+			pendingPvtData:     &pendingPvtData{BatchPending: false},
+		}
+
+		if errInitState := s.initState(); errInitState != nil {
+			return nil, errInitState
+		}
+		s.collElgProc.LaunchCollElgProc()
+
+		logger.Debugf("Pvtdata store opened. Initial state: isEmpty [%t], lastCommittedBlock [%d]",
+			s.isEmpty, s.lastCommittedBlock)
+
+		return s, nil
+	}
+
+	db, err = getPvtDataCouchInstance(p.couchInstance, pvtDataStoreDBName)
+	if err != nil {
+		return nil, err
+	}
+	s := &store{db: db, ledgerid: ledgerid,
+		pendingPvtData: &pendingPvtData{BatchPending: false},
+	}
+	lastCommittedBlock, _, err := lookupLastBlock(db)
+	if err != nil {
+		return nil, err
+	}
+	s.isEmpty = true
+	if lastCommittedBlock != 0 {
+		s.lastCommittedBlock = lastCommittedBlock
+		s.isEmpty = false
+	}
+	return s, nil
+
+}
+
+// Close closes the store
+func (p *provider) Close() {
+	p.missingKeysIndexProvider.Close()
+}
+
+//////// store functions  ////////////////
+//////////////////////////////////////////
+
+func (s *store) initState() error {
+	var blist lastUpdatedOldBlocksList
+	lastCommittedBlock, _, err := lookupLastBlock(s.db)
+	if err != nil {
+		return err
+	}
+	s.isEmpty = true
+	if lastCommittedBlock != 0 {
+		s.lastCommittedBlock = lastCommittedBlock
+		s.isEmpty = false
+	}
+
+	if s.pendingPvtData, err = s.hasPendingCommit(); err != nil {
+		return err
+	}
+
+	if blist, err = common.GetLastUpdatedOldBlocksList(s.missingKeysIndexDB); err != nil {
+		return err
+	}
+	if len(blist) > 0 {
+		s.isLastUpdatedOldBlocksSet = true
+	} // false if not set
+
+	return nil
+}
+
+func (s *store) Init(btlPolicy pvtdatapolicy.BTLPolicy) {
+	s.btlPolicy = btlPolicy
+}
+
+// Prepare implements the function in the interface `Store`
+func (s *store) Prepare(blockNum uint64, pvtData []*ledger.TxPvtData, missingPvtData ledger.TxMissingPvtDataMap) error {
+	if !roles.IsCommitter() {
+		panic("calling Prepare on a peer that is not a committer")
+	}
+
+	if s.pendingPvtData.BatchPending {
+		return pvtdatastorage.NewErrIllegalCall(`A pending batch exists as as result of last invoke to "Prepare" call. Invoke "Commit" or "Rollback" on the pending batch before invoking "Prepare" function`)
+	}
+
+	expectedBlockNum := s.nextBlockNum()
+	if expectedBlockNum != blockNum {
+		return pvtdatastorage.NewErrIllegalCall(fmt.Sprintf("Expected block number=%d, received block number=%d", expectedBlockNum, blockNum))
+	}
+
+	storeEntries, err := common.PrepareStoreEntries(blockNum, pvtData, s.btlPolicy, missingPvtData)
+	if err != nil {
+		return err
+	}
+
+	pvtDataDoc, err := createPvtDataCouchDoc(storeEntries, blockNum, "")
+	if err != nil {
+		return err
+	}
+
+	s.pendingPvtData = &pendingPvtData{BatchPending: true}
+	if pvtDataDoc != nil || len(storeEntries.MissingDataEntries) > 0 {
+		s.pendingPvtData.MissingDataEntries, err = s.perparePendingMissingDataEntries(storeEntries.MissingDataEntries)
+		if err != nil {
+			return err
+		}
+		s.pendingPvtData.PvtDataDoc = pvtDataDoc
+		if err := s.savePendingKey(); err != nil {
+			return err
+		}
+
+	}
+	logger.Debugf("Saved %d private data write sets for block [%d]", len(pvtData), blockNum)
+	return nil
+}
+
+// Commit implements the function in the interface `Store`
+func (s *store) Commit() error {
+	if !roles.IsCommitter() {
+		panic("calling Commit on a peer that is not a committer")
+	}
+
+	if !s.pendingPvtData.BatchPending {
+		return pvtdatastorage.NewErrIllegalCall("No pending batch to commit")
+	}
+
+	committingBlockNum := s.nextBlockNum()
+	logger.Debugf("Committing private data for block [%d]", committingBlockNum)
+
+	var docs []*couchdb.CouchDoc
+	if s.pendingPvtData.PvtDataDoc != nil {
+		docs = append(docs, s.pendingPvtData.PvtDataDoc)
+	}
+
+	lastCommittedBlockDoc, err := s.prepareLastCommittedBlockDoc(committingBlockNum)
+	if err != nil {
+		return err
+	}
+	docs = append(docs, lastCommittedBlockDoc)
+
+	_, err = s.db.BatchUpdateDocuments(docs)
+	if err != nil {
+		return errors.WithMessage(err, fmt.Sprintf("writing private data to CouchDB failed [%d]", committingBlockNum))
+	}
+
+	batch := leveldbhelper.NewUpdateBatch()
+	if len(s.pendingPvtData.MissingDataEntries) > 0 {
+		for missingDataKey, missingDataValue := range s.pendingPvtData.MissingDataEntries {
+			batch.Put([]byte(missingDataKey), []byte(missingDataValue))
+		}
+		if err := s.missingKeysIndexDB.WriteBatch(batch, true); err != nil {
+			return err
+		}
+	}
+
+	batch.Delete(common.PendingCommitKey)
+	if err := s.missingKeysIndexDB.WriteBatch(batch, true); err != nil {
+		return err
+	}
+
+	s.pendingPvtData = &pendingPvtData{BatchPending: false}
+	s.isEmpty = false
+	s.lastCommittedBlock = committingBlockNum
+
+	logger.Debugf("Committed private data for block [%d]", committingBlockNum)
+	s.performPurgeIfScheduled(committingBlockNum)
+	return nil
+}
+
+func (s *store) prepareLastCommittedBlockDoc(committingBlockNum uint64) (*couchdb.CouchDoc, error) {
+	_, rev, err := lookupLastBlock(s.db)
+	if err != nil {
+		return nil, err
+	}
+	lastCommittedBlockDoc, err := createLastCommittedBlockDoc(committingBlockNum, rev)
+	if err != nil {
+		return nil, err
+	}
+	return lastCommittedBlockDoc, nil
+}
+
+// Rollback implements the function in the interface `Store`
+func (s *store) Rollback() error {
+	if !roles.IsCommitter() {
+		panic("calling Rollback on a peer that is not a committer")
+	}
+
+	if !s.pendingPvtData.BatchPending {
+		return pvtdatastorage.NewErrIllegalCall("No pending batch to rollback")
+	}
+
+	s.pendingPvtData = &pendingPvtData{BatchPending: false}
+	if err := s.missingKeysIndexDB.Delete(common.PendingCommitKey, true); err != nil {
+		return err
+	}
+	return nil
+}
+
+// CommitPvtDataOfOldBlocks commits the pvtData (i.e., previously missing data) of old blocks.
+// The parameter `blocksPvtData` refers a list of old block's pvtdata which are missing in the pvtstore.
+// Given a list of old block's pvtData, `CommitPvtDataOfOldBlocks` performs the following four
+// operations
+// (1) construct dataEntries for all pvtData
+// (2) construct update entries (i.e., dataEntries, expiryEntries, missingDataEntries, and
+//     lastUpdatedOldBlocksList) from the above created data entries
+// (3) create a db update batch from the update entries
+// (4) commit the update entries to the pvtStore
+func (s *store) CommitPvtDataOfOldBlocks(blocksPvtData map[uint64][]*ledger.TxPvtData) error {
+	if s.isLastUpdatedOldBlocksSet {
+		return pvtdatastorage.NewErrIllegalCall(`The lastUpdatedOldBlocksList is set. It means that the
+		stateDB may not be in sync with the pvtStore`)
+	}
+
+	batch := leveldbhelper.NewUpdateBatch()
+	docs := make([]*couchdb.CouchDoc, 0)
+	// create a list of blocks' pvtData which are being stored. If this list is
+	// found during the recovery, the stateDB may not be in sync with the pvtData
+	// and needs recovery. In a normal flow, once the stateDB is synced, the
+	// block list would be deleted.
+	updatedBlksListMap := make(map[uint64]bool)
+	// (1) construct dataEntries for all pvtData
+	entries := common.ConstructDataEntriesFromBlocksPvtData(blocksPvtData)
+
+	for blockNum, value := range entries {
+		// (2) construct update entries (i.e., dataEntries, expiryEntries, missingDataEntries) from the above created data entries
+		logger.Debugf("Constructing pvtdatastore entries for pvtData of [%d] old blocks", len(blocksPvtData))
+		updateEntries, err := common.ConstructUpdateEntriesFromDataEntries(value, s.btlPolicy, s.getExpiryDataOfExpiryKey, s.getBitmapOfMissingDataKey)
+		if err != nil {
+			return err
+		}
+		// (3) create a db update batch from the update entries
+		logger.Debug("Constructing update batch from pvtdatastore entries")
+		batch, err = common.ConstructUpdateBatchFromUpdateEntries(updateEntries, batch)
+		if err != nil {
+			return err
+		}
+		pvtDataDoc, err := s.preparePvtDataDoc(blockNum, updateEntries)
+		if err != nil {
+			return err
+		}
+		if pvtDataDoc != nil {
+			docs = append(docs, pvtDataDoc)
+		}
+		updatedBlksListMap[blockNum] = true
+	}
+	if err := s.addLastUpdatedOldBlocksList(batch, updatedBlksListMap); err != nil {
+		return err
+	}
+	// (4) commit the update entries to the pvtStore
+	logger.Debug("Committing the update batch to pvtdatastore")
+	if _, err := s.db.BatchUpdateDocuments(docs); err != nil {
+		return err
+	}
+	if err := s.missingKeysIndexDB.WriteBatch(batch, true); err != nil {
+		return err
+	}
+	s.isLastUpdatedOldBlocksSet = true
+
+	return nil
+}
+
+// GetLastUpdatedOldBlocksPvtData implements the function in the interface `Store`
+func (s *store) GetLastUpdatedOldBlocksPvtData() (map[uint64][]*ledger.TxPvtData, error) {
+	if !s.isLastUpdatedOldBlocksSet {
+		return nil, nil
+	}
+
+	updatedBlksList, err := common.GetLastUpdatedOldBlocksList(s.missingKeysIndexDB)
+	if err != nil {
+		return nil, err
+	}
+
+	blksPvtData := make(map[uint64][]*ledger.TxPvtData)
+	for _, blkNum := range updatedBlksList {
+		if blksPvtData[blkNum], err = s.GetPvtDataByBlockNum(blkNum, nil); err != nil {
+			return nil, err
+		}
+	}
+	return blksPvtData, nil
+}
+
+// ResetLastUpdatedOldBlocksList implements the function in the interface `Store`
+func (s *store) ResetLastUpdatedOldBlocksList() error {
+	if err := common.ResetLastUpdatedOldBlocksList(s.missingKeysIndexDB); err != nil {
+		return err
+	}
+	s.isLastUpdatedOldBlocksSet = false
+	return nil
+}
+
+// GetPvtDataByBlockNum implements the function in the interface `Store`.
+// If the store is empty or the last committed block number is smaller then the
+// requested block number, an 'ErrOutOfRange' is thrown
+func (s *store) GetPvtDataByBlockNum(blockNum uint64, filter ledger.PvtNsCollFilter) ([]*ledger.TxPvtData, error) {
+	logger.Debugf("Get private data for block [%d], filter=%#v", blockNum, filter)
+
+	if err := s.checkLastCommittedBlock(blockNum); err != nil {
+		return nil, err
+	}
+
+	blockPvtDataResponse, err := retrieveBlockPvtData(s.db, blockNumberToKey(blockNum))
+	if err != nil {
+		_, ok := err.(*NotFoundInIndexErr)
+		if ok {
+			return nil, nil
+		}
+		return nil, err
+	}
+
+	var sortedKeys []string
+	for key := range blockPvtDataResponse.Data {
+		sortedKeys = append(sortedKeys, key)
+	}
+	sort.Strings(sortedKeys)
+
+	return s.getBlockPvtData(blockPvtDataResponse.Data, filter, blockNum, sortedKeys)
+
+}
+
+func (s *store) checkLastCommittedBlock(blockNum uint64) error {
+	if roles.IsCommitter() {
+		if s.isEmpty {
+			return pvtdatastorage.NewErrOutOfRange("The store is empty")
+		}
+		if blockNum > s.lastCommittedBlock {
+			return pvtdatastorage.NewErrOutOfRange(fmt.Sprintf("Last committed block=%d, block requested=%d", s.lastCommittedBlock, blockNum))
+		}
+	} else {
+		lastCommittedBlock, _, err := lookupLastBlock(s.db)
+		if err != nil {
+			return err
+		}
+		if lastCommittedBlock == 0 {
+			return pvtdatastorage.NewErrOutOfRange("The store is empty")
+		}
+		if blockNum > lastCommittedBlock {
+			return pvtdatastorage.NewErrOutOfRange(fmt.Sprintf("Last committed block=%d, block requested=%d", s.lastCommittedBlock, blockNum))
+		}
+	}
+	return nil
+}
+
+// ProcessCollsEligibilityEnabled implements the function in the interface `Store`
+func (s *store) ProcessCollsEligibilityEnabled(committingBlk uint64, nsCollMap map[string][]string) error {
+	return common.ProcessCollsEligibilityEnabled(committingBlk, nsCollMap, s.collElgProc, s.missingKeysIndexDB)
+}
+
+// LastCommittedBlockHeight implements the function in the interface `Store`
+func (s *store) LastCommittedBlockHeight() (uint64, error) {
+	if s.isEmpty {
+		return 0, nil
+	}
+	return s.lastCommittedBlock + 1, nil
+}
+
+// HasPendingBatch implements the function in the interface `Store`
+func (s *store) HasPendingBatch() (bool, error) {
+	return s.pendingPvtData.BatchPending, nil
+}
+
+// IsEmpty implements the function in the interface `Store`
+func (s *store) IsEmpty() (bool, error) {
+	return s.isEmpty, nil
+}
+
+// Shutdown implements the function in the interface `Store`
+func (s *store) Shutdown() {
+	// do nothing
+}
+
+func (s *store) preparePvtDataDoc(blockNum uint64, updateEntries *common.EntriesForPvtDataOfOldBlocks) (*couchdb.CouchDoc, error) {
+	dataEntries, expiryEntries, rev, err := s.retrieveBlockPvtEntries(blockNum)
+	if err != nil {
+		return nil, err
+	}
+	pvtDataDoc, err := createPvtDataCouchDoc(s.prepareStoreEntries(updateEntries, dataEntries, expiryEntries), blockNum, rev)
+	if err != nil {
+		return nil, err
+	}
+	return pvtDataDoc, nil
+}
+
+func (s *store) retrieveBlockPvtEntries(blockNum uint64) ([]*common.DataEntry, []*common.ExpiryEntry, string, error) {
+	rev := ""
+	var dataEntries []*common.DataEntry
+	var expiryEntries []*common.ExpiryEntry
+	blockPvtDataResponse, err := retrieveBlockPvtData(s.db, blockNumberToKey(blockNum))
+	if err != nil {
+		_, ok := err.(*NotFoundInIndexErr)
+		if ok {
+			return nil, nil, "", nil
+		}
+		return nil, nil, "", err
+	}
+
+	if blockPvtDataResponse != nil {
+		rev = blockPvtDataResponse.Rev
+		for key := range blockPvtDataResponse.Data {
+			dataKeyBytes, errDecodeString := hex.DecodeString(key)
+			if errDecodeString != nil {
+				return nil, nil, "", errDecodeString
+			}
+			dataKey := common.DecodeDatakey(dataKeyBytes)
+			dataValue, err := common.DecodeDataValue(blockPvtDataResponse.Data[key])
+			if err != nil {
+				return nil, nil, "", err
+			}
+			dataEntries = append(dataEntries, &common.DataEntry{Key: dataKey, Value: dataValue})
+		}
+		for key := range blockPvtDataResponse.Expiry {
+			expiryKeyBytes, err := hex.DecodeString(key)
+			if err != nil {
+				return nil, nil, "", err
+			}
+			expiryKey := common.DecodeExpiryKey(expiryKeyBytes)
+			expiryValue, err := common.DecodeExpiryValue(blockPvtDataResponse.Expiry[key])
+			if err != nil {
+				return nil, nil, "", err
+			}
+			expiryEntries = append(expiryEntries, &common.ExpiryEntry{Key: expiryKey, Value: expiryValue})
+		}
+	}
+	return dataEntries, expiryEntries, rev, nil
+}
+
+func (s *store) addLastUpdatedOldBlocksList(batch *leveldbhelper.UpdateBatch, updatedBlksListMap map[uint64]bool) error {
+	var updatedBlksList lastUpdatedOldBlocksList
+	for blkNum := range updatedBlksListMap {
+		updatedBlksList = append(updatedBlksList, blkNum)
+	}
+
+	// better to store as sorted list
+	sort.SliceStable(updatedBlksList, func(i, j int) bool {
+		return updatedBlksList[i] < updatedBlksList[j]
+	})
+
+	buf := proto.NewBuffer(nil)
+	if err := buf.EncodeVarint(uint64(len(updatedBlksList))); err != nil {
+		return err
+	}
+	for _, blkNum := range updatedBlksList {
+		if err := buf.EncodeVarint(blkNum); err != nil {
+			return err
+		}
+	}
+
+	batch.Put(common.LastUpdatedOldBlocksKey, buf.Bytes())
+	return nil
+}
+
+func (s *store) getBlockPvtData(results map[string][]byte, filter ledger.PvtNsCollFilter, blockNum uint64, sortedKeys []string) ([]*ledger.TxPvtData, error) {
+	var blockPvtdata []*ledger.TxPvtData
+	var currentTxNum uint64
+	var currentTxWsetAssember *common.TxPvtdataAssembler
+	firstItr := true
+
+	for _, key := range sortedKeys {
+		dataKeyBytes, err := hex.DecodeString(key)
+		if err != nil {
+			return nil, err
+		}
+		if common.V11Format(dataKeyBytes) {
+			return v11RetrievePvtdata(results, filter)
+		}
+		dataValueBytes := results[key]
+		dataKey := common.DecodeDatakey(dataKeyBytes)
+		expired, err := s.checkIsExpired(dataKey, filter, s.lastCommittedBlock)
+		if err != nil {
+			return nil, err
+		}
+		if expired {
+			continue
+		}
+
+		dataValue, err := common.DecodeDataValue(dataValueBytes)
+		if err != nil {
+			return nil, err
+		}
+
+		if firstItr {
+			currentTxNum = dataKey.TxNum
+			currentTxWsetAssember = common.NewTxPvtdataAssembler(blockNum, currentTxNum)
+			firstItr = false
+		}
+
+		if dataKey.TxNum != currentTxNum {
+			blockPvtdata = append(blockPvtdata, currentTxWsetAssember.GetTxPvtdata())
+			currentTxNum = dataKey.TxNum
+			currentTxWsetAssember = common.NewTxPvtdataAssembler(blockNum, currentTxNum)
+		}
+		currentTxWsetAssember.Add(dataKey.Ns, dataValue)
+	}
+	if currentTxWsetAssember != nil {
+		blockPvtdata = append(blockPvtdata, currentTxWsetAssember.GetTxPvtdata())
+	}
+	return blockPvtdata, nil
+}
+
+func (s *store) checkIsExpired(dataKey *common.DataKey, filter ledger.PvtNsCollFilter, lastCommittedBlock uint64) (bool, error) {
+	expired, err := common.IsExpired(dataKey.NsCollBlk, s.btlPolicy, lastCommittedBlock)
+	if err != nil {
+		return false, err
+	}
+	if expired || !common.PassesFilter(dataKey, filter) {
+		return true, nil
+	}
+	return false, nil
+}
+
+// InitLastCommittedBlock implements the function in the interface `Store`
+func (s *store) InitLastCommittedBlock(blockNum uint64) error {
+	if !(s.isEmpty && !s.pendingPvtData.BatchPending) {
+		return pvtdatastorage.NewErrIllegalCall("The private data store is not empty. InitLastCommittedBlock() function call is not allowed")
+	}
+	s.isEmpty = false
+	s.lastCommittedBlock = blockNum
+
+	_, rev, err := lookupLastBlock(s.db)
+	if err != nil {
+		return err
+	}
+	lastCommittedBlockDoc, err := createLastCommittedBlockDoc(s.lastCommittedBlock, rev)
+	if err != nil {
+		return err
+	}
+	_, err = s.db.BatchUpdateDocuments([]*couchdb.CouchDoc{lastCommittedBlockDoc})
+	if err != nil {
+		return err
+	}
+
+	logger.Debugf("InitLastCommittedBlock set to block [%d]", blockNum)
+	return nil
+}
+
+//GetMissingPvtDataInfoForMostRecentBlocks implements the function in the interface `Store`
+func (s *store) GetMissingPvtDataInfoForMostRecentBlocks(maxBlock int) (ledger.MissingPvtDataInfo, error) {
+	return common.GetMissingPvtDataInfoForMostRecentBlocks(maxBlock, s.lastCommittedBlock, s.btlPolicy, s.missingKeysIndexDB)
+}
+
+func v11RetrievePvtdata(pvtDataResults map[string][]byte, filter ledger.PvtNsCollFilter) ([]*ledger.TxPvtData, error) {
+	var blkPvtData []*ledger.TxPvtData
+	for key, val := range pvtDataResults {
+		pvtDatum, err := common.V11DecodeKV([]byte(key), val, filter)
+		if err != nil {
+			return nil, err
+		}
+		blkPvtData = append(blkPvtData, pvtDatum)
+	}
+	return blkPvtData, nil
+}
+
+func (s *store) getExpiryDataOfExpiryKey(expiryKey *common.ExpiryKey) (*common.ExpiryData, error) {
+	var expiryEntriesMap map[string][]byte
+	var err error
+	if expiryEntriesMap, err = s.getExpiryEntriesDB(expiryKey.CommittingBlk); err != nil {
+		return nil, err
+	}
+	v := expiryEntriesMap[hex.EncodeToString(common.EncodeExpiryKey(expiryKey))]
+	if v == nil {
+		return nil, nil
+	}
+	return common.DecodeExpiryValue(v)
+}
+
+func (s *store) getExpiryEntriesDB(blockNum uint64) (map[string][]byte, error) {
+	blockPvtData, err := retrieveBlockPvtData(s.db, blockNumberToKey(blockNum))
+	if err != nil {
+		return nil, err
+	}
+	return blockPvtData.Expiry, nil
+}
+
+func (s *store) getBitmapOfMissingDataKey(missingDataKey *common.MissingDataKey) (*bitset.BitSet, error) {
+	var v []byte
+	var err error
+	if v, err = s.missingKeysIndexDB.Get(common.EncodeMissingDataKey(missingDataKey)); err != nil {
+		return nil, err
+	}
+	if v == nil {
+		return nil, nil
+	}
+	return common.DecodeMissingDataValue(v)
+}
+
+func (s *store) prepareStoreEntries(updateEntries *common.EntriesForPvtDataOfOldBlocks, dataEntries []*common.DataEntry, expiryEntries []*common.ExpiryEntry) *common.StoreEntries {
+	if dataEntries == nil {
+		dataEntries = make([]*common.DataEntry, 0)
+	}
+	if expiryEntries == nil {
+		expiryEntries = make([]*common.ExpiryEntry, 0)
+	}
+	for k, v := range updateEntries.DataEntries {
+		k := k
+		dataEntries = append(dataEntries, &common.DataEntry{Key: &k, Value: v})
+	}
+	for k, v := range updateEntries.ExpiryEntries {
+		k := k
+		expiryEntries = append(expiryEntries, &common.ExpiryEntry{Key: &k, Value: v})
+	}
+	return &common.StoreEntries{DataEntries: dataEntries, ExpiryEntries: expiryEntries}
+}
+
+func (s *store) hasPendingCommit() (*pendingPvtData, error) {
+	var v []byte
+	var err error
+	if v, err = s.missingKeysIndexDB.Get(common.PendingCommitKey); err != nil {
+		return nil, err
+	}
+	if v != nil {
+		var pPvtData pendingPvtData
+		if err := json.Unmarshal(v, &pPvtData); err != nil {
+			return nil, err
+		}
+		return &pPvtData, nil
+	}
+	return &pendingPvtData{BatchPending: false}, nil
+
+}
+
+func (s *store) savePendingKey() error {
+	bytes, err := json.Marshal(s.pendingPvtData)
+	if err != nil {
+		return err
+	}
+	if err := s.missingKeysIndexDB.Put(common.PendingCommitKey, bytes, true); err != nil {
+		return err
+	}
+	return nil
+}
+
+func (s *store) perparePendingMissingDataEntries(mssingDataEntries map[common.MissingDataKey]*bitset.BitSet) (map[string]string, error) {
+	pendingMissingDataEntries := make(map[string]string)
+	for missingDataKey, missingDataValue := range mssingDataEntries {
+		missingDataKey := missingDataKey
+		keyBytes := common.EncodeMissingDataKey(&missingDataKey)
+		valBytes, err := common.EncodeMissingDataValue(missingDataValue)
+		if err != nil {
+			return nil, err
+		}
+		pendingMissingDataEntries[string(keyBytes)] = string(valBytes)
+	}
+	return pendingMissingDataEntries, nil
+}
+
+func (s *store) nextBlockNum() uint64 {
+	if s.isEmpty {
+		return 0
+	}
+	return s.lastCommittedBlock + 1
+}
+
+func (s *store) performPurgeIfScheduled(latestCommittedBlk uint64) {
+	if latestCommittedBlk%ledgerconfig.GetPvtdataStorePurgeInterval() != 0 {
+		return
+	}
+	go func() {
+		s.purgerLock.Lock()
+		logger.Debugf("Purger started: Purging expired private data till block number [%d]", latestCommittedBlk)
+		defer s.purgerLock.Unlock()
+		err := s.purgeExpiredData(latestCommittedBlk)
+		if err != nil {
+			logger.Warningf("Could not purge data from pvtdata store:%s", err)
+		}
+		logger.Debug("Purger finished")
+	}()
+}
+
+func (s *store) purgeExpiredData(maxBlkNum uint64) error {
+	pvtData, err := retrieveBlockExpiryData(s.db, blockNumberToKey(maxBlkNum))
+	if err != nil {
+		return err
+	}
+	if len(pvtData) == 0 {
+		return nil
+	}
+
+	docs, batch, err := s.prepareExpiredData(pvtData, maxBlkNum)
+	if err != nil {
+		return err
+	}
+	if len(docs) > 0 {
+		_, err := s.db.BatchUpdateDocuments(docs)
+		if err != nil {
+			return errors.WithMessage(err, fmt.Sprintf("BatchUpdateDocuments failed for [%d] documents", len(docs)))
+		}
+	}
+	if err := s.missingKeysIndexDB.WriteBatch(batch, false); err != nil {
+		return err
+	}
+
+	logger.Infof("[%s] - Entries purged from private data storage till block number [%d]", s.ledgerid, maxBlkNum)
+	return nil
+}
+
+func (s *store) prepareExpiredData(pvtData []*blockPvtDataResponse, maxBlkNum uint64) ([]*couchdb.CouchDoc, *leveldbhelper.UpdateBatch, error) {
+	batch := leveldbhelper.NewUpdateBatch()
+	var docs []*couchdb.CouchDoc
+	for _, data := range pvtData {
+		expBlkNums := make([]string, 0)
+		for key, value := range data.Expiry {
+			expiryKeyBytes, err := hex.DecodeString(key)
+			if err != nil {
+				return nil, nil, err
+			}
+			expiryKey := common.DecodeExpiryKey(expiryKeyBytes)
+			if expiryKey.ExpiringBlk <= maxBlkNum {
+				expiryValue, err := common.DecodeExpiryValue(value)
+				if err != nil {
+					return nil, nil, err
+				}
+				dataKeys, missingDataKeys := common.DeriveKeys(&common.ExpiryEntry{Key: expiryKey, Value: expiryValue})
+				for _, dataKey := range dataKeys {
+					delete(data.Data, hex.EncodeToString(common.EncodeDataKey(dataKey)))
+				}
+				for _, missingDataKey := range missingDataKeys {
+					batch.Delete(common.EncodeMissingDataKey(missingDataKey))
+				}
+			} else {
+				expBlkNums = append(expBlkNums, blockNumberToKey(expiryKey.ExpiringBlk))
+			}
+		}
+		if len(data.Data) == 0 {
+			data.Deleted = true
+		}
+		data.ExpiringBlkNums = expBlkNums
+		jsonBytes, err := json.Marshal(data)
+		if err != nil {
+			return nil, nil, err
+		}
+		docs = append(docs, &couchdb.CouchDoc{JSONValue: jsonBytes})
+	}
+
+	return docs, batch, nil
+
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/test_exports.go
new file mode 100644
index 00000000..f7c230a9
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/test_exports.go
@@ -0,0 +1,77 @@
+/*
+Copyright IBM Corp, SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatastorage
+
+import (
+	"os"
+	"testing"
+
+	"github.com/hyperledger/fabric/common/metrics/disabled"
+	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/stretchr/testify/require"
+)
+
+// StoreEnv provides the  store env for testing
+type StoreEnv struct {
+	t                 testing.TB
+	TestStoreProvider pvtdatastorage.Provider
+	TestStore         pvtdatastorage.Store
+	ledgerid          string
+	btlPolicy         pvtdatapolicy.BTLPolicy
+	couchDBDef        *couchdb.CouchDBDef
+}
+
+// NewTestStoreEnv construct a StoreEnv for testing
+func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLPolicy, couchDBDef *couchdb.CouchDBDef) *StoreEnv {
+	removeStorePath()
+	req := require.New(t)
+	testStoreProvider, err := NewProvider()
+	req.NoError(err)
+	testStore, err := testStoreProvider.OpenStore(ledgerid)
+	req.NoError(err)
+	testStore.Init(btlPolicy)
+	s := &StoreEnv{t, testStoreProvider, testStore, ledgerid, btlPolicy, couchDBDef}
+	return s
+}
+
+// CloseAndReopen closes and opens the store provider
+func (env *StoreEnv) CloseAndReopen() {
+	var err error
+	env.TestStoreProvider.Close()
+	env.TestStoreProvider, err = NewProvider()
+	require.NoError(env.t, err)
+	env.TestStore, err = env.TestStoreProvider.OpenStore(env.ledgerid)
+	env.TestStore.Init(env.btlPolicy)
+	require.NoError(env.t, err)
+}
+
+//Cleanup env test
+func (env *StoreEnv) Cleanup(ledgerid string) {
+	//create a new connection
+	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBDef.URL, env.couchDBDef.Username, env.couchDBDef.Password,
+		env.couchDBDef.MaxRetries, env.couchDBDef.MaxRetriesOnStartup, env.couchDBDef.RequestTimeout, env.couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	if err != nil {
+		panic(err.Error())
+	}
+	pvtDataStoreDBName := couchdb.ConstructBlockchainDBName(ledgerid, pvtDataStoreName)
+	db := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: pvtDataStoreDBName}
+	//drop the test database
+	if _, err := db.DropDatabase(); err != nil {
+		panic(err.Error())
+	}
+	removeStorePath()
+}
+
+func removeStorePath() {
+	dbPath := ledgerconfig.GetPvtdataStorePath()
+	if err := os.RemoveAll(dbPath); err != nil {
+		panic(err.Error())
+	}
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/collelgproc.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/collelgproc.go
new file mode 100644
index 00000000..2c69b75c
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/collelgproc.go
@@ -0,0 +1,139 @@
+/*
+Copyright IBM Corp. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package common
+
+import (
+	"sync"
+	"time"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/common/ledger/util/leveldbhelper"
+	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
+)
+
+// todo add pinning script to include copied code into this file, original file from fabric is found in fabric/core/ledger/pvtdatastorage/store_imp.go
+// todo below functions are originally unexported, the pinning script must capitalize these functions to export them
+
+var logger = flogging.MustGetLogger("collelgproc")
+
+type CollElgProc struct {
+	notification, procComplete chan bool
+	purgerLock                 *sync.Mutex
+	db                         *leveldbhelper.DBHandle
+}
+
+func NewCollElgProc(purgerLock *sync.Mutex, missingKeysIndexDB *leveldbhelper.DBHandle) *CollElgProc {
+
+	return &CollElgProc{
+		notification: make(chan bool, 1),
+		procComplete: make(chan bool, 1),
+		purgerLock:   purgerLock,
+		db:           missingKeysIndexDB,
+	}
+}
+
+func (c *CollElgProc) notify() {
+	select {
+	case c.notification <- true:
+		logger.Debugf("Signaled to collection eligibility processing routine")
+	default: //noop
+		logger.Debugf("Previous signal still pending. Skipping new signal")
+	}
+}
+
+func (c *CollElgProc) waitForNotification() {
+	<-c.notification
+}
+
+func (c *CollElgProc) done() {
+	select {
+	case c.procComplete <- true:
+	default:
+	}
+}
+
+func (c *CollElgProc) WaitForDone() {
+	<-c.procComplete
+}
+
+func (c *CollElgProc) LaunchCollElgProc() {
+	maxBatchSize := ledgerconfig.GetPvtdataStoreCollElgProcMaxDbBatchSize()
+	batchesInterval := ledgerconfig.GetPvtdataStoreCollElgProcDbBatchesInterval()
+	go func() {
+		c.processCollElgEvents(maxBatchSize, batchesInterval) // process collection eligibility events when store is opened - in case there is an unprocessed events from previous run
+		for {
+			logger.Debugf("Waiting for collection eligibility event")
+			c.waitForNotification()
+			c.processCollElgEvents(maxBatchSize, batchesInterval)
+			c.done()
+		}
+	}()
+}
+
+func (c *CollElgProc) processCollElgEvents(maxBatchSize, batchesInterval int) {
+	logger.Debugf("Starting to process collection eligibility events")
+	c.purgerLock.Lock()
+	defer c.purgerLock.Unlock()
+	collElgStartKey, collElgEndKey := createRangeScanKeysForCollElg()
+	eventItr := c.db.GetIterator(collElgStartKey, collElgEndKey)
+	defer eventItr.Release()
+	batch := leveldbhelper.NewUpdateBatch()
+	totalEntriesConverted := 0
+
+	for eventItr.Next() {
+		collElgKey, collElgVal := eventItr.Key(), eventItr.Value()
+		blkNum := decodeCollElgKey(collElgKey)
+		CollElgInfo, err := decodeCollElgVal(collElgVal)
+		logger.Debugf("Processing collection eligibility event [blkNum=%d], CollElgInfo=%s", blkNum, CollElgInfo)
+		if err != nil {
+			logger.Errorf("This error is not expected %s", err)
+			continue
+		}
+		for ns, colls := range CollElgInfo.NsCollMap {
+			var coll string
+			for _, coll = range colls.Entries {
+				logger.Infof("Converting missing data entries from ineligible to eligible for [ns=%s, coll=%s]", ns, coll)
+				startKey, endKey := createRangeScanKeysForIneligibleMissingData(blkNum, ns, coll)
+				collItr := c.db.GetIterator(startKey, endKey)
+				collEntriesConverted := 0
+
+				for collItr.Next() { // each entry
+					originalKey, originalVal := collItr.Key(), collItr.Value()
+					modifiedKey := decodeMissingDataKey(originalKey)
+					modifiedKey.IsEligible = true
+					batch.Delete(originalKey)
+					copyVal := make([]byte, len(originalVal))
+					copy(copyVal, originalVal)
+					batch.Put(EncodeMissingDataKey(modifiedKey), copyVal)
+					collEntriesConverted++
+					if batch.Len() > maxBatchSize {
+						if err := c.db.WriteBatch(batch, true); err != nil {
+							logger.Error(err.Error())
+						}
+						batch = leveldbhelper.NewUpdateBatch()
+						sleepTime := time.Duration(batchesInterval)
+						logger.Infof("Going to sleep for %d milliseconds between batches. Entries for [ns=%s, coll=%s] converted so far = %d",
+							sleepTime, ns, coll, collEntriesConverted)
+						c.purgerLock.Unlock()
+						time.Sleep(sleepTime * time.Millisecond)
+						c.purgerLock.Lock()
+					}
+				} // entry loop
+
+				collItr.Release()
+				logger.Infof("Converted all [%d] entries for [ns=%s, coll=%s]", collEntriesConverted, ns, coll)
+				totalEntriesConverted += collEntriesConverted
+			} // coll loop
+		} // ns loop
+		batch.Delete(collElgKey) // delete the collection eligibility event key as well
+	} // event loop
+
+	if err := c.db.WriteBatch(batch, true); err != nil {
+		logger.Error(err.Error())
+	}
+	logger.Debugf("Converted [%d] inelligible mising data entries to elligible", totalEntriesConverted)
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/helper.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/helper.go
new file mode 100644
index 00000000..43ff6972
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/helper.go
@@ -0,0 +1,235 @@
+/*
+Copyright IBM Corp. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package common
+
+import (
+	"math"
+
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/willf/bitset"
+)
+
+// todo add pinning script to include copied code into this file, original file from fabric is found in fabric/core/ledger/pvtdatastorage/helper.go
+// todo below functions are originally unexported, the pinning script must capitalize these functions to export them
+
+func PrepareStoreEntries(blockNum uint64, pvtData []*ledger.TxPvtData, btlPolicy pvtdatapolicy.BTLPolicy,
+	missingPvtData ledger.TxMissingPvtDataMap) (*StoreEntries, error) {
+	dataEntries := prepareDataEntries(blockNum, pvtData)
+
+	missingDataEntries := prepareMissingDataEntries(blockNum, missingPvtData)
+
+	expiryEntries, err := prepareExpiryEntries(blockNum, dataEntries, missingDataEntries, btlPolicy)
+	if err != nil {
+		return nil, err
+	}
+
+	return &StoreEntries{
+		DataEntries:        dataEntries,
+		ExpiryEntries:      expiryEntries,
+		MissingDataEntries: missingDataEntries}, nil
+}
+
+func prepareDataEntries(blockNum uint64, pvtData []*ledger.TxPvtData) []*DataEntry {
+	var dataEntries []*DataEntry
+	for _, txPvtdata := range pvtData {
+		for _, nsPvtdata := range txPvtdata.WriteSet.NsPvtRwset {
+			for _, collPvtdata := range nsPvtdata.CollectionPvtRwset {
+				txnum := txPvtdata.SeqInBlock
+				ns := nsPvtdata.Namespace
+				coll := collPvtdata.CollectionName
+				dataKey := &DataKey{NsCollBlk: NsCollBlk{Ns: ns, Coll: coll, BlkNum: blockNum}, TxNum: txnum}
+				dataEntries = append(dataEntries, &DataEntry{Key: dataKey, Value: collPvtdata})
+			}
+		}
+	}
+	return dataEntries
+}
+
+func prepareMissingDataEntries(committingBlk uint64, missingPvtData ledger.TxMissingPvtDataMap) map[MissingDataKey]*bitset.BitSet {
+	missingDataEntries := make(map[MissingDataKey]*bitset.BitSet)
+
+	for txNum, missingData := range missingPvtData {
+		for _, nsColl := range missingData {
+			key := MissingDataKey{NsCollBlk: NsCollBlk{Ns: nsColl.Namespace, Coll: nsColl.Collection, BlkNum: committingBlk},
+				IsEligible: nsColl.IsEligible}
+
+			if _, ok := missingDataEntries[key]; !ok {
+				missingDataEntries[key] = &bitset.BitSet{}
+			}
+			bitmap := missingDataEntries[key]
+
+			bitmap.Set(uint(txNum))
+		}
+	}
+
+	return missingDataEntries
+}
+
+// prepareExpiryEntries returns expiry entries for both private data which is present in the committingBlk
+// and missing private.
+func prepareExpiryEntries(committingBlk uint64, dataEntries []*DataEntry, missingDataEntries map[MissingDataKey]*bitset.BitSet,
+	btlPolicy pvtdatapolicy.BTLPolicy) ([]*ExpiryEntry, error) {
+
+	var expiryEntries []*ExpiryEntry
+	mapByExpiringBlk := make(map[uint64]*ExpiryData)
+
+	// 1. prepare expiryData for non-missing data
+	for _, dataEntry := range dataEntries {
+		prepareExpiryEntriesForPresentData(mapByExpiringBlk, dataEntry.Key, btlPolicy)
+
+	}
+
+	// 2. prepare expiryData for missing data
+	for missingDataKey := range missingDataEntries {
+		prepareExpiryEntriesForMissingData(mapByExpiringBlk, &missingDataKey, btlPolicy)
+
+	}
+
+	for expiryBlk, expiryData := range mapByExpiringBlk {
+		expiryKey := &ExpiryKey{ExpiringBlk: expiryBlk, CommittingBlk: committingBlk}
+		expiryEntries = append(expiryEntries, &ExpiryEntry{Key: expiryKey, Value: expiryData})
+	}
+
+	return expiryEntries, nil
+}
+
+// prepareExpiryDataForPresentData creates expiryData for non-missing pvt data
+func prepareExpiryEntriesForPresentData(mapByExpiringBlk map[uint64]*ExpiryData, dataKey *DataKey, btlPolicy pvtdatapolicy.BTLPolicy) error {
+	expiringBlk, err := btlPolicy.GetExpiringBlock(dataKey.Ns, dataKey.Coll, dataKey.BlkNum)
+	if err != nil {
+		return err
+	}
+	if neverExpires(expiringBlk) {
+		return nil
+	}
+
+	expiryData := getOrCreateExpiryData(mapByExpiringBlk, expiringBlk)
+
+	expiryData.AddPresentData(dataKey.Ns, dataKey.Coll, dataKey.TxNum)
+	return nil
+}
+
+// prepareExpiryDataForMissingData creates expiryData for missing pvt data
+func prepareExpiryEntriesForMissingData(mapByExpiringBlk map[uint64]*ExpiryData, missingKey *MissingDataKey, btlPolicy pvtdatapolicy.BTLPolicy) error {
+	expiringBlk, err := btlPolicy.GetExpiringBlock(missingKey.Ns, missingKey.Coll, missingKey.BlkNum)
+	if err != nil {
+		return err
+	}
+	if neverExpires(expiringBlk) {
+		return nil
+	}
+
+	expiryData := getOrCreateExpiryData(mapByExpiringBlk, expiringBlk)
+
+	expiryData.AddMissingData(missingKey.Ns, missingKey.Coll)
+	return nil
+}
+
+func getOrCreateExpiryData(mapByExpiringBlk map[uint64]*ExpiryData, expiringBlk uint64) *ExpiryData {
+	expiryData, ok := mapByExpiringBlk[expiringBlk]
+	if !ok {
+		expiryData = NewExpiryData()
+		mapByExpiringBlk[expiringBlk] = expiryData
+	}
+	return expiryData
+}
+
+func PassesFilter(dataKey *DataKey, filter ledger.PvtNsCollFilter) bool {
+	return filter == nil || filter.Has(dataKey.Ns, dataKey.Coll)
+}
+
+func IsExpired(key NsCollBlk, btl pvtdatapolicy.BTLPolicy, latestBlkNum uint64) (bool, error) {
+	expiringBlk, err := btl.GetExpiringBlock(key.Ns, key.Coll, key.BlkNum)
+	if err != nil {
+		return false, err
+	}
+
+	return latestBlkNum >= expiringBlk, nil
+}
+
+// DeriveKeys constructs dataKeys and missingDataKey from an expiryEntry
+func DeriveKeys(expiryEntry *ExpiryEntry) (dataKeys []*DataKey, missingDataKeys []*MissingDataKey) {
+	for ns, colls := range expiryEntry.Value.Map {
+		// 1. constructs dataKeys of expired existing pvt data
+		for coll, txNums := range colls.Map {
+			for _, txNum := range txNums.List {
+				dataKeys = append(dataKeys,
+					&DataKey{NsCollBlk{ns, coll, expiryEntry.Key.CommittingBlk}, txNum})
+			}
+		}
+		// 2. constructs missingDataKeys of expired missing pvt data
+		for coll := range colls.MissingDataMap {
+			// one key for eligible entries and another for ieligible entries
+			missingDataKeys = append(missingDataKeys,
+				&MissingDataKey{NsCollBlk{ns, coll, expiryEntry.Key.CommittingBlk}, true})
+			missingDataKeys = append(missingDataKeys,
+				&MissingDataKey{NsCollBlk{ns, coll, expiryEntry.Key.CommittingBlk}, false})
+
+		}
+	}
+	return
+}
+
+func newCollElgInfo(nsCollMap map[string][]string) *pvtdatastorage.CollElgInfo {
+	m := &pvtdatastorage.CollElgInfo{NsCollMap: map[string]*pvtdatastorage.CollNames{}}
+	for ns, colls := range nsCollMap {
+		collNames, ok := m.NsCollMap[ns]
+		if !ok {
+			collNames = &pvtdatastorage.CollNames{}
+			m.NsCollMap[ns] = collNames
+		}
+		collNames.Entries = colls
+	}
+	return m
+}
+
+type TxPvtdataAssembler struct {
+	blockNum, txNum uint64
+	txWset          *rwset.TxPvtReadWriteSet
+	currentNsWSet   *rwset.NsPvtReadWriteSet
+	firstCall       bool
+}
+
+func NewTxPvtdataAssembler(blockNum, txNum uint64) *TxPvtdataAssembler {
+	return &TxPvtdataAssembler{blockNum, txNum, &rwset.TxPvtReadWriteSet{}, nil, true}
+}
+
+func (a *TxPvtdataAssembler) Add(ns string, collPvtWset *rwset.CollectionPvtReadWriteSet) {
+	// start a NsWset
+	if a.firstCall {
+		a.currentNsWSet = &rwset.NsPvtReadWriteSet{Namespace: ns}
+		a.firstCall = false
+	}
+
+	// if a new ns started, add the existing NsWset to TxWset and start a new one
+	if a.currentNsWSet.Namespace != ns {
+		a.txWset.NsPvtRwset = append(a.txWset.NsPvtRwset, a.currentNsWSet)
+		a.currentNsWSet = &rwset.NsPvtReadWriteSet{Namespace: ns}
+	}
+	// add the collWset to the current NsWset
+	a.currentNsWSet.CollectionPvtRwset = append(a.currentNsWSet.CollectionPvtRwset, collPvtWset)
+}
+
+func (a *TxPvtdataAssembler) done() {
+	if a.currentNsWSet != nil {
+		a.txWset.NsPvtRwset = append(a.txWset.NsPvtRwset, a.currentNsWSet)
+	}
+	a.currentNsWSet = nil
+}
+
+func (a *TxPvtdataAssembler) GetTxPvtdata() *ledger.TxPvtData {
+	a.done()
+	return &ledger.TxPvtData{SeqInBlock: a.txNum, WriteSet: a.txWset}
+}
+
+func neverExpires(expiringBlkNum uint64) bool {
+	return expiringBlkNum == math.MaxUint64
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/kv_encoding.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/kv_encoding.go
new file mode 100644
index 00000000..db7cfd32
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/kv_encoding.go
@@ -0,0 +1,192 @@
+/*
+Copyright IBM Corp. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package common
+
+import (
+	"bytes"
+	"math"
+
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/version"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	"github.com/hyperledger/fabric/core/ledger/util"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/pkg/errors"
+	"github.com/willf/bitset"
+)
+
+// todo add pinning script to include copied code into this file, original file from fabric is found in fabric/core/ledger/pvtdatastorage/kv_encoding.go
+// todo below functions are originally unexported, the pinning script must capitalize these functions to export them
+
+var (
+	PendingCommitKey               = []byte{0}
+	pvtDataKeyPrefix               = []byte{2}
+	expiryKeyPrefix                = []byte{3}
+	eligibleMissingDataKeyPrefix   = []byte{4}
+	ineligibleMissingDataKeyPrefix = []byte{5}
+	collElgKeyPrefix               = []byte{6}
+	LastUpdatedOldBlocksKey        = []byte{7}
+	lastCommittedBlockKey          = []byte{8}
+	nilByte                        = byte(0)
+)
+
+func EncodeDataKey(key *DataKey) []byte {
+	dataKeyBytes := append(pvtDataKeyPrefix, version.NewHeight(key.BlkNum, key.TxNum).ToBytes()...)
+	dataKeyBytes = append(dataKeyBytes, []byte(key.Ns)...)
+	dataKeyBytes = append(dataKeyBytes, nilByte)
+	return append(dataKeyBytes, []byte(key.Coll)...)
+}
+
+func EncodeDataValue(collData *rwset.CollectionPvtReadWriteSet) ([]byte, error) {
+	return proto.Marshal(collData)
+}
+
+func EncodeExpiryKey(expiryKey *ExpiryKey) []byte {
+	// reusing version encoding scheme here
+	return append(expiryKeyPrefix, version.NewHeight(expiryKey.ExpiringBlk, expiryKey.CommittingBlk).ToBytes()...)
+}
+
+func DecodeExpiryKey(expiryKeyBytes []byte) *ExpiryKey {
+	height, _ := version.NewHeightFromBytes(expiryKeyBytes[1:])
+	return &ExpiryKey{ExpiringBlk: height.BlockNum, CommittingBlk: height.TxNum}
+}
+
+func EncodeExpiryValue(expiryData *ExpiryData) ([]byte, error) {
+	return proto.Marshal(expiryData)
+}
+
+func DecodeExpiryValue(expiryValueBytes []byte) (*ExpiryData, error) {
+	expiryData := &ExpiryData{}
+	err := proto.Unmarshal(expiryValueBytes, expiryData)
+	return expiryData, err
+}
+
+func DecodeDatakey(datakeyBytes []byte) *DataKey {
+	v, n := version.NewHeightFromBytes(datakeyBytes[1:])
+	blkNum := v.BlockNum
+	tranNum := v.TxNum
+	remainingBytes := datakeyBytes[n+1:]
+	nilByteIndex := bytes.IndexByte(remainingBytes, nilByte)
+	ns := string(remainingBytes[:nilByteIndex])
+	coll := string(remainingBytes[nilByteIndex+1:])
+	return &DataKey{NsCollBlk: NsCollBlk{Ns: ns, Coll: coll, BlkNum: blkNum}, TxNum: tranNum}
+}
+
+func DecodeDataValue(datavalueBytes []byte) (*rwset.CollectionPvtReadWriteSet, error) {
+	collPvtdata := &rwset.CollectionPvtReadWriteSet{}
+	err := proto.Unmarshal(datavalueBytes, collPvtdata)
+	return collPvtdata, err
+}
+
+func EncodeMissingDataKey(key *MissingDataKey) []byte {
+	if key.IsEligible {
+		keyBytes := append(eligibleMissingDataKeyPrefix, util.EncodeReverseOrderVarUint64(key.BlkNum)...)
+		keyBytes = append(keyBytes, []byte(key.Ns)...)
+		keyBytes = append(keyBytes, nilByte)
+		return append(keyBytes, []byte(key.Coll)...)
+	}
+
+	keyBytes := append(ineligibleMissingDataKeyPrefix, []byte(key.Ns)...)
+	keyBytes = append(keyBytes, nilByte)
+	keyBytes = append(keyBytes, []byte(key.Coll)...)
+	keyBytes = append(keyBytes, nilByte)
+	return append(keyBytes, []byte(util.EncodeReverseOrderVarUint64(key.BlkNum))...)
+}
+
+func decodeMissingDataKey(keyBytes []byte) *MissingDataKey {
+	key := &MissingDataKey{NsCollBlk: NsCollBlk{}}
+	if keyBytes[0] == eligibleMissingDataKeyPrefix[0] {
+		blkNum, numBytesConsumed := util.DecodeReverseOrderVarUint64(keyBytes[1:])
+
+		splittedKey := bytes.Split(keyBytes[numBytesConsumed+1:], []byte{nilByte})
+		key.Ns = string(splittedKey[0])
+		key.Coll = string(splittedKey[1])
+		key.BlkNum = blkNum
+		key.IsEligible = true
+		return key
+	}
+
+	splittedKey := bytes.SplitN(keyBytes[1:], []byte{nilByte}, 3) //encoded bytes for blknum may contain empty bytes
+	key.Ns = string(splittedKey[0])
+	key.Coll = string(splittedKey[1])
+	key.BlkNum, _ = util.DecodeReverseOrderVarUint64(splittedKey[2])
+	key.IsEligible = false
+	return key
+}
+
+func EncodeMissingDataValue(bitmap *bitset.BitSet) ([]byte, error) {
+	return bitmap.MarshalBinary()
+}
+
+func DecodeMissingDataValue(bitmapBytes []byte) (*bitset.BitSet, error) {
+	bitmap := &bitset.BitSet{}
+	if err := bitmap.UnmarshalBinary(bitmapBytes); err != nil {
+		return nil, err
+	}
+	return bitmap, nil
+}
+
+func encodeCollElgKey(blkNum uint64) []byte {
+	return append(collElgKeyPrefix, util.EncodeReverseOrderVarUint64(blkNum)...)
+}
+
+func decodeCollElgKey(b []byte) uint64 {
+	blkNum, _ := util.DecodeReverseOrderVarUint64(b[1:])
+	return blkNum
+}
+
+func encodeCollElgVal(m *pvtdatastorage.CollElgInfo) ([]byte, error) {
+	return proto.Marshal(m)
+}
+
+func decodeCollElgVal(b []byte) (*pvtdatastorage.CollElgInfo, error) {
+	m := &pvtdatastorage.CollElgInfo{}
+	if err := proto.Unmarshal(b, m); err != nil {
+		return nil, errors.WithStack(err)
+	}
+	return m, nil
+}
+
+func createRangeScanKeysForIneligibleMissingData(maxBlkNum uint64, ns, coll string) (startKey, endKey []byte) {
+	startKey = EncodeMissingDataKey(
+		&MissingDataKey{
+			NsCollBlk:  NsCollBlk{Ns: ns, Coll: coll, BlkNum: maxBlkNum},
+			IsEligible: false,
+		},
+	)
+	endKey = EncodeMissingDataKey(
+		&MissingDataKey{
+			NsCollBlk:  NsCollBlk{Ns: ns, Coll: coll, BlkNum: 0},
+			IsEligible: false,
+		},
+	)
+	return
+}
+
+func createRangeScanKeysForEligibleMissingDataEntries(blkNum uint64) (startKey, endKey []byte) {
+	startKey = append(eligibleMissingDataKeyPrefix, util.EncodeReverseOrderVarUint64(blkNum)...)
+	endKey = append(eligibleMissingDataKeyPrefix, util.EncodeReverseOrderVarUint64(0)...)
+
+	return startKey, endKey
+}
+
+func createRangeScanKeysForCollElg() (startKey, endKey []byte) {
+	return encodeCollElgKey(math.MaxUint64),
+		encodeCollElgKey(0)
+}
+
+func datakeyRange(blockNum uint64) (startKey, endKey []byte) {
+	startKey = append(pvtDataKeyPrefix, version.NewHeight(blockNum, 0).ToBytes()...)
+	endKey = append(pvtDataKeyPrefix, version.NewHeight(blockNum, math.MaxUint64).ToBytes()...)
+	return
+}
+
+func eligibleMissingdatakeyRange(blkNum uint64) (startKey, endKey []byte) {
+	startKey = append(eligibleMissingDataKeyPrefix, util.EncodeReverseOrderVarUint64(blkNum)...)
+	endKey = append(eligibleMissingDataKeyPrefix, util.EncodeReverseOrderVarUint64(blkNum-1)...)
+	return
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/store.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/store.go
new file mode 100644
index 00000000..bbc1433e
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/store.go
@@ -0,0 +1,404 @@
+/*
+Copyright IBM Corp. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package common
+
+import (
+	"sync/atomic"
+
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/common/ledger/util/leveldbhelper"
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	"github.com/willf/bitset"
+)
+
+// todo add pinning script to include copied code into this file, original file from fabric is found in fabric/core/ledger/pvtdatastorage/store_imp.go
+// todo below functions are originally unexported, the pinning script must capitalize these functions to export them
+
+type DataEntry struct {
+	Key   *DataKey
+	Value *rwset.CollectionPvtReadWriteSet
+}
+
+type ExpiryEntry struct {
+	Key   *ExpiryKey
+	Value *ExpiryData
+}
+
+type ExpiryKey struct {
+	ExpiringBlk   uint64
+	CommittingBlk uint64
+}
+
+type NsCollBlk struct {
+	Ns, Coll string
+	BlkNum   uint64
+}
+
+type DataKey struct {
+	NsCollBlk
+	TxNum uint64
+}
+
+type MissingDataKey struct {
+	NsCollBlk
+	IsEligible bool
+}
+
+type StoreEntries struct {
+	DataEntries        []*DataEntry
+	ExpiryEntries      []*ExpiryEntry
+	MissingDataEntries map[MissingDataKey]*bitset.BitSet
+}
+
+type EntriesForPvtDataOfOldBlocks struct {
+	// for each <ns, coll, blkNum, txNum>, store the dataEntry, i.e., pvtData
+	DataEntries map[DataKey]*rwset.CollectionPvtReadWriteSet
+	// store the retrieved (& updated) expiryData in expiryEntries
+	ExpiryEntries map[ExpiryKey]*ExpiryData
+	// for each <ns, coll, blkNum>, store the retrieved (& updated) bitmap in the missingDataEntries
+	MissingDataEntries map[NsCollBlk]*bitset.BitSet
+}
+
+func (updateEntries *EntriesForPvtDataOfOldBlocks) AddDataEntry(dataEntry *DataEntry) {
+	dataKey := DataKey{NsCollBlk: dataEntry.Key.NsCollBlk, TxNum: dataEntry.Key.TxNum}
+	updateEntries.DataEntries[dataKey] = dataEntry.Value
+}
+
+func (updateEntries *EntriesForPvtDataOfOldBlocks) UpdateAndAddExpiryEntry(expiryEntry *ExpiryEntry, dataKey *DataKey) {
+	txNum := dataKey.TxNum
+	nsCollBlk := dataKey.NsCollBlk
+	// update
+	expiryEntry.Value.AddPresentData(nsCollBlk.Ns, nsCollBlk.Coll, txNum)
+	// we cannot delete entries from MissingDataMap as
+	// we keep only one entry per missing <ns-col>
+	// irrespective of the number of txNum.
+
+	// add
+	expiryKey := ExpiryKey{expiryEntry.Key.ExpiringBlk, expiryEntry.Key.CommittingBlk}
+	updateEntries.ExpiryEntries[expiryKey] = expiryEntry.Value
+}
+
+func (updateEntries *EntriesForPvtDataOfOldBlocks) UpdateAndAddMissingDataEntry(missingData *bitset.BitSet, dataKey *DataKey) {
+
+	txNum := dataKey.TxNum
+	nsCollBlk := dataKey.NsCollBlk
+	// update
+	missingData.Clear(uint(txNum))
+	// add
+	updateEntries.MissingDataEntries[nsCollBlk] = missingData
+}
+
+type ExpiryData pvtdatastorage.ExpiryData
+
+func NewExpiryData() *ExpiryData {
+	return &ExpiryData{Map: make(map[string]*pvtdatastorage.Collections)}
+}
+
+func (e *ExpiryData) getOrCreateCollections(ns string) *pvtdatastorage.Collections {
+	collections, ok := e.Map[ns]
+	if !ok {
+		collections = &pvtdatastorage.Collections{
+			Map:            make(map[string]*pvtdatastorage.TxNums),
+			MissingDataMap: make(map[string]bool)}
+		e.Map[ns] = collections
+	} else {
+		// due to protobuf encoding/decoding, the previously
+		// initialized map could be a nil now due to 0 length.
+		// Hence, we need to reinitialize the map.
+		if collections.Map == nil {
+			collections.Map = make(map[string]*pvtdatastorage.TxNums)
+		}
+		if collections.MissingDataMap == nil {
+			collections.MissingDataMap = make(map[string]bool)
+		}
+	}
+	return collections
+}
+
+func (e *ExpiryData) AddPresentData(ns, coll string, txNum uint64) {
+	collections := e.getOrCreateCollections(ns)
+
+	txNums, ok := collections.Map[coll]
+	if !ok {
+		txNums = &pvtdatastorage.TxNums{}
+		collections.Map[coll] = txNums
+	}
+	txNums.List = append(txNums.List, txNum)
+}
+
+func (e *ExpiryData) AddMissingData(ns, coll string) {
+	collections := e.getOrCreateCollections(ns)
+	collections.MissingDataMap[coll] = true
+}
+
+func (e *ExpiryData) Reset() {
+	*e = ExpiryData{}
+}
+func (e *ExpiryData) String() string {
+	return proto.CompactTextString(e)
+}
+
+func (*ExpiryData) ProtoMessage() {
+}
+
+func ConstructDataEntriesFromBlocksPvtData(blocksPvtData map[uint64][]*ledger.TxPvtData) map[uint64][]*DataEntry {
+	// construct dataEntries for all pvtData
+	dataEntries := make(map[uint64][]*DataEntry)
+	for blkNum, pvtData := range blocksPvtData {
+		// prepare the dataEntries for the pvtData
+		dataEntries[blkNum] = prepareDataEntries(blkNum, pvtData)
+	}
+	return dataEntries
+}
+
+func ConstructUpdateEntriesFromDataEntries(dataEntries []*DataEntry, btlPolicy pvtdatapolicy.BTLPolicy,
+	getExpiryDataOfExpiryKey func(*ExpiryKey) (*ExpiryData, error), getBitmapOfMissingDataKey func(*MissingDataKey) (*bitset.BitSet, error)) (*EntriesForPvtDataOfOldBlocks, error) {
+	updateEntries := &EntriesForPvtDataOfOldBlocks{
+		DataEntries:        make(map[DataKey]*rwset.CollectionPvtReadWriteSet),
+		ExpiryEntries:      make(map[ExpiryKey]*ExpiryData),
+		MissingDataEntries: make(map[NsCollBlk]*bitset.BitSet)}
+
+	// for each data entry, first, get the expiryData and missingData from the pvtStore.
+	// Second, update the expiryData and missingData as per the data entry. Finally, add
+	// the data entry along with the updated expiryData and missingData to the update entries
+	for _, dataEntry := range dataEntries {
+		// get the expiryBlk number to construct the expiryKey
+		expiryKey, err := constructExpiryKeyFromDataEntry(dataEntry, btlPolicy)
+		if err != nil {
+			return nil, err
+		}
+
+		// get the existing expiryData ntry
+		var expiryData *ExpiryData
+		if !neverExpires(expiryKey.ExpiringBlk) {
+			if expiryData, err = getExpiryDataFromUpdateEntriesOrStore(updateEntries, expiryKey, getExpiryDataOfExpiryKey); err != nil {
+				return nil, err
+			}
+			if expiryData == nil {
+				// data entry is already expired
+				// and purged (a rare scenario)
+				continue
+			}
+		}
+
+		// get the existing missingData entry
+		var missingData *bitset.BitSet
+		nsCollBlk := dataEntry.Key.NsCollBlk
+		if missingData, err = getMissingDataFromUpdateEntriesOrStore(updateEntries, nsCollBlk, getBitmapOfMissingDataKey); err != nil {
+			return nil, err
+		}
+		if missingData == nil {
+			// data entry is already expired
+			// and purged (a rare scenario)
+			continue
+		}
+
+		updateEntries.AddDataEntry(dataEntry)
+		if expiryData != nil { // would be nill for the never expiring entry
+			expiryEntry := &ExpiryEntry{Key: &expiryKey, Value: expiryData}
+			updateEntries.UpdateAndAddExpiryEntry(expiryEntry, dataEntry.Key)
+		}
+		updateEntries.UpdateAndAddMissingDataEntry(missingData, dataEntry.Key)
+	}
+	return updateEntries, nil
+}
+
+func ConstructUpdateBatchFromUpdateEntries(updateEntries *EntriesForPvtDataOfOldBlocks, batch *leveldbhelper.UpdateBatch) (*leveldbhelper.UpdateBatch, error) {
+	// add the following four types of entries to the update batch: (1) updated missing data entries
+
+	// (1) add updated missingData to the batch
+	if err := addUpdatedMissingDataEntriesToUpdateBatch(batch, updateEntries); err != nil {
+		return nil, err
+	}
+
+	return batch, nil
+}
+
+func constructExpiryKeyFromDataEntry(dataEntry *DataEntry, btlPolicy pvtdatapolicy.BTLPolicy) (ExpiryKey, error) {
+	// get the expiryBlk number to construct the expiryKey
+	nsCollBlk := dataEntry.Key.NsCollBlk
+	expiringBlk, err := btlPolicy.GetExpiringBlock(nsCollBlk.Ns, nsCollBlk.Coll, nsCollBlk.BlkNum)
+	if err != nil {
+		return ExpiryKey{}, err
+	}
+	return ExpiryKey{ExpiringBlk: expiringBlk, CommittingBlk: nsCollBlk.BlkNum}, nil
+}
+
+func getExpiryDataFromUpdateEntriesOrStore(updateEntries *EntriesForPvtDataOfOldBlocks, expiryKey ExpiryKey, getExpiryDataOfExpiryKey func(*ExpiryKey) (*ExpiryData, error)) (*ExpiryData, error) {
+	expiryData, ok := updateEntries.ExpiryEntries[expiryKey]
+	if !ok {
+		var err error
+		expiryData, err = getExpiryDataOfExpiryKey(&expiryKey)
+		if err != nil {
+			return nil, err
+		}
+	}
+	return expiryData, nil
+}
+
+func getMissingDataFromUpdateEntriesOrStore(updateEntries *EntriesForPvtDataOfOldBlocks, nsCollBlk NsCollBlk, getBitmapOfMissingDataKey func(*MissingDataKey) (*bitset.BitSet, error)) (*bitset.BitSet, error) {
+	missingData, ok := updateEntries.MissingDataEntries[nsCollBlk]
+	if !ok {
+		var err error
+		missingDataKey := &MissingDataKey{NsCollBlk: nsCollBlk, IsEligible: true}
+		missingData, err = getBitmapOfMissingDataKey(missingDataKey)
+		if err != nil {
+			return nil, err
+		}
+	}
+	return missingData, nil
+}
+
+func addUpdatedMissingDataEntriesToUpdateBatch(batch *leveldbhelper.UpdateBatch, entries *EntriesForPvtDataOfOldBlocks) error {
+	var keyBytes, valBytes []byte
+	var err error
+	for nsCollBlk, missingData := range entries.MissingDataEntries {
+		keyBytes = EncodeMissingDataKey(&MissingDataKey{nsCollBlk, true})
+		// if the missingData is empty, we need to delete the missingDataKey
+		if missingData.None() {
+			batch.Delete(keyBytes)
+			continue
+		}
+		if valBytes, err = EncodeMissingDataValue(missingData); err != nil {
+			return err
+		}
+		batch.Put(keyBytes, valBytes)
+	}
+	return nil
+}
+
+func GetLastUpdatedOldBlocksList(missingKeysIndexDB *leveldbhelper.DBHandle) ([]uint64, error) {
+	var v []byte
+	var err error
+	if v, err = missingKeysIndexDB.Get(LastUpdatedOldBlocksKey); err != nil {
+		return nil, err
+	}
+	if v == nil {
+		return nil, nil
+	}
+
+	var updatedBlksList []uint64
+	buf := proto.NewBuffer(v)
+	numBlks, err := buf.DecodeVarint()
+	if err != nil {
+		return nil, err
+	}
+	for i := 0; i < int(numBlks); i++ {
+		blkNum, err := buf.DecodeVarint()
+		if err != nil {
+			return nil, err
+		}
+		updatedBlksList = append(updatedBlksList, blkNum)
+	}
+	return updatedBlksList, nil
+}
+
+func ResetLastUpdatedOldBlocksList(missingKeysIndexDB *leveldbhelper.DBHandle) error {
+	batch := leveldbhelper.NewUpdateBatch()
+	batch.Delete(LastUpdatedOldBlocksKey)
+	if err := missingKeysIndexDB.WriteBatch(batch, true); err != nil {
+		return err
+	}
+	return nil
+}
+
+// GetMissingPvtDataInfoForMostRecentBlocks
+func GetMissingPvtDataInfoForMostRecentBlocks(maxBlock int, lastCommittedBlk uint64, btlPolicy pvtdatapolicy.BTLPolicy, missingKeysIndexDB *leveldbhelper.DBHandle) (ledger.MissingPvtDataInfo, error) {
+	// we assume that this function would be called by the gossip only after processing the
+	// last retrieved missing pvtdata info and committing the same.
+	if maxBlock < 1 {
+		return nil, nil
+	}
+
+	missingPvtDataInfo := make(ledger.MissingPvtDataInfo)
+	numberOfBlockProcessed := 0
+	lastProcessedBlock := uint64(0)
+	isMaxBlockLimitReached := false
+	// as we are not acquiring a read lock, new blocks can get committed while we
+	// construct the MissingPvtDataInfo. As a result, lastCommittedBlock can get
+	// changed. To ensure consistency, we atomically load the lastCommittedBlock value
+	lastCommittedBlock := atomic.LoadUint64(&lastCommittedBlk)
+
+	startKey, endKey := createRangeScanKeysForEligibleMissingDataEntries(lastCommittedBlock)
+	dbItr := missingKeysIndexDB.GetIterator(startKey, endKey)
+	defer dbItr.Release()
+
+	for dbItr.Next() {
+		missingDataKeyBytes := dbItr.Key()
+		missingDataKey := decodeMissingDataKey(missingDataKeyBytes)
+
+		if isMaxBlockLimitReached && (missingDataKey.BlkNum != lastProcessedBlock) {
+			// esnures that exactly maxBlock number
+			// of blocks' entries are processed
+			break
+		}
+
+		// check whether the entry is expired. If so, move to the next item.
+		// As we may use the old lastCommittedBlock value, there is a possibility that
+		// this missing data is actually expired but we may get the stale information.
+		// Though it may leads to extra work of pulling the expired data, it will not
+		// affect the correctness. Further, as we try to fetch the most recent missing
+		// data (less possibility of expiring now), such scenario would be rare. In the
+		// best case, we can load the latest lastCommittedBlock value here atomically to
+		// make this scenario very rare.
+		lastCommittedBlock = atomic.LoadUint64(&lastCommittedBlk)
+		expired, err := IsExpired(missingDataKey.NsCollBlk, btlPolicy, lastCommittedBlock)
+		if err != nil {
+			return nil, err
+		}
+		if expired {
+			continue
+		}
+
+		// check for an existing entry for the blkNum in the MissingPvtDataInfo.
+		// If no such entry exists, create one. Also, keep track of the number of
+		// processed block due to maxBlock limit.
+		if _, ok := missingPvtDataInfo[missingDataKey.BlkNum]; !ok {
+			numberOfBlockProcessed++
+			if numberOfBlockProcessed == maxBlock {
+				isMaxBlockLimitReached = true
+				// as there can be more than one entry for this block,
+				// we cannot `break` here
+				lastProcessedBlock = missingDataKey.BlkNum
+			}
+		}
+
+		valueBytes := dbItr.Value()
+		bitmap, err := DecodeMissingDataValue(valueBytes)
+		if err != nil {
+			return nil, err
+		}
+
+		// for each transaction which misses private data, make an entry in missingBlockPvtDataInfo
+		for index, isSet := bitmap.NextSet(0); isSet; index, isSet = bitmap.NextSet(index + 1) {
+			txNum := uint64(index)
+			missingPvtDataInfo.Add(missingDataKey.BlkNum, txNum, missingDataKey.Ns, missingDataKey.Coll)
+		}
+	}
+
+	return missingPvtDataInfo, nil
+}
+
+// ProcessCollsEligibilityEnabled
+func ProcessCollsEligibilityEnabled(committingBlk uint64, nsCollMap map[string][]string, collElgProcSync *CollElgProc, missingKeysIndexDB *leveldbhelper.DBHandle) error {
+	key := encodeCollElgKey(committingBlk)
+	m := newCollElgInfo(nsCollMap)
+	val, err := encodeCollElgVal(m)
+	if err != nil {
+		return err
+	}
+	batch := leveldbhelper.NewUpdateBatch()
+	batch.Put(key, val)
+	if err = missingKeysIndexDB.WriteBatch(batch, true); err != nil {
+		return err
+	}
+	collElgProcSync.notify()
+	return nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/v11.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/v11.go
new file mode 100644
index 00000000..804729f4
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/v11.go
@@ -0,0 +1,78 @@
+/*
+Copyright IBM Corp. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package common
+
+import (
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/version"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+)
+
+// todo add pinning script to include copied code into this file, original file from fabric is found in fabric/core/ledger/pvtdatastorage/v11.go
+// todo below functions are originally unexported, the pinning script must capitalize these functions to export them
+
+type blkTranNumKey []byte
+
+func V11Format(datakeyBytes []byte) bool {
+	_, n := version.NewHeightFromBytes(datakeyBytes[1:])
+	remainingBytes := datakeyBytes[n+1:]
+	return len(remainingBytes) == 0
+}
+
+func v11DecodePK(key blkTranNumKey) (blockNum uint64, tranNum uint64) {
+	height, _ := version.NewHeightFromBytes(key[1:])
+	return height.BlockNum, height.TxNum
+}
+
+func v11DecodePvtRwSet(encodedBytes []byte) (*rwset.TxPvtReadWriteSet, error) {
+	writeset := &rwset.TxPvtReadWriteSet{}
+	return writeset, proto.Unmarshal(encodedBytes, writeset)
+}
+
+func V11DecodeKV(k, v []byte, filter ledger.PvtNsCollFilter) (*ledger.TxPvtData, error) {
+	_, tNum := v11DecodePK(k)
+	var pvtWSet *rwset.TxPvtReadWriteSet
+	var err error
+	if pvtWSet, err = v11DecodePvtRwSet(v); err != nil {
+		return nil, err
+	}
+	filteredWSet := v11TrimPvtWSet(pvtWSet, filter)
+	return &ledger.TxPvtData{SeqInBlock: tNum, WriteSet: filteredWSet}, nil
+}
+
+func v11TrimPvtWSet(pvtWSet *rwset.TxPvtReadWriteSet, filter ledger.PvtNsCollFilter) *rwset.TxPvtReadWriteSet {
+	if filter == nil {
+		return pvtWSet
+	}
+
+	var filteredNsRwSet []*rwset.NsPvtReadWriteSet
+	for _, ns := range pvtWSet.NsPvtRwset {
+		var filteredCollRwSet []*rwset.CollectionPvtReadWriteSet
+		for _, coll := range ns.CollectionPvtRwset {
+			if filter.Has(ns.Namespace, coll.CollectionName) {
+				filteredCollRwSet = append(filteredCollRwSet, coll)
+			}
+		}
+		if filteredCollRwSet != nil {
+			filteredNsRwSet = append(filteredNsRwSet,
+				&rwset.NsPvtReadWriteSet{
+					Namespace:          ns.Namespace,
+					CollectionPvtRwset: filteredCollRwSet,
+				},
+			)
+		}
+	}
+	var filteredTxPvtRwSet *rwset.TxPvtReadWriteSet
+	if filteredNsRwSet != nil {
+		filteredTxPvtRwSet = &rwset.TxPvtReadWriteSet{
+			DataModel:  pvtWSet.GetDataModel(),
+			NsPvtRwset: filteredNsRwSet,
+		}
+	}
+	return filteredTxPvtRwSet
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/store_impl.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/store_impl.go
new file mode 100644
index 00000000..1c02c63c
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/store_impl.go
@@ -0,0 +1,206 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatastorage
+
+import (
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cachedpvtdatastore"
+	cdbpvtdatastore "github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore"
+)
+
+//////// Provider functions  /////////////
+//////////////////////////////////////////
+
+// PvtDataProvider encapsulates the storage and cache providers in addition to the missing data index provider
+type PvtDataProvider struct {
+	storageProvider pvtdatastorage.Provider
+	cacheProvider   pvtdatastorage.Provider
+}
+
+// NewProvider creates a new PvtDataStoreProvider that combines a cache provider and a backing storage provider
+func NewProvider() *PvtDataProvider {
+	// create couchdb pvt date store provider
+	storageProvider, err := cdbpvtdatastore.NewProvider()
+	if err != nil {
+		panic(err)
+	}
+	// create cache pvt date store provider
+	cacheProvider := cachedpvtdatastore.NewProvider()
+
+	p := PvtDataProvider{
+		storageProvider: storageProvider,
+		cacheProvider:   cacheProvider,
+	}
+	return &p
+}
+
+// OpenStore creates a pvt data store instance for the given ledger ID
+func (c *PvtDataProvider) OpenStore(ledgerID string) (pvtdatastorage.Store, error) {
+	pvtDataStore, err := c.storageProvider.OpenStore(ledgerID)
+	if err != nil {
+		return nil, err
+	}
+	cachePvtDataStore, err := c.cacheProvider.OpenStore(ledgerID)
+	if err != nil {
+		return nil, err
+	}
+
+	return newPvtDataStore(pvtDataStore, cachePvtDataStore)
+}
+
+// Close cleans up the Provider
+func (c *PvtDataProvider) Close() {
+	c.storageProvider.Close()
+	c.cacheProvider.Close()
+
+}
+
+type pvtDataStore struct {
+	pvtDataDBStore    pvtdatastorage.Store
+	cachePvtDataStore pvtdatastorage.Store
+}
+
+func newPvtDataStore(pvtDataDBStore pvtdatastorage.Store, cachePvtDataStore pvtdatastorage.Store) (*pvtDataStore, error) {
+	isEmpty, err := pvtDataDBStore.IsEmpty()
+	if err != nil {
+		return nil, err
+	}
+	// InitLastCommittedBlock for cache if pvtdata storage not empty
+	if !isEmpty {
+		lastCommittedBlockHeight, err := pvtDataDBStore.LastCommittedBlockHeight()
+		if err != nil {
+			return nil, err
+		}
+		err = cachePvtDataStore.InitLastCommittedBlock(lastCommittedBlockHeight - 1)
+		if err != nil {
+			return nil, err
+		}
+	}
+	c := pvtDataStore{
+		pvtDataDBStore:    pvtDataDBStore,
+		cachePvtDataStore: cachePvtDataStore,
+	}
+	return &c, nil
+}
+
+//////// store functions  ////////////////
+//////////////////////////////////////////
+func (c *pvtDataStore) Init(btlPolicy pvtdatapolicy.BTLPolicy) {
+	c.cachePvtDataStore.Init(btlPolicy)
+	c.pvtDataDBStore.Init(btlPolicy)
+}
+
+// Prepare pvt data in cache and send pvt data to background prepare/commit go routine
+func (c *pvtDataStore) Prepare(blockNum uint64, pvtData []*ledger.TxPvtData, pvtMissingDataMap ledger.TxMissingPvtDataMap) error {
+	// Prepare data in cache
+	err := c.cachePvtDataStore.Prepare(blockNum, pvtData, pvtMissingDataMap)
+	if err != nil {
+		return err
+	}
+	// Prepare data in storage
+	return c.pvtDataDBStore.Prepare(blockNum, pvtData, pvtMissingDataMap)
+}
+
+// Commit pvt data in cache and call background pvtDataWriter go routine to commit data
+func (c *pvtDataStore) Commit() error {
+	// Commit data in cache
+	err := c.cachePvtDataStore.Commit()
+	if err != nil {
+		return err
+	}
+	// Commit data in storage
+	return c.pvtDataDBStore.Commit()
+}
+
+//InitLastCommittedBlock initialize last committed block
+func (c *pvtDataStore) InitLastCommittedBlock(blockNum uint64) error {
+	// InitLastCommittedBlock data in cache
+	err := c.cachePvtDataStore.InitLastCommittedBlock(blockNum)
+	if err != nil {
+		return err
+	}
+	// InitLastCommittedBlock data in storage
+	return c.pvtDataDBStore.InitLastCommittedBlock(blockNum)
+}
+
+//GetPvtDataByBlockNum implements the function in the interface `Store`
+func (c *pvtDataStore) GetPvtDataByBlockNum(blockNum uint64, filter ledger.PvtNsCollFilter) ([]*ledger.TxPvtData, error) {
+	result, err := c.cachePvtDataStore.GetPvtDataByBlockNum(blockNum, filter)
+	if err != nil {
+		return nil, err
+	}
+	if len(result) > 0 {
+		return result, nil
+	}
+
+	// data is not in cache will try to get it from storage
+	return c.pvtDataDBStore.GetPvtDataByBlockNum(blockNum, filter)
+}
+
+//HasPendingBatch implements the function in the interface `Store`
+func (c *pvtDataStore) HasPendingBatch() (bool, error) {
+	return c.pvtDataDBStore.HasPendingBatch()
+}
+
+//LastCommittedBlockHeight implements the function in the interface `Store`
+func (c *pvtDataStore) LastCommittedBlockHeight() (uint64, error) {
+	return c.pvtDataDBStore.LastCommittedBlockHeight()
+}
+
+//IsEmpty implements the function in the interface `Store`
+func (c *pvtDataStore) IsEmpty() (bool, error) {
+	return c.pvtDataDBStore.IsEmpty()
+}
+
+// Rollback pvt data in cache and call background pvtDataWriter go routine to rollback data
+func (c *pvtDataStore) Rollback() error {
+	// Rollback data in cache
+	err := c.cachePvtDataStore.Rollback()
+	if err != nil {
+		return err
+	}
+	// Rollback data in storage
+	return c.pvtDataDBStore.Rollback()
+}
+
+//Shutdown implements the function in the interface `Store`
+func (c *pvtDataStore) Shutdown() {
+	c.cachePvtDataStore.Shutdown()
+	c.pvtDataDBStore.Shutdown()
+}
+
+//GetMissingPvtDataInfoForMostRecentBlocks implements the function in the interface `Store`
+func (c *pvtDataStore) GetMissingPvtDataInfoForMostRecentBlocks(maxBlock int) (ledger.MissingPvtDataInfo, error) {
+	return c.pvtDataDBStore.GetMissingPvtDataInfoForMostRecentBlocks(maxBlock)
+}
+
+//ProcessCollsEligibilityEnabled implements the function in the interface `Store`
+func (c *pvtDataStore) ProcessCollsEligibilityEnabled(committingBlk uint64, nsCollMap map[string][]string) error {
+	return c.pvtDataDBStore.ProcessCollsEligibilityEnabled(committingBlk, nsCollMap)
+}
+
+//CommitPvtDataOfOldBlocks implements the function in the interface `Store`
+func (c *pvtDataStore) CommitPvtDataOfOldBlocks(blocksPvtData map[uint64][]*ledger.TxPvtData) error {
+	err := c.pvtDataDBStore.CommitPvtDataOfOldBlocks(blocksPvtData)
+	if err != nil {
+		return errors.WithMessage(err, "CommitPvtDataOfOldBlocks in store failed")
+	}
+	return nil
+}
+
+//GetLastUpdatedOldBlocksPvtData implements the function in the interface `Store`
+func (c *pvtDataStore) GetLastUpdatedOldBlocksPvtData() (map[uint64][]*ledger.TxPvtData, error) {
+	return c.pvtDataDBStore.GetLastUpdatedOldBlocksPvtData()
+}
+
+//ResetLastUpdatedOldBlocksList implements the function in the interface `Store`
+func (c *pvtDataStore) ResetLastUpdatedOldBlocksList() error {
+	return c.pvtDataDBStore.ResetLastUpdatedOldBlocksList()
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/test_exports.go
new file mode 100644
index 00000000..364bb823
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/test_exports.go
@@ -0,0 +1,77 @@
+/*
+Copyright IBM Corp, SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package pvtdatastorage
+
+import (
+	"os"
+	"testing"
+
+	"github.com/hyperledger/fabric/common/metrics/disabled"
+	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/stretchr/testify/require"
+)
+
+// StoreEnv provides the  store env for testing
+type StoreEnv struct {
+	t                 testing.TB
+	TestStoreProvider pvtdatastorage.Provider
+	TestStore         pvtdatastorage.Store
+	ledgerid          string
+	btlPolicy         pvtdatapolicy.BTLPolicy
+	couchDBDef        *couchdb.CouchDBDef
+}
+
+// NewTestStoreEnv construct a StoreEnv for testing
+func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLPolicy, couchDBDef *couchdb.CouchDBDef) *StoreEnv {
+	removeStorePath()
+	req := require.New(t)
+	testStoreProvider := NewProvider()
+	testStore, err := testStoreProvider.OpenStore(ledgerid)
+	req.NoError(err)
+	testStore.Init(btlPolicy)
+	s := &StoreEnv{t, testStoreProvider, testStore, ledgerid, btlPolicy, couchDBDef}
+	return s
+}
+
+// CloseAndReopen closes and opens the store provider
+func (env *StoreEnv) CloseAndReopen() {
+	var err error
+	env.TestStoreProvider.Close()
+	env.TestStoreProvider = NewProvider()
+	env.TestStore, err = env.TestStoreProvider.OpenStore(env.ledgerid)
+	env.TestStore.Init(env.btlPolicy)
+	require.NoError(env.t, err)
+}
+
+//Cleanup env test
+func (env *StoreEnv) Cleanup(ledgerid string) {
+	//create a new connection
+	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBDef.URL, env.couchDBDef.Username, env.couchDBDef.Password,
+		env.couchDBDef.MaxRetries, env.couchDBDef.MaxRetriesOnStartup, env.couchDBDef.RequestTimeout, env.couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	if err != nil {
+		panic(err.Error())
+	}
+	pvtDataStoreDBName := couchdb.ConstructBlockchainDBName(ledgerid, "pvtdata")
+	db := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: pvtDataStoreDBName}
+	//drop the test database
+	if _, err := db.DropDatabase(); err != nil {
+		panic(err.Error())
+	}
+	env.TestStore.Shutdown()
+
+	removeStorePath()
+}
+
+func removeStorePath() {
+	dbPath := ledgerconfig.GetPvtdataStorePath()
+	if err := os.RemoveAll(dbPath); err != nil {
+		panic(err.Error())
+	}
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/roles.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/roles.go
new file mode 100644
index 00000000..a99b1004
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/roles.go
@@ -0,0 +1,123 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package roles
+
+import (
+	"strings"
+	"sync"
+
+	"github.com/trustbloc/fabric-peer-ext/pkg/config"
+)
+
+const (
+	// CommitterRole indicates that the peer commits data to the ledger
+	CommitterRole Role = "committer"
+	// EndorserRole indicates that the peer endorses transaction proposals
+	EndorserRole Role = "endorser"
+	// ValidatorRole indicates that the peer validates the block
+	ValidatorRole Role = "validator"
+)
+
+// Role is the role of the peer
+type Role string
+
+// Roles is a set of peer roles
+type Roles []Role
+
+// New creates Roles from the given slice of roles
+func New(r ...Role) Roles {
+	return Roles(r)
+}
+
+// FromStrings creates Roles from the given slice of strings
+func FromStrings(r ...string) Roles {
+	rls := make(Roles, len(r))
+	for i, s := range r {
+		rls[i] = Role(s)
+	}
+	return rls
+}
+
+// Contains return true if the given role is included in the set
+func (r Roles) Contains(role Role) bool {
+	if len(r) == 0 {
+		// Return true by default in order to be backward compatible
+		return true
+	}
+	for _, r := range r {
+		if r == role {
+			return true
+		}
+	}
+	return false
+}
+
+var initOnce sync.Once
+var roles map[Role]struct{}
+
+// HasRole returns true if the peer has the given role
+func HasRole(role Role) bool {
+	initOnce.Do(func() {
+		roles = getRoles()
+	})
+
+	if len(roles) == 0 {
+		// No roles were explicitly set, therefore the peer is assumed to have all roles.
+		return true
+	}
+
+	_, ok := roles[role]
+	return ok
+}
+
+// IsCommitter returns true if the peer is a committer, otherwise the peer does not commit to the DB
+func IsCommitter() bool {
+	return HasRole(CommitterRole)
+}
+
+// IsEndorser returns true if the peer is an endorser
+func IsEndorser() bool {
+	return HasRole(EndorserRole)
+}
+
+// IsValidator returns true if the peer is a validator
+func IsValidator() bool {
+	return HasRole(ValidatorRole)
+}
+
+// GetRoles returns the roles for the peer
+func GetRoles() []Role {
+	var ret []Role
+	for role := range roles {
+		ret = append(ret, role)
+	}
+	return ret
+}
+
+// AsString returns the roles for the peer
+func AsString() []string {
+	var ret []string
+	for role := range roles {
+		ret = append(ret, string(role))
+	}
+	return ret
+}
+
+func getRoles() map[Role]struct{} {
+	exists := struct{}{}
+	strRoles := config.GetRoles()
+	if strRoles == "" {
+		// The peer has all roles by default
+		return map[Role]struct{}{}
+	}
+	rolesMap := make(map[Role]struct{})
+	for _, r := range strings.Split(strRoles, ",") {
+		r = strings.ToLower(strings.TrimSpace(r))
+		rolesMap[Role(r)] = exists
+	}
+	return rolesMap
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/test_exports.go
new file mode 100644
index 00000000..27057b16
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/test_exports.go
@@ -0,0 +1,14 @@
+// +build testing
+
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package roles
+
+//SetRoles used for unit test
+func SetRoles(rolesValue map[Role]struct{}) {
+	roles = rolesValue
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/testutil/ext_test_env.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/testutil/ext_test_env.go
new file mode 100644
index 00000000..5ee6f31f
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/testutil/ext_test_env.go
@@ -0,0 +1,91 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package testutil
+
+import (
+	"fmt"
+	"os"
+	"time"
+
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/common/metrics/disabled"
+	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/hyperledger/fabric/integration/runner"
+	"github.com/spf13/viper"
+)
+
+var logger = flogging.MustGetLogger("testutil")
+
+//SetupExtTestEnv creates new couchdb instance for test
+//returns couchdbd address, cleanup and stop function handle.
+func SetupExtTestEnv() (addr string, cleanup func(string), stop func()) {
+	externalCouch, set := os.LookupEnv("COUCHDB_ADDR")
+	if set {
+		return externalCouch, func(string) {}, func() {}
+	}
+
+	couchDB := &runner.CouchDB{}
+	couchDB.Image = "couchdb:2.2.0"
+	if err := couchDB.Start(); err != nil {
+		panic(fmt.Errorf("failed to start couchDB: %s", err))
+	}
+
+	oldAddr := viper.GetString("ledger.state.couchDBConfig.couchDBAddress")
+
+	//update config
+	updateConfig(couchDB.Address())
+
+	return couchDB.Address(),
+		func(name string) {
+			cleanupCouchDB(name, couchDB)
+		}, func() {
+			//reset viper cdb config
+			updateConfig(oldAddr)
+			if err := couchDB.Stop(); err != nil {
+				panic(err.Error())
+			}
+		}
+}
+
+func cleanupCouchDB(name string, couchDB *runner.CouchDB) {
+	couchDBDef := couchdb.GetCouchDBDefinition()
+	couchInstance, _ := couchdb.CreateCouchInstance(couchDB.Address(), couchDBDef.Username, couchDBDef.Password,
+		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+
+	blkdb := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: fmt.Sprintf("%s$$blocks_", name)}
+	pvtdb := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: fmt.Sprintf("%s$$pvtdata_", name)}
+	txndb := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: fmt.Sprintf("%s$$transactions_", name)}
+
+	//drop the test databases
+	_, err := blkdb.DropDatabase()
+	if err != nil {
+		logger.Warnf("Failed to drop db: %s, cause:%s", blkdb.DBName, err)
+	}
+	_, err = pvtdb.DropDatabase()
+	if err != nil {
+		logger.Warnf("Failed to drop db: %s, cause:%s", pvtdb.DBName, err)
+	}
+	_, err = txndb.DropDatabase()
+	if err != nil {
+		logger.Warnf("Failed to drop db: %s, cause:%s", txndb.DBName, err)
+	}
+}
+
+//updateConfig updates 'couchAddress' in config
+func updateConfig(couchAddress string) {
+
+	viper.Set("ledger.state.couchDBConfig.couchDBAddress", couchAddress)
+	// Replace with correct username/password such as
+	// admin/admin if user security is enabled on couchdb.
+	viper.Set("ledger.state.couchDBConfig.username", "")
+	viper.Set("ledger.state.couchDBConfig.password", "")
+	viper.Set("ledger.state.couchDBConfig.maxRetries", 1)
+	viper.Set("ledger.state.couchDBConfig.maxRetriesOnStartup", 1)
+	viper.Set("ledger.state.couchDBConfig.requestTimeout", time.Second*35)
+	viper.Set("ledger.state.couchDBConfig.createGlobalChangesDB", false)
+
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/common/common_store_helper.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/common/common_store_helper.go
new file mode 100644
index 00000000..65ef598f
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/common/common_store_helper.go
@@ -0,0 +1,159 @@
+/*
+Copyright IBM Corp. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package common
+
+import (
+	"bytes"
+	"errors"
+
+	"github.com/hyperledger/fabric/common/ledger/util"
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+)
+
+// TODO add pinning script to include copied code into this file, original file from fabric is found in fabric/core/transientstore/store_helper.go
+// TODO below functions are originally unexported, the pinning script must capitalize these functions to export them
+
+var (
+	prwsetPrefix             = []byte("P")[0] // key prefix for storing private write set in transient store.
+	purgeIndexByHeightPrefix = []byte("H")[0] // key prefix for storing index on private write set using received at block height.
+	//purgeIndexByTxidPrefix   = []byte("T")[0] // key prefix for storing index on private write set using txid
+	compositeKeySep = byte(0x00)
+)
+
+// CreateCompositeKeyForPvtRWSet creates a key for storing private write set
+// in the transient store. The structure of the key is <prwsetPrefix>~txid~uuid~blockHeight.
+// TODO add pinning script to expose this function
+func CreateCompositeKeyForPvtRWSet(txid string, uuid string, blockHeight uint64) []byte {
+	var compositeKey []byte
+	compositeKey = append(compositeKey, prwsetPrefix)
+	compositeKey = append(compositeKey, compositeKeySep)
+	compositeKey = append(compositeKey, createCompositeKeyWithoutPrefixForTxid(txid, uuid, blockHeight)...)
+
+	return compositeKey
+}
+
+// createCompositeKeyWithoutPrefixForTxid creates a composite key of structure txid~uuid~blockHeight.
+func createCompositeKeyWithoutPrefixForTxid(txid string, uuid string, blockHeight uint64) []byte {
+	var compositeKey []byte
+	compositeKey = append(compositeKey, []byte(txid)...)
+	compositeKey = append(compositeKey, compositeKeySep)
+	compositeKey = append(compositeKey, []byte(uuid)...)
+	compositeKey = append(compositeKey, compositeKeySep)
+	compositeKey = append(compositeKey, util.EncodeOrderPreservingVarUint64(blockHeight)...)
+
+	return compositeKey
+}
+
+// CreateCompositeKeyForPurgeIndexByHeight creates a key to index private write set based on
+// received at block height such that purge based on block height can be achieved. The structure
+// of the key is <purgeIndexByHeightPrefix>~blockHeight~txid~uuid.
+// TODO add pinning script to expose this function
+func CreateCompositeKeyForPurgeIndexByHeight(blockHeight uint64, txid string, uuid string) []byte {
+	var compositeKey []byte
+	compositeKey = append(compositeKey, purgeIndexByHeightPrefix)
+	compositeKey = append(compositeKey, compositeKeySep)
+	compositeKey = append(compositeKey, util.EncodeOrderPreservingVarUint64(blockHeight)...)
+	compositeKey = append(compositeKey, compositeKeySep)
+	compositeKey = append(compositeKey, []byte(txid)...)
+	compositeKey = append(compositeKey, compositeKeySep)
+	compositeKey = append(compositeKey, []byte(uuid)...)
+
+	return compositeKey
+}
+
+// SplitCompositeKeyOfPvtRWSet splits the compositeKey (<prwsetPrefix>~txid~uuid~blockHeight)
+// into uuid and blockHeight.
+// TODO add pinning script to expose this function
+func SplitCompositeKeyOfPvtRWSet(compositeKey []byte) (uuid string, blockHeight uint64) {
+	return splitCompositeKeyWithoutPrefixForTxid(compositeKey[2:])
+}
+
+// SplitCompositeKeyOfPurgeIndexByHeight splits the compositeKey (<purgeIndexByHeightPrefix>~blockHeight~txid~uuid)
+// into txid, uuid and blockHeight.
+// TODO add pinning script to expose this function
+func SplitCompositeKeyOfPurgeIndexByHeight(compositeKey []byte) (txid string, uuid string, blockHeight uint64) {
+	var n int
+	blockHeight, n = util.DecodeOrderPreservingVarUint64(compositeKey[2:])
+	splits := bytes.Split(compositeKey[n+3:], []byte{compositeKeySep})
+	txid = string(splits[0])
+	uuid = string(splits[1])
+	return
+}
+
+// splitCompositeKeyWithoutPrefixForTxid splits the composite key txid~uuid~blockHeight into
+// uuid and blockHeight
+func splitCompositeKeyWithoutPrefixForTxid(compositeKey []byte) (uuid string, blockHeight uint64) {
+	// skip txid as all functions which requires split of composite key already has it
+	firstSepIndex := bytes.IndexByte(compositeKey, compositeKeySep)
+	secondSepIndex := firstSepIndex + bytes.IndexByte(compositeKey[firstSepIndex+1:], compositeKeySep) + 1
+	uuid = string(compositeKey[firstSepIndex+1 : secondSepIndex])
+	blockHeight, _ = util.DecodeOrderPreservingVarUint64(compositeKey[secondSepIndex+1:])
+	return
+}
+
+// TrimPvtWSet returns a `TxPvtReadWriteSet` that retains only list of 'ns/collections' supplied in the filter
+// A nil filter does not filter any results and returns the original `pvtWSet` as is
+// TODO add pinning script to expose this function
+func TrimPvtWSet(pvtWSet *rwset.TxPvtReadWriteSet, filter ledger.PvtNsCollFilter) *rwset.TxPvtReadWriteSet {
+	if filter == nil {
+		return pvtWSet
+	}
+
+	var filteredNsRwSet []*rwset.NsPvtReadWriteSet
+	for _, ns := range pvtWSet.NsPvtRwset {
+		var filteredCollRwSet []*rwset.CollectionPvtReadWriteSet
+		for _, coll := range ns.CollectionPvtRwset {
+			if filter.Has(ns.Namespace, coll.CollectionName) {
+				filteredCollRwSet = append(filteredCollRwSet, coll)
+			}
+		}
+		if filteredCollRwSet != nil {
+			filteredNsRwSet = append(filteredNsRwSet,
+				&rwset.NsPvtReadWriteSet{
+					Namespace:          ns.Namespace,
+					CollectionPvtRwset: filteredCollRwSet,
+				},
+			)
+		}
+	}
+	var filteredTxPvtRwSet *rwset.TxPvtReadWriteSet
+	if filteredNsRwSet != nil {
+		filteredTxPvtRwSet = &rwset.TxPvtReadWriteSet{
+			DataModel:  pvtWSet.GetDataModel(),
+			NsPvtRwset: filteredNsRwSet,
+		}
+	}
+	return filteredTxPvtRwSet
+}
+
+// TrimPvtCollectionConfigs returns a map of `CollectionConfigPackage` with configs retained only for config types 'staticCollectionConfig' supplied in the filter
+// A nil filter does not set Config to any collectionConfigPackage and returns a map with empty configs for each `configs` element
+// TODO add pinning script to expose this function and add below comment
+func TrimPvtCollectionConfigs(configs map[string]*common.CollectionConfigPackage,
+	filter ledger.PvtNsCollFilter) (map[string]*common.CollectionConfigPackage, error) {
+	if filter == nil {
+		return configs, nil
+	}
+	result := make(map[string]*common.CollectionConfigPackage)
+
+	for ns, pkg := range configs {
+		result[ns] = &common.CollectionConfigPackage{}
+		for _, colConf := range pkg.GetConfig() {
+			switch cconf := colConf.Payload.(type) {
+			case *common.CollectionConfig_StaticCollectionConfig:
+				if filter.Has(ns, cconf.StaticCollectionConfig.Name) {
+					result[ns].Config = append(result[ns].Config, colConf)
+				}
+			default:
+				return nil, errors.New("unexpected collection type")
+			}
+		}
+	}
+	return result, nil
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/store.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/store.go
new file mode 100644
index 00000000..ad40e4c2
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/store.go
@@ -0,0 +1,471 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package transientstore
+
+import (
+	"encoding/base64"
+	"encoding/hex"
+	"fmt"
+	"sort"
+
+	"github.com/bluele/gcache"
+	"github.com/golang/protobuf/proto"
+	"github.com/hyperledger/fabric/common/util"
+	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/core/transientstore"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
+	pb "github.com/hyperledger/fabric/protos/transientstore"
+	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/transientstore/common"
+)
+
+var nilByte = byte('\x00')
+
+// ErrStoreEmpty is used to indicate that there are no entries in transient store
+var ErrStoreEmpty = errors.New("Transient store is empty")
+
+// Store manages the storage of private write sets for a ledgerId.
+// Ideally, a ledger can remove the data from this storage when it is committed to
+// the permanent storage or the pruning of some data items is enforced by the policy
+// the internal storage mechanism used in this specific store is gcache of type 'simple'
+// cache to allow 'unlimited' growth of data and avoid eviction due to size. The assumption
+// is the ledger will purge data from this storage once transactions are committed or deemed invalid.
+
+type store struct {
+	// cache contains a key of txid and a value represented as a map of composite key/TxRWSet values (real data store)
+	cache gcache.Cache
+	// blockHeightCache contains a key of blockHeight and value represented as a slice of txids
+	blockHeightCache gcache.Cache
+	// txidCache contains a key of txid and value represented as a slice of blockHeights
+	txidCache gcache.Cache
+}
+
+func newStore() *store {
+	s := &store{}
+	s.cache = gcache.New(0).LoaderFunc(loadPvtRWSetMap).Build()
+	s.blockHeightCache = gcache.New(0).LoaderFunc(loadBlockHeight).Build()
+	s.txidCache = gcache.New(0).LoaderFunc(loadTxid).Build()
+	return s
+}
+
+// Persist stores the private write set of a transaction in the transient store
+// based on txid and the block height the private data was received at
+func (s *store) Persist(txid string, blockHeight uint64, privateSimulationResults *rwset.TxPvtReadWriteSet) error {
+	logger.Debugf("Persisting private data to transient store for txid [%s] at block height [%d]", txid, blockHeight)
+
+	uuid := util.GenerateUUID()
+	compositeKeyPvtRWSet := common.CreateCompositeKeyForPvtRWSet(txid, uuid, blockHeight)
+	privateSimulationResultsBytes, err := proto.Marshal(privateSimulationResults)
+	if err != nil {
+		return err
+	}
+
+	s.setTxPvtWRSetToCache(txid, compositeKeyPvtRWSet, privateSimulationResultsBytes)
+
+	s.setTxidToBlockHeightCache(txid, blockHeight)
+
+	s.updateTxidCache(txid, blockHeight)
+	return nil
+}
+
+// PersistWithConfig stores the private write set of a transaction along with the collection config
+// in the transient store based on txid and the block height the private data was received at
+func (s *store) PersistWithConfig(txid string, blockHeight uint64, privateSimulationResultsWithConfig *pb.TxPvtReadWriteSetWithConfigInfo) error {
+	if privateSimulationResultsWithConfig != nil {
+		logger.Debugf("Persisting private data to transient store for txid [%s] at block height [%d] with [%d] config(s)", txid, blockHeight, len(privateSimulationResultsWithConfig.CollectionConfigs))
+	} else {
+		logger.Debugf("Persisting private data to transient store for txid [%s] at block height [%d] with nil config", txid, blockHeight)
+	}
+
+	uuid := util.GenerateUUID()
+	compositeKeyPvtRWSet := common.CreateCompositeKeyForPvtRWSet(txid, uuid, blockHeight)
+	privateSimulationResultsWithConfigBytes, err := proto.Marshal(privateSimulationResultsWithConfig)
+	if err != nil {
+		return err
+	}
+
+	// emulating original Fabric's new proto (post v1.2) by appending nilByte
+	// TODO remove this when Fabric stops appending nilByte
+	privateSimulationResultsWithConfigBytes = append([]byte{nilByte}, privateSimulationResultsWithConfigBytes...)
+
+	s.setTxPvtWRSetToCache(txid, compositeKeyPvtRWSet, privateSimulationResultsWithConfigBytes)
+
+	s.setTxidToBlockHeightCache(txid, blockHeight)
+
+	s.updateTxidCache(txid, blockHeight)
+	return nil
+}
+
+func (s *store) updateTxidCache(txid string, blockHeight uint64) {
+	value, err := s.txidCache.Get(txid)
+	if err != nil {
+		if err != gcache.KeyNotFoundError {
+			panic(fmt.Sprintf("Get from cache must never return an error other than KeyNotFoundError err:%s", err))
+		}
+	}
+	uintVal := value.(*blockHeightsSlice)
+	if found, _ := uintVal.findBlockHeightEntryInSlice(blockHeight); !found {
+		uintVal.add(blockHeight)
+	}
+
+	err = s.txidCache.Set(txid, uintVal)
+	if err != nil {
+		panic(fmt.Sprintf("Storing blockheight '%d' for txid key '%s' in transientstore cache must never fail, err:%s", blockHeight, txid, err))
+	}
+}
+
+func (s *store) getTxPvtRWSetFromCache(txid string) *pvtRWSetMap {
+	value, err := s.cache.Get(txid)
+	if err != nil {
+		if err != gcache.KeyNotFoundError {
+			panic(fmt.Sprintf("Get from cache must never return an error other than KeyNotFoundError err:%s", err))
+		}
+	}
+
+	return value.(*pvtRWSetMap)
+}
+
+func (s *store) getTxidsFromBlockHeightCache(blockHeight uint64) *txidsSlice {
+	blockHeightValue, err := s.blockHeightCache.Get(blockHeight)
+	if err != nil {
+		if err != gcache.KeyNotFoundError {
+			panic(fmt.Sprintf("Get from cache must never return an error other than KeyNotFoundError err:%s", err))
+		}
+	}
+	return blockHeightValue.(*txidsSlice)
+}
+
+func (s *store) setTxPvtWRSetToCache(txid string, compositeKeyPvtRWSet, privSimulationResults []byte) {
+	txPvtRWSetMap := s.getTxPvtRWSetFromCache(txid)
+	k := hex.EncodeToString(compositeKeyPvtRWSet)
+	v := base64.StdEncoding.EncodeToString(privSimulationResults)
+	txPvtRWSetMap.set(k, v)
+
+	err := s.cache.Set(txid, txPvtRWSetMap)
+	if err != nil {
+		panic(fmt.Sprintf("Set to cache must never return an error, got error:%s", err))
+	}
+}
+
+func (s *store) setTxidToBlockHeightCache(txid string, blockHeight uint64) {
+	blockHeightTxids := s.getTxidsFromBlockHeightCache(blockHeight)
+	found, _ := blockHeightTxids.findTxidEntryInSlice(txid)
+	if !found {
+		blockHeightTxids.add(txid)
+		err := s.blockHeightCache.Set(blockHeight, blockHeightTxids)
+		if err != nil {
+			panic(fmt.Sprintf("Set to cache must never return an error, got error:%s", err))
+		}
+	}
+}
+
+// GetTxPvtRWSetByTxid returns an iterator due to the fact that the txid may have multiple private
+// write sets persisted from different endorsers (via Gossip)
+func (s *store) GetTxPvtRWSetByTxid(txid string, filter ledger.PvtNsCollFilter) (transientstore.RWSetScanner, error) {
+	logger.Debugf("Calling GetTxPvtRWSetByTxid on transient store for txid [%s]", txid)
+	var results []keyValue
+
+	val, err := s.cache.Get(txid)
+	if err != nil {
+		if err != gcache.KeyNotFoundError {
+			panic(fmt.Sprintf("Get from cache must never return an error other than KeyNotFoundError err:%s", err))
+		}
+		// return empty results
+		return &RwsetScanner{filter: filter, results: []keyValue{}}, nil
+	}
+
+	pvtRWsm := val.(*pvtRWSetMap)
+	pvtRWsm.mu.RLock()
+	defer pvtRWsm.mu.RUnlock()
+	for key, value := range pvtRWsm.m {
+		results = append(results, keyValue{key: key, value: value})
+	}
+
+	return &RwsetScanner{filter: filter, results: results}, nil
+}
+
+// GetMinTransientBlkHt returns the lowest block height remaining in transient store
+func (s *store) GetMinTransientBlkHt() (uint64, error) {
+	var minTransientBlkHt uint64
+	val := s.blockHeightCache.GetALL()
+
+	for key := range val {
+		k := key.(uint64)
+		if minTransientBlkHt == 0 || k < minTransientBlkHt {
+			minTransientBlkHt = k
+		}
+	}
+	logger.Debugf("Called GetMinTransientBlkHt on transient store, min block height is: %d", minTransientBlkHt)
+	if minTransientBlkHt == 0 { // mimic Fabric's transientstore with leveldb -> return an error
+		return 0, ErrStoreEmpty
+	}
+	return minTransientBlkHt, nil
+}
+
+// PurgeByTxids removes private write sets of a given set of transactions from the
+// transient store
+func (s *store) PurgeByTxids(txids []string) error {
+	logger.Debugf("Calling PurgeByTxids on transient store for txids [%v]", txids)
+	s.purgeTxPvtRWSetCacheByTxids(txids)
+	return s.purgeBlockHeightCacheByTxids(txids)
+}
+
+// Shutdown noop for in memory storage
+func (s *store) Shutdown() {
+
+}
+
+func (s *store) purgeTxPvtRWSetCacheByTxids(txids []string) {
+	for _, txID := range txids {
+		s.cache.Remove(txID)
+	}
+}
+
+func (s *store) purgeTxRWSetCacheByBlockHeight(txids []string, maxBlockNumToRetain uint64) error {
+	for _, txID := range txids {
+		txMap := s.getTxPvtRWSetFromCache(txID)
+		for _, txK := range txMap.keys() {
+			hexKey, err := hex.DecodeString(txK)
+			if err != nil {
+				return err
+			}
+			_, blkHeight := common.SplitCompositeKeyOfPvtRWSet(hexKey)
+			if blkHeight < maxBlockNumToRetain {
+				txMap.delete(txK)
+			}
+		}
+		if txMap.length() == 0 {
+			s.cache.Remove(txID)
+		}
+
+	}
+	return nil
+}
+
+func (s *store) purgeBlockHeightCacheByTxids(txids []string) error {
+	sort.Strings(txids)
+	var blkHeightTxids *txidsSlice
+	var blkHeightKeys []uint64
+	// step 1 fetch block heights for txids
+	blkHeightKeys, err := s.getBlockHeightKeysFromTxidCache(txids)
+	if err != nil {
+		return err
+	}
+	// step 2 remove txids from blockHeightCache
+	for _, blkHgtKey := range blkHeightKeys {
+		value, err := s.blockHeightCache.Get(blkHgtKey)
+		if err != nil {
+			if err == gcache.KeyNotFoundError {
+				continue
+			}
+			return err
+		}
+		blkHeightTxids = value.(*txidsSlice)
+		for _, txID := range txids {
+			for { // ensure to remove duplicates
+				if isFound, i := blkHeightTxids.findTxidEntryInSlice(txID); isFound {
+					blkHeightTxids.removeTxidEntryAtIndex(i)
+				} else {
+					break
+				}
+			}
+		}
+
+		if blkHeightTxids.length() == 0 {
+			s.blockHeightCache.Remove(blkHgtKey)
+		} else {
+			err := s.blockHeightCache.Set(blkHgtKey, blkHeightTxids)
+			if err != nil {
+				return err
+			}
+		}
+	}
+
+	// step 3 remove blockHeights from txidCache
+	return s.purgeTxidsCacheByBlockHeight(txids, blkHeightKeys)
+}
+
+func (s *store) getBlockHeightKeysFromTxidCache(txids []string) ([]uint64, error) {
+	var blkHeightKeys []uint64
+	for _, t := range txids {
+		blkHgts, err := s.txidCache.Get(t)
+		if err != nil {
+			if err == gcache.KeyNotFoundError {
+				continue
+			}
+			return nil, err
+		}
+		if blkHgts.(*blockHeightsSlice).length() > 0 {
+			blkHeightKeys = append(blkHeightKeys, blkHgts.(*blockHeightsSlice).getBlockHeights()...)
+		}
+	}
+	blkHeightKeys = sliceUniqueUint64(blkHeightKeys)
+	return blkHeightKeys, nil
+}
+
+// PurgeByHeight will remove all ReadWriteSets with block height below maxBlockNumToRetain
+func (s *store) PurgeByHeight(maxBlockNumToRetain uint64) error {
+	logger.Debugf("Calling PurgeByHeight on transient store for maxBlockNumToRetain [%d]", maxBlockNumToRetain)
+	txIDs := make([]string, 0)
+	blkHgts := make([]uint64, 0)
+	for key, value := range s.blockHeightCache.GetALL() {
+		k := key.(uint64)
+		if k < maxBlockNumToRetain {
+			txIDs = append(txIDs, value.(*txidsSlice).getTxids()...)
+			blkHgts = append(blkHgts, k)
+			s.blockHeightCache.Remove(k)
+		}
+	}
+	txIDs = sliceUniqueString(txIDs)
+	blkHgts = sliceUniqueUint64(blkHgts)
+	err := s.purgeTxRWSetCacheByBlockHeight(txIDs, maxBlockNumToRetain)
+	if err != nil {
+		return err
+	}
+	return s.purgeTxidsCacheByBlockHeight(txIDs, blkHgts)
+
+}
+
+func (s *store) purgeTxidsCacheByBlockHeight(txids []string, blockHeights []uint64) error {
+	for _, txid := range txids {
+		blkHgt, err := s.txidCache.Get(txid)
+		if err != nil {
+			if err == gcache.KeyNotFoundError {
+				continue
+			}
+			return err
+		}
+		blkHgtSliceByTxid := blkHgt.(*blockHeightsSlice)
+
+		for _, b := range blockHeights {
+			if isFound, i := blkHgtSliceByTxid.findBlockHeightEntryInSlice(b); isFound {
+				blkHgtSliceByTxid.removeBlockHeightEntryAtIndex(i)
+			}
+		}
+
+		if blkHgtSliceByTxid.length() == 0 {
+			s.txidCache.Remove(txid)
+		}
+	}
+	return nil
+}
+
+type keyValue struct {
+	key   string
+	value string
+}
+
+// RwsetScanner provides an iterator for EndorserPvtSimulationResults from transientstore
+type RwsetScanner struct {
+	filter  ledger.PvtNsCollFilter
+	results []keyValue
+	next    int
+}
+
+// Next moves the iterator to the next key/value pair.
+// It returns whether the iterator is exhausted.
+// TODO: Once the related gossip changes are made as per FAB-5096, remove this function
+func (scanner *RwsetScanner) Next() (*transientstore.EndorserPvtSimulationResults, error) {
+	kv, ok := scanner.nextKV()
+	if !ok {
+		return nil, nil
+	}
+
+	keyBytes, err := hex.DecodeString(kv.key)
+	if err != nil {
+		return nil, err
+	}
+	_, blockHeight := common.SplitCompositeKeyOfPvtRWSet(keyBytes)
+	logger.Debugf("scanner next blockHeight %d", blockHeight)
+	txPvtRWSet := &rwset.TxPvtReadWriteSet{}
+	valueBytes, err := base64.StdEncoding.DecodeString(kv.value)
+	if err != nil {
+		return nil, errors.Wrapf(err, "error from DecodeString for transientDataField")
+	}
+
+	if err := proto.Unmarshal(valueBytes, txPvtRWSet); err != nil {
+		return nil, err
+	}
+	filteredTxPvtRWSet := common.TrimPvtWSet(txPvtRWSet, scanner.filter)
+	logger.Debugf("scanner next filteredTxPvtRWSet %v", filteredTxPvtRWSet)
+
+	return &transientstore.EndorserPvtSimulationResults{
+		ReceivedAtBlockHeight: blockHeight,
+		PvtSimulationResults:  filteredTxPvtRWSet,
+	}, nil
+
+}
+
+// NextWithConfig moves the iterator to the next key/value pair with configs.
+// It returns whether the iterator is exhausted.
+// TODO: Once the related gossip changes are made as per FAB-5096, rename this function to Next
+func (scanner *RwsetScanner) NextWithConfig() (*transientstore.EndorserPvtSimulationResultsWithConfig, error) {
+	kv, ok := scanner.nextKV()
+	if !ok {
+		return nil, nil
+	}
+
+	keyBytes, err := hex.DecodeString(kv.key)
+	if err != nil {
+		return nil, err
+	}
+	_, blockHeight := common.SplitCompositeKeyOfPvtRWSet(keyBytes)
+	logger.Debugf("scanner NextWithConfig blockHeight %d", blockHeight)
+
+	valueBytes, err := base64.StdEncoding.DecodeString(kv.value)
+	if err != nil {
+		return nil, errors.Wrapf(err, "error from DecodeString for transientDataField")
+	}
+
+	txPvtRWSet := &rwset.TxPvtReadWriteSet{}
+	var filteredTxPvtRWSet *rwset.TxPvtReadWriteSet
+	txPvtRWSetWithConfig := &pb.TxPvtReadWriteSetWithConfigInfo{}
+
+	if valueBytes[0] == nilByte {
+		// new proto, i.e., TxPvtReadWriteSetWithConfigInfo
+		if er := proto.Unmarshal(valueBytes[1:], txPvtRWSetWithConfig); er != nil {
+			return nil, er
+		}
+
+		logger.Debugf("scanner NextWithConfig txPvtRWSetWithConfig %v", txPvtRWSetWithConfig)
+
+		filteredTxPvtRWSet = common.TrimPvtWSet(txPvtRWSetWithConfig.GetPvtRwset(), scanner.filter)
+		logger.Debugf("scanner NextWithConfig filteredTxPvtRWSet %v", filteredTxPvtRWSet)
+		configs, err := common.TrimPvtCollectionConfigs(txPvtRWSetWithConfig.CollectionConfigs, scanner.filter)
+		if err != nil {
+			return nil, err
+		}
+		logger.Debugf("scanner NextWithConfig configs %v", configs)
+		txPvtRWSetWithConfig.CollectionConfigs = configs
+	} else {
+		// old proto, i.e., TxPvtReadWriteSet
+		if e := proto.Unmarshal(valueBytes, txPvtRWSet); e != nil {
+			return nil, e
+		}
+		filteredTxPvtRWSet = common.TrimPvtWSet(txPvtRWSet, scanner.filter)
+	}
+
+	txPvtRWSetWithConfig.PvtRwset = filteredTxPvtRWSet
+
+	return &transientstore.EndorserPvtSimulationResultsWithConfig{
+		ReceivedAtBlockHeight:          blockHeight,
+		PvtSimulationResultsWithConfig: txPvtRWSetWithConfig,
+	}, nil
+}
+
+func (scanner *RwsetScanner) nextKV() (keyValue, bool) {
+	i := scanner.next
+	if i >= len(scanner.results) {
+		return keyValue{}, false
+	}
+	scanner.next++
+	return scanner.results[i], true
+}
+
+// Close releases resource held by the iterator
+func (scanner *RwsetScanner) Close() {
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/store_helper.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/store_helper.go
new file mode 100644
index 00000000..04a3532d
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/store_helper.go
@@ -0,0 +1,190 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package transientstore
+
+import (
+	"sort"
+	"sync"
+)
+
+// loadPvtRWSetMap is a loader function of store.cache
+func loadPvtRWSetMap(key interface{}) (interface{}, error) {
+	return &pvtRWSetMap{m: map[string]string{}}, nil
+}
+
+// pvtRWSetMap represents a cached element in store.cache
+type pvtRWSetMap struct {
+	mu sync.RWMutex
+	m  map[string]string
+}
+
+//func (p *pvtRWSetMap) get(k string) string {
+//	p.mu.RLock()
+//	defer p.mu.RUnlock()
+//
+//	return p.m[k]
+//}
+
+func (p *pvtRWSetMap) set(k string, v string) {
+	p.mu.Lock()
+	defer p.mu.Unlock()
+
+	p.m[k] = v
+}
+
+func (p *pvtRWSetMap) length() int {
+	p.mu.RLock()
+	defer p.mu.RUnlock()
+
+	return len(p.m)
+}
+
+func (p *pvtRWSetMap) delete(k string) {
+	p.mu.Lock()
+	defer p.mu.Unlock()
+
+	delete(p.m, k)
+}
+
+func (p *pvtRWSetMap) keys() []string {
+	p.mu.RLock()
+	defer p.mu.RUnlock()
+
+	keys := make([]string, 0, len(p.m))
+	for k := range p.m {
+		keys = append(keys, k)
+	}
+	return keys
+}
+
+// loadBlockHeight is a loader function of store.blockHeightCache
+func loadBlockHeight(key interface{}) (interface{}, error) {
+	return &txidsSlice{m: []string{}}, nil
+}
+
+// txidsSlice represents a cached element in store.blockHeightCache
+type txidsSlice struct {
+	mu sync.RWMutex
+	m  []string
+}
+
+func (p *txidsSlice) add(v string) {
+	p.mu.Lock()
+	defer p.mu.Unlock()
+
+	p.m = append(p.m, v)
+	sort.Strings(p.m) // ensures txids are sorted to help sort.search call in findTxidEntryInSlice below
+}
+
+// findTxidEntryInSlice will search for txid in txidsSlice
+func (p *txidsSlice) findTxidEntryInSlice(txid string) (bool, int) {
+	p.mu.RLock()
+	defer p.mu.RUnlock()
+	i := sort.Search(len(p.m), func(i int) bool { return p.m[i] >= txid }) //  equivalent to sort.SearchStrings()
+	return i < len(p.m) && p.m[i] == txid, i
+}
+
+// removeTxidEntryAtIndex removes an entry at index in the txidsSlice
+func (p *txidsSlice) removeTxidEntryAtIndex(index int) {
+	p.mu.Lock()
+	defer p.mu.Unlock()
+	p.m = append(p.m[:index], p.m[index+1:]...)
+}
+
+func (p *txidsSlice) length() int {
+	p.mu.RLock()
+	defer p.mu.RUnlock()
+
+	return len(p.m)
+}
+
+func (p *txidsSlice) getTxids() []string {
+	p.mu.RLock()
+	defer p.mu.RUnlock()
+
+	return p.m
+}
+
+// loadTxid is a loader function of store.txidCache
+func loadTxid(key interface{}) (interface{}, error) {
+	return &blockHeightsSlice{m: []uint64{}}, nil
+}
+
+// blockHeightsSlice represents a cached element in store.txidCache
+type blockHeightsSlice struct {
+	mu sync.RWMutex
+	m  []uint64
+}
+
+func (p *blockHeightsSlice) add(v uint64) {
+	p.mu.Lock()
+	defer p.mu.Unlock()
+
+	p.m = append(p.m, v)
+	sort.Slice(p.m, func(i, j int) bool { return p.m[i] < p.m[j] }) // ensures blockHeights are sorted to help sort.search call in findBlockHeightEntryInSlice below
+}
+
+// findBlockHeightEntryInSlice will search for a blockheight (uint64) entry in blockHeightsSlice
+func (p *blockHeightsSlice) findBlockHeightEntryInSlice(blockHeight uint64) (bool, int) {
+	p.mu.RLock()
+	defer p.mu.RUnlock()
+
+	i := sort.Search(len(p.m), func(i int) bool { return p.m[i] >= blockHeight })
+	return i < len(p.m) && p.m[i] == blockHeight, i
+}
+
+// removeBlockHeightEntryAtIndex removes an entry at index in blockHeightsSlice
+func (p *blockHeightsSlice) removeBlockHeightEntryAtIndex(index int) {
+	p.mu.Lock()
+	defer p.mu.Unlock()
+
+	p.m = append(p.m[:index], p.m[index+1:]...)
+}
+
+func (p *blockHeightsSlice) length() int {
+	p.mu.RLock()
+	defer p.mu.RUnlock()
+
+	return len(p.m)
+}
+
+func (p *blockHeightsSlice) getBlockHeights() []uint64 {
+	p.mu.RLock()
+	defer p.mu.RUnlock()
+
+	return p.m
+}
+
+// sliceUniqueString will strip out any duplicate entries from a slice s (of type string)
+func sliceUniqueString(s []string) []string {
+	seen := make(map[string]struct{}, len(s))
+	j := 0
+	for _, v := range s {
+		if _, ok := seen[v]; ok {
+			continue
+		}
+		seen[v] = struct{}{}
+		s[j] = v
+		j++
+	}
+	return s[:j]
+}
+
+// sliceUniqueUint64 will strip out any duplicate entries from a slice s (of type uint64)
+func sliceUniqueUint64(s []uint64) []uint64 {
+	seen := make(map[uint64]struct{}, len(s))
+	j := 0
+	for _, v := range s {
+		if _, ok := seen[v]; ok {
+			continue
+		}
+		seen[v] = struct{}{}
+		s[j] = v
+		j++
+	}
+	return s[:j]
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/storeprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/storeprovider.go
new file mode 100644
index 00000000..098dd6fa
--- /dev/null
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/transientstore/storeprovider.go
@@ -0,0 +1,33 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package transientstore
+
+import (
+	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/core/transientstore"
+)
+
+var logger = flogging.MustGetLogger("transientstore")
+
+// Provider represents a trasientstore provider
+type Provider struct {
+}
+
+// NewStoreProvider instantiates a transient data storage provider backed by Memory
+func NewStoreProvider() *Provider {
+	logger.Debugf("constructing transient mem data storage provider")
+	return &Provider{}
+}
+
+// OpenStore creates a handle to the transient data store for the given ledger ID
+func (p *Provider) OpenStore(ledgerid string) (transientstore.Store, error) {
+	return newStore(), nil
+}
+
+// Close cleans up the provider
+func (p *Provider) Close() {
+}
-- 
2.20.1 (Apple Git-117)

