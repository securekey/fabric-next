diff a/core/ledger/kvledger/txmgmt/txmgr/lockbasedtxmgr/lockbased_txmgr.go b/core/ledger/kvledger/txmgmt/txmgr/lockbasedtxmgr/lockbased_txmgr.go	(rejected hunks)
@@ -8,9 +8,8 @@ package lockbasedtxmgr
 import (
 	"sync"
 
-	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
-
 	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/common/metrics"
 	"github.com/hyperledger/fabric/core/ledger"
 	"github.com/hyperledger/fabric/core/ledger/kvledger/bookkeeping"
 	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/privacyenabledstate"
@@ -18,8 +17,13 @@ import (
 	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/validator"
 	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/validator/valimpl"
 	"github.com/hyperledger/fabric/core/ledger/kvledger/txmgmt/version"
+	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
+	"github.com/hyperledger/fabric/core/ledger/util"
 	"github.com/hyperledger/fabric/protos/common"
 	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
+	"github.com/pkg/errors"
+	"github.com/uber-go/tally"
+	"golang.org/x/net/context"
 )
 
 var logger = flogging.MustGetLogger("lockbasedtxmgr")
@@ -27,40 +31,63 @@ var logger = flogging.MustGetLogger("lockbasedtxmgr")
 // LockBasedTxMgr a simple implementation of interface `txmgmt.TxMgr`.
 // This implementation uses a read-write lock to prevent conflicts between transaction simulation and committing
 type LockBasedTxMgr struct {
-	ledgerid        string
-	db              privacyenabledstate.DB
-	pvtdataPurgeMgr *pvtdataPurgeMgr
-	validator       validator.Validator
-	stateListeners  []ledger.StateListener
-	commitRWLock    sync.RWMutex
-	current         *current
+	ledgerid         string
+	db               privacyenabledstate.DB
+	pvtdataPurgeMgr  *pvtdataPurgeMgr
+	validator        validator.Validator
+	stateListeners   []ledger.StateListener
+	commitRWLock     sync.RWMutex
+	current          *update
+	StopWatch        tally.Stopwatch
+	StopWatchAccess  string
+	StopWatch1       tally.Stopwatch
+	StopWatch1Access string
+	btlPolicy        pvtdatapolicy.BTLPolicy
+
+	commitCh   chan *update
+	commitDone chan *ledger.BlockAndPvtData
+	shutdownCh chan struct{}
+	doneCh     chan struct{}
 }
 
-type current struct {
-	block     *common.Block
-	batch     *privacyenabledstate.UpdateBatch
-	listeners []ledger.StateListener
+type update struct {
+	blockAndPvtData *ledger.BlockAndPvtData
+	batch           *privacyenabledstate.UpdateBatch
+	listeners       []ledger.StateListener
+	commitDoneCh    chan struct{}
 }
 
-func (c *current) blockNum() uint64 {
-	return c.block.Header.Number
+func (c *update) blockNum() uint64 {
+	return c.blockAndPvtData.Block.Header.Number
 }
 
-func (c *current) maxTxNumber() uint64 {
-	return uint64(len(c.block.Data.Data)) - 1
+func (c *update) maxTxNumber() uint64 {
+	return uint64(len(c.blockAndPvtData.Block.Data.Data)) - 1
 }
 
 // NewLockBasedTxMgr constructs a new instance of NewLockBasedTxMgr
 func NewLockBasedTxMgr(ledgerid string, db privacyenabledstate.DB, stateListeners []ledger.StateListener,
-	btlPolicy pvtdatapolicy.BTLPolicy, bookkeepingProvider bookkeeping.Provider) (*LockBasedTxMgr, error) {
+	btlPolicy pvtdatapolicy.BTLPolicy, bookkeepingProvider bookkeeping.Provider, commitDone chan *ledger.BlockAndPvtData) (*LockBasedTxMgr, error) {
 	db.Open()
-	txmgr := &LockBasedTxMgr{ledgerid: ledgerid, db: db, stateListeners: stateListeners}
+	txmgr := &LockBasedTxMgr{
+		ledgerid:       ledgerid,
+		db:             db,
+		stateListeners: stateListeners,
+		commitCh:       make(chan *update),
+		commitDone:     commitDone,
+		shutdownCh:     make(chan struct{}),
+		doneCh:         make(chan struct{}),
+		btlPolicy:      btlPolicy,
+	}
+
 	pvtstatePurgeMgr, err := pvtstatepurgemgmt.InstantiatePurgeMgr(ledgerid, db, btlPolicy, bookkeepingProvider)
 	if err != nil {
 		return nil, err
 	}
 	txmgr.pvtdataPurgeMgr = &pvtdataPurgeMgr{pvtstatePurgeMgr, false}
-	txmgr.validator = valimpl.NewStatebasedValidator(txmgr, db)
+	txmgr.validator = valimpl.NewStatebasedValidator(ledgerid, txmgr, db)
+
+	go txmgr.committer()
 	return txmgr, nil
 }
 
@@ -84,37 +115,68 @@ func (txmgr *LockBasedTxMgr) NewTxSimulator(txid string) (ledger.TxSimulator, er
 	if err != nil {
 		return nil, err
 	}
+	stopWatch := metrics.RootScope.Timer("lockbasedtxmgr_NewTxSimulator_commitRWLock_RLock_wait_duration").Start()
 	txmgr.commitRWLock.RLock()
+	stopWatch.Stop()
+	txmgr.StopWatch1 = metrics.RootScope.Timer("lockbasedtxmgr_NewTxSimulator_commitRWLock_RLock_duration").Start()
+	txmgr.StopWatch1Access = "1"
 	return s, nil
 }
 
+// ValidateMVCC validates block for MVCC conflicts and phantom reads against committed data
+func (txmgr *LockBasedTxMgr) ValidateMVCC(ctx context.Context, block *common.Block, txFlags util.TxValidationFlags, filter util.TxFilter) error {
+	err := txmgr.validator.ValidateMVCC(ctx, block, txFlags, filter)
+	if err != nil {
+		return err
+	}
+	return nil
+}
+
 // ValidateAndPrepare implements method in interface `txmgmt.TxMgr`
 func (txmgr *LockBasedTxMgr) ValidateAndPrepare(blockAndPvtdata *ledger.BlockAndPvtData, doMVCCValidation bool) error {
-	block := blockAndPvtdata.Block
+	if !txmgr.waitForPreviousToFinish() {
+		return errors.New("shutdown has been requested")
+	}
+
 	logger.Debugf("Waiting for purge mgr to finish the background job of computing expirying keys for the block")
 	txmgr.pvtdataPurgeMgr.WaitForPrepareToFinish()
-	logger.Debugf("Validating new block with num trans = [%d]", len(block.Data.Data))
+
+	logger.Debugf("Validating new block %d with num trans = [%d]", blockAndPvtdata.Block.Header.Number, len(blockAndPvtdata.Block.Data.Data))
 	batch, err := txmgr.validator.ValidateAndPrepareBatch(blockAndPvtdata, doMVCCValidation)
 	if err != nil {
-		txmgr.reset()
 		return err
 	}
-	txmgr.current = &current{block: block, batch: batch}
-	if err := txmgr.invokeNamespaceListeners(); err != nil {
-		txmgr.reset()
+	current := update{blockAndPvtData: blockAndPvtdata, batch: batch, commitDoneCh:make(chan struct{})}
+	if err := txmgr.invokeNamespaceListeners(&current); err != nil {
 		return err
 	}
+	txmgr.current = &current
+
 	return nil
 }
 
-func (txmgr *LockBasedTxMgr) invokeNamespaceListeners() error {
+func (txmgr *LockBasedTxMgr) waitForPreviousToFinish() bool {
+	if txmgr.current == nil {
+		return true
+	}
+
+	select {
+	case <-txmgr.current.commitDoneCh:
+	case <-txmgr.doneCh:
+		return false // the committer goroutine is shutting down - no new commits should be done.
+	}
+
+	return true
+}
+
+func (txmgr *LockBasedTxMgr) invokeNamespaceListeners(c *update) error {
 	for _, listener := range txmgr.stateListeners {
-		stateUpdatesForListener := extractStateUpdates(txmgr.current.batch, listener.InterestedInNamespaces())
+		stateUpdatesForListener := extractStateUpdates(c.batch, listener.InterestedInNamespaces())
 		if len(stateUpdatesForListener) == 0 {
 			continue
 		}
-		txmgr.current.listeners = append(txmgr.current.listeners, listener)
-		if err := listener.HandleStateUpdates(txmgr.ledgerid, stateUpdatesForListener, txmgr.current.blockNum()); err != nil {
+		c.listeners = append(c.listeners, listener)
+		if err := listener.HandleStateUpdates(txmgr.ledgerid, stateUpdatesForListener, c.blockNum()); err != nil {
 			return err
 		}
 		logger.Debugf("Invoking listener for state changes:%s", listener)
@@ -124,57 +186,29 @@ func (txmgr *LockBasedTxMgr) invokeNamespaceListeners() error {
 
 // Shutdown implements method in interface `txmgmt.TxMgr`
 func (txmgr *LockBasedTxMgr) Shutdown() {
+
+	close(txmgr.doneCh)
+	<-txmgr.shutdownCh
+
 	txmgr.db.Close()
 }
 
 // Commit implements method in interface `txmgmt.TxMgr`
 func (txmgr *LockBasedTxMgr) Commit() error {
-	// When using the purge manager for the first block commit after peer start, the asynchronous function
-	// 'PrepareForExpiringKeys' is invoked in-line. However, for the subsequent blocks commits, this function is invoked
-	// in advance for the next block
-	if !txmgr.pvtdataPurgeMgr.usedOnce {
-		txmgr.pvtdataPurgeMgr.PrepareForExpiringKeys(txmgr.current.blockNum())
-		txmgr.pvtdataPurgeMgr.usedOnce = true
-	}
-	defer func() {
-		txmgr.clearCache()
-		txmgr.pvtdataPurgeMgr.PrepareForExpiringKeys(txmgr.current.blockNum() + 1)
-		logger.Debugf("Cleared version cache and launched the background routine for preparing keys to purge with the next block")
-		txmgr.reset()
-	}()
-
-	logger.Debugf("Committing updates to state database")
 	if txmgr.current == nil {
 		panic("validateAndPrepare() method should have been called before calling commit()")
 	}
 
-	if err := txmgr.pvtdataPurgeMgr.DeleteExpiredAndUpdateBookkeeping(
-		txmgr.current.batch.PvtUpdates, txmgr.current.batch.HashUpdates); err != nil {
-		return err
-	}
-
-	txmgr.commitRWLock.Lock()
-	defer txmgr.commitRWLock.Unlock()
-	logger.Debugf("Write lock acquired for committing updates to state database")
-	commitHeight := version.NewHeight(txmgr.current.blockNum(), txmgr.current.maxTxNumber())
-	if err := txmgr.db.ApplyPrivacyAwareUpdates(txmgr.current.batch, commitHeight); err != nil {
-		return err
-	}
-	logger.Debugf("Updates committed to state database")
-
-	// purge manager should be called (in this call the purge mgr removes the expiry entries from schedules) after committing to statedb
-	if err := txmgr.pvtdataPurgeMgr.BlockCommitDone(); err != nil {
-		return err
-	}
-	// In the case of error state listeners will not recieve this call - instead a peer panic is caused by the ledger upon receiveing
-	// an error from this function
-	txmgr.updateStateListeners()
+	txmgr.commitCh <- txmgr.current
 	return nil
 }
 
 // Rollback implements method in interface `txmgmt.TxMgr`
 func (txmgr *LockBasedTxMgr) Rollback() {
-	txmgr.reset()
+	if txmgr.current == nil {
+		panic("validateAndPrepare() method should have been called before calling rollback()")
+	}
+	txmgr.current = nil
 }
 
 // clearCache empty the cache maintained by the statedb implementation
