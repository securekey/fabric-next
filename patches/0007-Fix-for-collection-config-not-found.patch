From 1823f2c97eeaa18739e6a5b3d6b2cd207e8c709f Mon Sep 17 00:00:00 2001
From: Bob Stasyszyn <Bob.Stasyszyn@securekey.com>
Date: Wed, 12 Jun 2019 16:56:15 -0400
Subject: [PATCH] [BLOC-1513] Fix for collection config not found

The collection config package that is assembled by the endorser removes
configs for collections in which there was no write set and therefore
the error 'config for collection [xxx] not found' results. Thes commit
removes the dependency on the collection config package and uses the
collection config retriever to manage collection configs.

Signed-off-by: Bob Stasyszyn <Bob.Stasyszyn@securekey.com>
Change-Id: If27b3284c5b28c967feb552f5837ddc505131798
---
 Gopkg.lock                                    |  4 +-
 Gopkg.toml                                    |  2 +-
 core/chaincode/exectransaction_test.go        |  2 +-
 core/endorser/endorser.go                     | 29 +++++-
 .../statedb/statecouchdb/statecouchdb.go      |  2 +-
 core/ledger/util/couchdb/couchdb.go           | 34 +++++++
 core/ledger/util/couchdb/couchdb_test.go      | 48 ++++-----
 core/ledger/util/couchdb/couchdbutil.go       |  9 +-
 core/ledger/util/couchdb/couchdbutil_test.go  |  6 +-
 core/ledger/util/couchdb/metrics_test.go      |  2 +-
 extensions/endorser/api/endorser.go           | 27 +++++
 extensions/endorser/endorser.go               | 14 ++-
 extensions/endorser/endorser_test.go          | 27 ++++-
 extensions/gossip/api/gossipapi.go            |  6 +-
 .../cdbblkstorage/cdb_blkstorage_provider.go  | 10 +-
 .../pkg/collections/offledger/dcas/cas.go     | 21 ++--
 .../pkg/collections/offledger/dcas/dcas.go    | 24 ++++-
 .../dissemination/disseminationplan.go        |  5 +-
 .../offledger/retriever/olretriever.go        | 41 +++++++-
 .../offledger/storeprovider/olstore.go        | 53 +++++++---
 .../storeprovider/olstoreprovider.go          | 17 +++-
 .../storeprovider/store/cache/cache.go        | 11 +++
 .../store/couchdbstore/dbstore.go             | 32 ++++--
 .../store/couchdbstore/dbstore_provider.go    | 98 +++++++++++++++----
 .../pkg/collections/retriever/retriever.go    |  1 +
 .../storeprovider/storeprovider.go            |  4 +-
 .../fabric-peer-ext/pkg/config/config.go      | 10 +-
 .../fabric-peer-ext/pkg/endorser/endorser.go  | 78 ++++++++-------
 .../gossip/blockpublisher/blockpublisher.go   | 12 +--
 .../fabric-peer-ext/pkg/idstore/store_impl.go | 13 +--
 .../pkg/idstore/test_exports.go               | 22 ++---
 .../pkg/mocks/mockblockhandler.go             |  6 +-
 .../cdbpvtdatastore/store_impl.go             | 23 ++---
 .../cdbpvtdatastore/test_exports.go           | 20 ++--
 .../pkg/pvtdatastorage/common/collelgproc.go  | 11 ++-
 .../pkg/pvtdatastorage/store_impl.go          |  4 +-
 .../pkg/pvtdatastorage/test_exports.go        | 25 +++--
 .../fabric-peer-ext/pkg/roles/roles.go        |  2 +-
 .../pkg/testutil/ext_test_env.go              | 78 ++++++++++++++-
 39 files changed, 611 insertions(+), 222 deletions(-)
 create mode 100644 extensions/endorser/api/endorser.go

diff --git a/Gopkg.lock b/Gopkg.lock
index e7e31a69..b5c9bff6 100644
--- a/Gopkg.lock
+++ b/Gopkg.lock
@@ -729,7 +729,7 @@
   revision = "bea94bb476ccecfbd31b12ed493a971bdb8c904b"
 
 [[projects]]
-  digest = "1:b2a59318676b45d2b2a461e290d1edde9dd878b247c2e2a1b1d8e322945e019f"
+  digest = "1:2af3aeb5d098d72b09e268dfb269f99383d724344676b74c0f5f072b99850cee"
   name = "github.com/trustbloc/fabric-peer-ext"
   packages = [
     "pkg/blkstorage/cdbblkstorage",
@@ -777,7 +777,7 @@
     "pkg/transientstore/common",
   ]
   pruneopts = "NUT"
-  revision = "9b2d0053a5e40e93141576b7210ef021fe881852"
+  revision = "9b20d84ee0a4b89039086a3a2da103584e7ed1d8"
 
 [[projects]]
   digest = "1:3f3f2b36f76d1187ccf6640dd5bdbce43fd3c1a2cc0d747abc1e0de374d13e63"
diff --git a/Gopkg.toml b/Gopkg.toml
index 5791b96f..945cdf7b 100644
--- a/Gopkg.toml
+++ b/Gopkg.toml
@@ -17,7 +17,7 @@ noverify = [
 
 [[constraint]]
   name = "github.com/trustbloc/fabric-peer-ext"
-  revision = "9b2d0053a5e40e93141576b7210ef021fe881852"
+  revision = "9b20d84ee0a4b89039086a3a2da103584e7ed1d8"
 
 [[override]]
   name = "github.com/bluele/gcache"
diff --git a/core/chaincode/exectransaction_test.go b/core/chaincode/exectransaction_test.go
index 158fbf12..94781be1 100644
--- a/core/chaincode/exectransaction_test.go
+++ b/core/chaincode/exectransaction_test.go
@@ -198,7 +198,7 @@ func finitPeer(lis net.Listener, chainIDs ...string) {
 		requestTimeout := viper.GetDuration("ledger.state.couchDBConfig.requestTimeout")
 		createGlobalChangesDB := viper.GetBool("ledger.state.couchDBConfig.createGlobalChangesDB")
 
-		couchInstance, _ := couchdb.CreateCouchInstance(connectURL, username, password, maxRetries, maxRetriesOnStartup, requestTimeout, createGlobalChangesDB, &disabled.Provider{})
+		couchInstance, _ := couchdb.CreateCouchInstance1_4_1(connectURL, username, password, maxRetries, maxRetriesOnStartup, requestTimeout, createGlobalChangesDB, &disabled.Provider{})
 		db := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: chainID}
 		//drop the test database
 		db.DropDatabase()
diff --git a/core/endorser/endorser.go b/core/endorser/endorser.go
index e8b8d267..fa6ddb9e 100644
--- a/core/endorser/endorser.go
+++ b/core/endorser/endorser.go
@@ -23,8 +23,11 @@ import (
 	"github.com/hyperledger/fabric/core/common/ccprovider"
 	"github.com/hyperledger/fabric/core/common/validation"
 	"github.com/hyperledger/fabric/core/ledger"
+	"github.com/hyperledger/fabric/core/peer"
 	xendorser "github.com/hyperledger/fabric/extensions/endorser"
+	xendorserapi "github.com/hyperledger/fabric/extensions/endorser/api"
 	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset"
 	pb "github.com/hyperledger/fabric/protos/peer"
 	"github.com/hyperledger/fabric/protos/transientstore"
 	putils "github.com/hyperledger/fabric/protos/utils"
@@ -100,13 +103,18 @@ type Support interface {
 	GetLedgerHeight(channelID string) (uint64, error)
 }
 
+type rwSetFilter interface {
+	Filter(channelID string, pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error)
+}
+
 // Endorser provides the Endorser service ProcessProposal
 type Endorser struct {
 	distributePrivateData privateDataDistributor
 	s                     Support
 	PlatformRegistry      *platforms.Registry
 	PvtRWSetAssembler
-	Metrics *EndorserMetrics
+	Metrics     *EndorserMetrics
+	rwSetFilter rwSetFilter
 }
 
 // validateResult provides the result of endorseProposal verification
@@ -118,6 +126,16 @@ type validateResult struct {
 	resp    *pb.ProposalResponse
 }
 
+type ledgerProvider func(cid string) ledger.PeerLedger
+
+type qeProviderFactory struct {
+	getLedger ledgerProvider
+}
+
+func (q *qeProviderFactory) GetQueryExecutorProvider(channelID string) xendorserapi.QueryExecutorProvider {
+	return q.getLedger(channelID)
+}
+
 // NewEndorserServer creates and returns a new Endorser server instance.
 func NewEndorserServer(privDist privateDataDistributor, s Support, pr *platforms.Registry, metricsProv metrics.Provider) *Endorser {
 	e := &Endorser{
@@ -126,6 +144,11 @@ func NewEndorserServer(privDist privateDataDistributor, s Support, pr *platforms
 		PlatformRegistry:      pr,
 		PvtRWSetAssembler:     &rwSetAssembler{},
 		Metrics:               NewEndorserMetrics(metricsProv),
+		rwSetFilter: xendorser.NewCollRWSetFilter(
+			&qeProviderFactory{
+				getLedger: peer.GetLedger,
+			},
+			peer.BlockPublisher),
 	}
 	return e
 }
@@ -257,7 +280,6 @@ func (e *Endorser) SimulateProposal(txParams *ccprovider.TransactionParams, cid
 			return nil, nil, nil, nil, err
 		}
 
-		var collConfigs map[string]*common.CollectionConfigPackage
 		if simResult.PvtSimulationResults != nil {
 			if cid.Name == "lscc" {
 				// TODO: remove once we can store collection configuration outside of LSCC
@@ -285,11 +307,10 @@ func (e *Endorser) SimulateProposal(txParams *ccprovider.TransactionParams, cid
 			if err := e.distributePrivateData(txParams.ChannelID, txParams.TxID, pvtDataWithConfig, endorsedAt); err != nil {
 				return nil, nil, nil, nil, err
 			}
-			collConfigs = pvtDataWithConfig.CollectionConfigs
 		}
 
 		txParams.TXSimulator.Done()
-		pubSimRes, err := xendorser.FilterPubSimulationResults(collConfigs, simResult.PubSimulationResults)
+		pubSimRes, err := e.rwSetFilter.Filter(txParams.ChannelID, simResult.PubSimulationResults)
 		if err != nil {
 			return nil, nil, nil, nil, err
 		}
diff --git a/core/ledger/kvledger/txmgmt/statedb/statecouchdb/statecouchdb.go b/core/ledger/kvledger/txmgmt/statedb/statecouchdb/statecouchdb.go
index f335a213..4a103b7c 100644
--- a/core/ledger/kvledger/txmgmt/statedb/statecouchdb/statecouchdb.go
+++ b/core/ledger/kvledger/txmgmt/statedb/statecouchdb/statecouchdb.go
@@ -43,7 +43,7 @@ type VersionedDBProvider struct {
 func NewVersionedDBProvider(metricsProvider metrics.Provider) (*VersionedDBProvider, error) {
 	logger.Debugf("constructing CouchDB VersionedDBProvider")
 	couchDBDef := couchdb.GetCouchDBDefinition()
-	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := couchdb.CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, metricsProvider)
 	if err != nil {
 		return nil, err
diff --git a/core/ledger/util/couchdb/couchdb.go b/core/ledger/util/couchdb/couchdb.go
index e12239e2..7a896258 100644
--- a/core/ledger/util/couchdb/couchdb.go
+++ b/core/ledger/util/couchdb/couchdb.go
@@ -116,6 +116,40 @@ type QueryResult struct {
 	Attachments []*AttachmentInfo
 }
 
+// Config is a structure used to configure a CouchInstance.
+// NOTE: This struct is added in order to satisfy the compilation of fabric-peer-ext.
+type Config struct {
+	// Address is the hostname:port of the CouchDB database instance.
+	Address string
+	// Username is the username used to authenticate with CouchDB.  This username
+	// must have read and write access permissions.
+	Username string
+	// Password is the password for Username.
+	Password string
+	// MaxRetries is the maximum number of times to retry CouchDB operations on
+	// failure.
+	MaxRetries int
+	// MaxRetriesOnStartup is the maximum number of times to retry CouchDB operations on
+	// failure when initializing the ledger.
+	MaxRetriesOnStartup int
+	// RequestTimeout is the timeout used for CouchDB operations.
+	RequestTimeout time.Duration
+	// InternalQueryLimit is the maximum number of records to return internally
+	// when querying CouchDB.
+	InternalQueryLimit int
+	// MaxBatchUpdateSize is the maximum number of records to included in CouchDB
+	// bulk update operations.
+	MaxBatchUpdateSize int
+	// WarmIndexesAfterNBlocks is the number of blocks after which to warm any
+	// CouchDB indexes.
+	WarmIndexesAfterNBlocks int
+	// CreateGlobalChangesDB determines whether or not to create the "_global_changes"
+	// system database.
+	CreateGlobalChangesDB bool
+	// RedoLogPath is the directory where the CouchDB redo log files are stored.
+	RedoLogPath string
+}
+
 //CouchConnectionDef contains parameters
 type CouchConnectionDef struct {
 	URL                   string
diff --git a/core/ledger/util/couchdb/couchdb_test.go b/core/ledger/util/couchdb/couchdb_test.go
index 52edac4b..4deb08ef 100644
--- a/core/ledger/util/couchdb/couchdb_test.go
+++ b/core/ledger/util/couchdb/couchdb_test.go
@@ -35,7 +35,7 @@ var couchDBDef *CouchDBDef
 
 func cleanup(database string) error {
 	//create a new connection
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	if err != nil {
 		fmt.Println("Unexpected error", err)
@@ -258,7 +258,7 @@ func TestDBCreateSaveWithoutRevision(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -281,7 +281,7 @@ func TestDBCreateEnsureFullCommit(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -302,28 +302,28 @@ func TestDBCreateEnsureFullCommit(t *testing.T) {
 func TestDBBadDatabaseName(t *testing.T) {
 
 	//create a new instance and database object using a valid database name mixed case
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	_, dberr := CreateCouchDatabase(couchInstance, "testDB")
 	assert.Error(t, dberr, "Error should have been thrown for an invalid db name")
 
 	//create a new instance and database object using a valid database name letters and numbers
-	couchInstance, err = CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err = CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	_, dberr = CreateCouchDatabase(couchInstance, "test132")
 	assert.NoError(t, dberr, "Error when testing a valid database name")
 
 	//create a new instance and database object using a valid database name - special characters
-	couchInstance, err = CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err = CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	_, dberr = CreateCouchDatabase(couchInstance, "test1234~!@#$%^&*()[]{}.")
 	assert.Error(t, dberr, "Error should have been thrown for an invalid db name")
 
 	//create a new instance and database object using a invalid database name - too long	/*
-	couchInstance, err = CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err = CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	_, dberr = CreateCouchDatabase(couchInstance, "a12345678901234567890123456789012345678901234"+
@@ -338,7 +338,7 @@ func TestDBBadConnection(t *testing.T) {
 
 	//create a new instance and database object
 	//Limit the maxRetriesOnStartup to 3 in order to reduce time for the failure
-	_, err := CreateCouchInstance(badConnectURL, couchDBDef.Username, couchDBDef.Password,
+	_, err := CreateCouchInstance1_4_1(badConnectURL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, 3, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.Error(t, err, "Error should have been thrown for a bad connection")
 }
@@ -351,7 +351,7 @@ func TestBadDBCredentials(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	_, err = CreateCouchInstance(couchDBDef.URL, "fred", "fred",
+	_, err = CreateCouchInstance1_4_1(couchDBDef.URL, "fred", "fred",
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.Error(t, err, "Error should have been thrown for bad credentials")
 
@@ -381,7 +381,7 @@ func testDBCreateDatabaseAndPersist(t *testing.T, maxRetries int) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		maxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -600,12 +600,12 @@ func TestDBRequestTimeout(t *testing.T) {
 
 	//create a new instance and database object with a timeout that will fail
 	//Also use a maxRetriesOnStartup=3 to reduce the number of retries
-	_, err = CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	_, err = CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, 3, impossibleTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.Error(t, err, "Error should have been thown while trying to create a couchdb instance with a connection timeout")
 
 	//create a new instance and database object
-	_, err = CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	_, err = CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		-1, 3, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.Error(t, err, "Error should have been thrown while attempting to create a database")
 
@@ -619,7 +619,7 @@ func TestDBTimeoutConflictRetry(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, 3, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -659,7 +659,7 @@ func TestDBBadNumberOfRetries(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	_, err = CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	_, err = CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		-1, 3, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.Error(t, err, "Error should have been thrown while attempting to create a database")
 
@@ -673,7 +673,7 @@ func TestDBBadJSON(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -703,7 +703,7 @@ func TestPrefixScan(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -773,7 +773,7 @@ func TestDBSaveAttachment(t *testing.T) {
 	attachments = append(attachments, attachment)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -803,7 +803,7 @@ func TestDBDeleteDocument(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -838,7 +838,7 @@ func TestDBDeleteNonExistingDocument(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -887,7 +887,7 @@ func TestIndexOperations(t *testing.T) {
 	byteJSON10 := []byte(`{"_id":"10", "asset_name":"marble10","color":"white","size":10,"owner":"tom"}`)
 
 	//create a new instance and database object   --------------------------------------------------------
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -1146,7 +1146,7 @@ func TestRichQuery(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object   --------------------------------------------------------
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -1387,7 +1387,7 @@ func testBatchBatchOperations(t *testing.T, maxRetries int) {
 	defer cleanup(database)
 
 	//create a new instance and database object   --------------------------------------------------------
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -1588,7 +1588,7 @@ func TestDatabaseSecuritySettings(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new instance and database object   --------------------------------------------------------
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
@@ -1651,7 +1651,7 @@ func TestURLWithSpecialCharacters(t *testing.T) {
 	assert.Equal(t, "http://127.0.0.1:5984/testdb%2Bwith%2Bplus_sign/_index/designdoc/json/indexname", couchdbURL.String())
 
 	//create a new instance and database object   --------------------------------------------------------
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to create couch instance")
 	db := CouchDatabase{CouchInstance: couchInstance, DBName: database}
diff --git a/core/ledger/util/couchdb/couchdbutil.go b/core/ledger/util/couchdb/couchdbutil.go
index 9fef90fb..2d42b06a 100644
--- a/core/ledger/util/couchdb/couchdbutil.go
+++ b/core/ledger/util/couchdb/couchdbutil.go
@@ -32,8 +32,13 @@ var chainNameAllowedLength = 50
 var namespaceNameAllowedLength = 50
 var collectionNameAllowedLength = 50
 
-//CreateCouchInstance creates a CouchDB instance
-func CreateCouchInstance(couchDBConnectURL, id, pw string, maxRetries,
+//CreateCouchInstance should never be called by Fabric 1.4.1 code. It's added here so that fabric-peer-ext compiles
+func CreateCouchInstance(config *Config, metricsProvider metrics.Provider) (*CouchInstance, error) {
+	panic("not implemented")
+}
+
+//CreateCouchInstance1_4_1 creates a CouchDB instance using Fabric 1.4.1.
+func CreateCouchInstance1_4_1(couchDBConnectURL, id, pw string, maxRetries,
 	maxRetriesOnStartup int, connectionTimeout time.Duration, createGlobalChangesDB bool, metricsProvider metrics.Provider) (*CouchInstance, error) {
 
 	couchConf, err := CreateConnectionDefinition(couchDBConnectURL,
diff --git a/core/ledger/util/couchdb/couchdbutil_test.go b/core/ledger/util/couchdb/couchdbutil_test.go
index 5d1a9754..c1ccf007 100644
--- a/core/ledger/util/couchdb/couchdbutil_test.go
+++ b/core/ledger/util/couchdb/couchdbutil_test.go
@@ -21,7 +21,7 @@ func TestCreateCouchDBConnectionAndDB(t *testing.T) {
 	cleanup(database)
 	defer cleanup(database)
 	//create a new connection
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to CreateCouchInstance")
 
@@ -40,7 +40,7 @@ func TestNotCreateCouchGlobalChangesDB(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new connection
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 	assert.NoError(t, err, "Error when trying to CreateCouchInstance")
 
@@ -63,7 +63,7 @@ func TestCreateCouchDBSystemDBs(t *testing.T) {
 	defer cleanup(database)
 
 	//create a new connection
-	couchInstance, err := CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
+	couchInstance, err := CreateCouchInstance1_4_1(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
 		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
 
 	assert.NoError(t, err, "Error when trying to CreateCouchInstance")
diff --git a/core/ledger/util/couchdb/metrics_test.go b/core/ledger/util/couchdb/metrics_test.go
index 59c8c25d..d5962e78 100644
--- a/core/ledger/util/couchdb/metrics_test.go
+++ b/core/ledger/util/couchdb/metrics_test.go
@@ -22,7 +22,7 @@ func TestAPIProcessTimeMetric(t *testing.T) {
 	fakeHistogram.WithReturns(fakeHistogram)
 
 	// create a new couch instance
-	couchInstance, err := CreateCouchInstance(
+	couchInstance, err := CreateCouchInstance1_4_1(
 		couchDBDef.URL,
 		couchDBDef.Username,
 		couchDBDef.Password,
diff --git a/extensions/endorser/api/endorser.go b/extensions/endorser/api/endorser.go
new file mode 100644
index 00000000..9a9199ec
--- /dev/null
+++ b/extensions/endorser/api/endorser.go
@@ -0,0 +1,27 @@
+/*
+Copyright SecureKey Technologies Inc. All Rights Reserved.
+
+SPDX-License-Identifier: Apache-2.0
+*/
+
+package api
+
+import (
+	"github.com/hyperledger/fabric/core/ledger"
+	xgossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
+)
+
+// QueryExecutorProvider returns a query executor
+type QueryExecutorProvider interface {
+	NewQueryExecutor() (ledger.QueryExecutor, error)
+}
+
+// QueryExecutorProviderFactory returns a query executor provider for a given channel
+type QueryExecutorProviderFactory interface {
+	GetQueryExecutorProvider(channelID string) QueryExecutorProvider
+}
+
+// BlockPublisherProvider returns a block publisher for a given channel
+type BlockPublisherProvider interface {
+	ForChannel(channelID string) xgossipapi.BlockPublisher
+}
diff --git a/extensions/endorser/endorser.go b/extensions/endorser/endorser.go
index 79a72fb1..0e034474 100644
--- a/extensions/endorser/endorser.go
+++ b/extensions/endorser/endorser.go
@@ -7,12 +7,18 @@ SPDX-License-Identifier: Apache-2.0
 package endorser
 
 import (
-	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/extensions/endorser/api"
 	"github.com/hyperledger/fabric/protos/ledger/rwset"
 	extendorser "github.com/trustbloc/fabric-peer-ext/pkg/endorser"
 )
 
-// FilterPubSimulationResults filters the public simulation results and returns the filtered results or error.
-func FilterPubSimulationResults(collConfigs map[string]*common.CollectionConfigPackage, pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error) {
-	return extendorser.FilterPubSimulationResults(collConfigs, pubSimulationResults)
+// CollRWSetFilter filters out all off-ledger (including transient data) read-write sets from the simulation results
+// so that they won't be included in the block.
+type CollRWSetFilter interface {
+	Filter(channelID string, pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error)
+}
+
+// NewCollRWSetFilter returns a new collection RW set filter
+func NewCollRWSetFilter(qepf api.QueryExecutorProviderFactory, bpp api.BlockPublisherProvider) CollRWSetFilter {
+	return extendorser.NewCollRWSetFilter(qepf, bpp)
 }
diff --git a/extensions/endorser/endorser_test.go b/extensions/endorser/endorser_test.go
index c5a8741e..172be735 100644
--- a/extensions/endorser/endorser_test.go
+++ b/extensions/endorser/endorser_test.go
@@ -9,14 +9,37 @@ package endorser
 import (
 	"testing"
 
-	"github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/extensions/endorser/api"
+	xgossipapi "github.com/hyperledger/fabric/extensions/gossip/api"
 	"github.com/hyperledger/fabric/protos/ledger/rwset"
 	"github.com/stretchr/testify/assert"
+	"github.com/stretchr/testify/require"
+)
+
+const (
+	channelID = "testchannel"
 )
 
 func TestFilterPubSimulationResults(t *testing.T) {
+	f := NewCollRWSetFilter(&mockQueryExecutorProviderFactory{}, &mockBlockPublisherProvider{})
+	require.NotNil(t, f)
+
 	pubSimulationResults := &rwset.TxReadWriteSet{}
-	p, err := FilterPubSimulationResults(map[string]*common.CollectionConfigPackage{}, pubSimulationResults)
+	p, err := f.Filter(channelID, pubSimulationResults)
 	assert.NoError(t, err)
 	assert.Equal(t, pubSimulationResults, p)
 }
+
+type mockQueryExecutorProviderFactory struct {
+}
+
+func (m *mockQueryExecutorProviderFactory) GetQueryExecutorProvider(channelID string) api.QueryExecutorProvider {
+	return nil
+}
+
+type mockBlockPublisherProvider struct {
+}
+
+func (m *mockBlockPublisherProvider) ForChannel(channelID string) xgossipapi.BlockPublisher {
+	return nil
+}
diff --git a/extensions/gossip/api/gossipapi.go b/extensions/gossip/api/gossipapi.go
index 6b0b88f9..a53afea5 100644
--- a/extensions/gossip/api/gossipapi.go
+++ b/extensions/gossip/api/gossipapi.go
@@ -16,13 +16,13 @@ import (
 type ConfigUpdateHandler func(blockNum uint64, configUpdate *cb.ConfigUpdate) error
 
 // WriteHandler handles a KV write
-type WriteHandler func(blockNum uint64, txID string, namespace string, kvWrite *kvrwset.KVWrite) error
+type WriteHandler func(blockNum uint64, channelID, txID, namespace string, kvWrite *kvrwset.KVWrite) error
 
 // ReadHandler handles a KV read
-type ReadHandler func(blockNum uint64, txID string, namespace string, kvRead *kvrwset.KVRead) error
+type ReadHandler func(blockNum uint64, channelID, txID, namespace string, kvRead *kvrwset.KVRead) error
 
 // ChaincodeEventHandler handles a chaincode event
-type ChaincodeEventHandler func(blockNum uint64, txID string, event *pb.ChaincodeEvent) error
+type ChaincodeEventHandler func(blockNum uint64, channelID, txID string, event *pb.ChaincodeEvent) error
 
 // ChaincodeUpgradeHandler handles chaincode upgrade events
 type ChaincodeUpgradeHandler func(blockNum uint64, txID string, chaincodeName string) error
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage_provider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage_provider.go
index 2f88a44f..3eb86e9f 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage_provider.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/blkstorage/cdbblkstorage/cdb_blkstorage_provider.go
@@ -9,13 +9,14 @@ package cdbblkstorage
 import (
 	"strings"
 
-	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
+	"github.com/hyperledger/fabric/core/ledger"
 
 	"github.com/hyperledger/fabric/common/flogging"
 	"github.com/hyperledger/fabric/common/ledger/blkstorage"
 	"github.com/hyperledger/fabric/common/metrics/disabled"
 	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
 	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/roles"
 )
 
 var logger = flogging.MustGetLogger("cdbblkstorage")
@@ -32,11 +33,10 @@ type CDBBlockstoreProvider struct {
 }
 
 // NewProvider creates a new CouchDB BlockStoreProvider
-func NewProvider(indexConfig *blkstorage.IndexConfig) (blkstorage.BlockStoreProvider, error) {
+func NewProvider(indexConfig *blkstorage.IndexConfig, ledgerconfig *ledger.Config) (blkstorage.BlockStoreProvider, error) {
 	logger.Debugf("constructing CouchDB block storage provider")
-	couchDBDef := couchdb.GetCouchDBDefinition()
-	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
-		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	couchDBConfig := ledgerconfig.StateDB.CouchDB
+	couchInstance, err := couchdb.CreateCouchInstance(couchDBConfig, &disabled.Provider{})
 	if err != nil {
 		return nil, errors.WithMessage(err, "obtaining CouchDB instance failed")
 	}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/cas.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/cas.go
index 986f4bb0..c00ab006 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/cas.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/cas.go
@@ -15,20 +15,16 @@ import (
 
 // GetCASKey returns the content-addressable key for the given content.
 func GetCASKey(content []byte) string {
-	address := calculateAddress(content)
-
-	// Address above is as per CAS spec(sha256 hash + base64 URL encoding),
-	// however since fabric/couchdb doesn't support keys that start with _
-	// we have to do additional transformation
-	return base58.Encode(address)
-}
-
-func calculateAddress(content []byte) []byte {
 	hash := getHash(content)
 	buf := make([]byte, base64.URLEncoding.EncodedLen(len(hash)))
 	base64.URLEncoding.Encode(buf, hash)
+	return string(buf)
+}
 
-	return buf
+// GetFabricCASKey returns the content-addressable key for the given content,
+// encoded in base58 so that it may be used as a key in Fabric.
+func GetFabricCASKey(content []byte) string {
+	return Base58Encode(GetCASKey(content))
 }
 
 // getHash will compute the hash for the supplied bytes using SHA256
@@ -39,3 +35,8 @@ func getHash(bytes []byte) []byte {
 	h.Write(bytes) //nolint
 	return h.Sum(nil)
 }
+
+// Base58Encode encodes the given string in base 58
+func Base58Encode(s string) string {
+	return base58.Encode([]byte(s))
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/dcas.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/dcas.go
index a83cfeb9..c715d179 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/dcas.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dcas/dcas.go
@@ -31,13 +31,27 @@ func Decorator(key *storeapi.Key, value *storeapi.ExpiringValue) (*storeapi.Key,
 		return nil, nil, err
 	}
 
-	if dcasKey == key.Key {
-		return key, value, nil
+	// The key needs to be base58 encoded since Fabric doesn't allow
+	// certain characters to be used in the key.
+	newKey := &storeapi.Key{
+		EndorsedAtTxID: key.EndorsedAtTxID,
+		Namespace:      key.Namespace,
+		Collection:     key.Collection,
+		Key:            Base58Encode(dcasKey),
 	}
 
-	newKey := *key
-	newKey.Key = dcasKey
-	return &newKey, value, nil
+	return newKey, value, nil
+}
+
+// KeyDecorator is an off-ledger decorator that ensures the given key is base58 encoded
+// since Fabric doesn't allow certain characters to be used in the key.
+func KeyDecorator(key *storeapi.Key) (*storeapi.Key, error) {
+	return &storeapi.Key{
+		EndorsedAtTxID: key.EndorsedAtTxID,
+		Namespace:      key.Namespace,
+		Collection:     key.Collection,
+		Key:            Base58Encode(key.Key),
+	}, nil
 }
 
 func validateCASKey(key string, value []byte) (string, error) {
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminationplan.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminationplan.go
index 6b88752f..c27e8a2c 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminationplan.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/dissemination/disseminationplan.go
@@ -86,10 +86,7 @@ func validateAll(collType cb.CollectionType, kvRWSet *kvrwset.KVRWSet) error {
 }
 
 func validate(collType cb.CollectionType, ws *kvrwset.KVWrite) error {
-	if ws.Value == nil {
-		return errors.Errorf("attempt to store nil value for key [%s]", ws.Key)
-	}
-	if collType == cb.CollectionType_COL_DCAS {
+	if collType == cb.CollectionType_COL_DCAS && ws.Value != nil {
 		expectedKey := dcas.GetCASKey(ws.Value)
 		if ws.Key != expectedKey {
 			return errors.Errorf("invalid CAS key [%s] - the key should be the hash of the value", ws.Key)
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever/olretriever.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever/olretriever.go
index b6a53a63..96e0501e 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever/olretriever.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/retriever/olretriever.go
@@ -40,12 +40,16 @@ type support interface {
 // Validator is a key/value validator
 type Validator func(txID, ns, coll, key string, value []byte) error
 
+// KeyDecorator allows for modification of the provided key
+type KeyDecorator func(key *storeapi.Key) (*storeapi.Key, error)
+
 // Provider is a collection data data provider.
 type Provider struct {
 	support
 	storeForChannel func(channelID string) olapi.Store
 	gossipAdapter   func() supportapi.GossipAdapter
 	validators      map[cb.CollectionType]Validator
+	keyDecorators   map[cb.CollectionType]KeyDecorator
 }
 
 // Option is a provider option
@@ -58,6 +62,13 @@ func WithValidator(collType cb.CollectionType, validator Validator) Option {
 	}
 }
 
+// WithKeyDecorator sets the key decorator
+func WithKeyDecorator(collType cb.CollectionType, decorator KeyDecorator) Option {
+	return func(p *Provider) {
+		p.keyDecorators[collType] = decorator
+	}
+}
+
 // NewProvider returns a new collection data provider
 func NewProvider(storeProvider func(channelID string) olapi.Store, support support, gossipProvider func() supportapi.GossipAdapter, opts ...Option) olapi.Provider {
 	p := &Provider{
@@ -65,6 +76,7 @@ func NewProvider(storeProvider func(channelID string) olapi.Store, support suppo
 		storeForChannel: storeProvider,
 		gossipAdapter:   gossipProvider,
 		validators:      make(map[cb.CollectionType]Validator),
+		keyDecorators:   make(map[cb.CollectionType]KeyDecorator),
 	}
 
 	// Apply options
@@ -84,6 +96,7 @@ func (p *Provider) RetrieverForChannel(channelID string) olapi.Retriever {
 		reqMgr:        requestmgr.Get(channelID),
 		resolvers:     make(map[collKey]resolver),
 		validators:    p.validators,
+		keyDecorators: p.keyDecorators,
 	}
 
 	// Add a handler so that we can remove the resolver for a chaincode that has been upgraded
@@ -119,6 +132,7 @@ type retriever struct {
 	lock          sync.RWMutex
 	reqMgr        requestmgr.RequestMgr
 	validators    map[cb.CollectionType]Validator
+	keyDecorators map[cb.CollectionType]KeyDecorator
 }
 
 // GetData gets the values for the data item
@@ -189,9 +203,18 @@ func (r *retriever) GetDataMultipleKeys(ctxt context.Context, key *storeapi.Mult
 }
 
 func (r *retriever) getMultipleKeysFromLocal(key *storeapi.MultiKey) (storeapi.ExpiringValues, error) {
+	decorateKey, err := r.getKeyDecorator(key.Namespace, key.Collection)
+	if err != nil {
+		return nil, err
+	}
+
 	localValues := make(storeapi.ExpiringValues, len(key.Keys))
 	for i, k := range key.Keys {
-		value, retrieveErr := r.store.GetData(storeapi.NewKey(key.EndorsedAtTxID, key.Namespace, key.Collection, k))
+		lkey, e := getKey(decorateKey, key.EndorsedAtTxID, key.Namespace, key.Collection, k)
+		if e != nil {
+			return nil, e
+		}
+		value, retrieveErr := r.store.GetData(lkey)
 		if retrieveErr != nil {
 			logger.Warningf("[%s] Error getting data from local store for [%s]: %s", r.channelID, key, retrieveErr)
 			return nil, errors.WithMessagef(retrieveErr, "unable to get data for channel [%s] and [%s]", r.channelID, key)
@@ -201,6 +224,22 @@ func (r *retriever) getMultipleKeysFromLocal(key *storeapi.MultiKey) (storeapi.E
 	return localValues, nil
 }
 
+func (r *retriever) getKeyDecorator(ns, coll string) (KeyDecorator, error) {
+	collConfig, err := r.Config(r.channelID, ns, coll)
+	if err != nil {
+		return nil, err
+	}
+	return r.keyDecorators[collConfig.Type], nil
+}
+
+func getKey(decorateKey KeyDecorator, txID, ns, coll, k string) (*storeapi.Key, error) {
+	key := storeapi.NewKey(txID, ns, coll, k)
+	if decorateKey == nil {
+		return key, nil
+	}
+	return decorateKey(key)
+}
+
 func getMissingKeyIndexes(values []*storeapi.ExpiringValue) []int {
 	var missingIndexes []int
 	for i, v := range values {
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstore.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstore.go
index 50cd2246..703763e1 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstore.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstore.go
@@ -16,6 +16,7 @@ import (
 	mspmgmt "github.com/hyperledger/fabric/msp/mgmt"
 	"github.com/hyperledger/fabric/protos/common"
 	cb "github.com/hyperledger/fabric/protos/common"
+	"github.com/hyperledger/fabric/protos/ledger/rwset/kvrwset"
 	pb "github.com/hyperledger/fabric/protos/transientstore"
 	"github.com/pkg/errors"
 	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api"
@@ -159,8 +160,13 @@ func (s *store) persistColl(txID string, ns string, collConfigPkgs map[string]*c
 	}
 
 	for _, kv := range batch {
-		logger.Debugf("[%s] Putting key [%s:%s:%s] in Tx [%s]", s.channelID, ns, collRWSet.CollectionName, kv.Key, kv.TxID)
-		s.cache.Put(ns, collRWSet.CollectionName, kv.Key, kv.Value)
+		if kv.Value != nil {
+			logger.Infof("[%s] Putting key [%s:%s:%s] in Tx [%s]", s.channelID, ns, collRWSet.CollectionName, kv.Key, kv.TxID)
+			s.cache.Put(ns, collRWSet.CollectionName, kv.Key, kv.Value)
+		} else {
+			logger.Infof("[%s] Deleting key [%s:%s:%s]", s.channelID, ns, collRWSet.CollectionName, kv.Key)
+			s.cache.Delete(ns, collRWSet.CollectionName, kv.Key)
+		}
 	}
 
 	return nil
@@ -214,25 +220,36 @@ func (s *store) getDataMultipleKeys(txID, ns, coll string, keys ...string) (stor
 
 func (s *store) createBatch(txID, ns string, config *cb.StaticCollectionConfig, collRWSet *rwsetutil.CollPvtRwSet, expiryTime time.Time) ([]*api.KeyValue, error) {
 	var batch []*api.KeyValue
-	for _, wSet := range collRWSet.KvRwSet.Writes {
-		if wSet.IsDelete {
-			return nil, errors.Errorf("[%s] Attempt to delete key [%s] in collection [%s:%s]", s.channelID, wSet.Key, ns, collRWSet.CollectionName)
-		}
-
-		key := storeapi.NewKey(txID, ns, collRWSet.CollectionName, wSet.Key)
-		value := &storeapi.ExpiringValue{
-			Value:  wSet.Value,
-			Expiry: expiryTime,
+	for _, w := range collRWSet.KvRwSet.Writes {
+		kv, err := s.newKeyValue(txID, ns, config, expiryTime, w)
+		if err != nil {
+			return nil, err
 		}
+		batch = append(batch, kv)
+	}
+	return batch, nil
+}
 
-		key, value, err := s.decorate(config, key, value)
+func (s *store) newKeyValue(txID, ns string, config *cb.StaticCollectionConfig, expiryTime time.Time, w *kvrwset.KVWrite) (*api.KeyValue, error) {
+	key := storeapi.NewKey(txID, ns, config.Name, w.Key)
+	if w.IsDelete {
+		dKey, err := s.decorateKey(config, key)
 		if err != nil {
 			return nil, err
 		}
+		return &api.KeyValue{Key: dKey.Key}, nil
+	}
 
-		batch = append(batch, api.NewKeyValue(key.Key, value.Value, txID, value.Expiry))
+	dKey, value, err := s.decorate(config, key,
+		&storeapi.ExpiringValue{
+			Value:  w.Value,
+			Expiry: expiryTime,
+		},
+	)
+	if err != nil {
+		return nil, err
 	}
-	return batch, nil
+	return api.NewKeyValue(dKey.Key, value.Value, txID, value.Expiry), nil
 }
 
 func (s *store) isAuthorized(ns string, config *common.StaticCollectionConfig) (bool, error) {
@@ -305,6 +322,14 @@ func (s *store) decorate(config *cb.StaticCollectionConfig, key *storeapi.Key, v
 	return cfg.decorator(key, value)
 }
 
+func (s *store) decorateKey(config *cb.StaticCollectionConfig, key *storeapi.Key) (*storeapi.Key, error) {
+	cfg, ok := s.collConfigs[config.Type]
+	if !ok || cfg.keyDecorator == nil {
+		return key, nil
+	}
+	return cfg.keyDecorator(key)
+}
+
 func (s *store) collTypeSupported(collType cb.CollectionType) bool {
 	_, ok := s.collConfigs[collType]
 	return ok
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstoreprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstoreprovider.go
index 0b94ea9e..c6c2290f 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstoreprovider.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/olstoreprovider.go
@@ -35,18 +35,29 @@ func WithCollectionType(collType common.CollectionType, opts ...CollOption) Opti
 	}
 }
 
-// Decorator allows the key/value to be modified before being persisted
+// Decorator allows the key/value to be modified/validated before being persisted
 type Decorator func(key *storeapi.Key, value *storeapi.ExpiringValue) (*storeapi.Key, *storeapi.ExpiringValue, error)
 
-// WithDecorator sets a decorator for a collection type allowing the key/value to be modified before being persisted
+// WithDecorator sets a decorator for a collection type allowing the key/value to be validated/modified before being persisted
 func WithDecorator(decorator Decorator) CollOption {
 	return func(c *collTypeConfig) {
 		c.decorator = decorator
 	}
 }
 
+// KeyDecorator allows the key to be modified/validated
+type KeyDecorator func(key *storeapi.Key) (*storeapi.Key, error)
+
+// WithKeyDecorator sets a key decorator for a collection type allowing the key to be validated/modified
+func WithKeyDecorator(decorator KeyDecorator) CollOption {
+	return func(c *collTypeConfig) {
+		c.keyDecorator = decorator
+	}
+}
+
 type collTypeConfig struct {
-	decorator Decorator
+	decorator    Decorator
+	keyDecorator KeyDecorator
 }
 
 // New returns a store provider factory
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache/cache.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache/cache.go
index abaad49c..0113daed 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache/cache.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/cache/cache.go
@@ -78,6 +78,17 @@ func (c *Cache) Put(ns, coll, key string, value *api.Value) {
 	}
 }
 
+// Delete deletes the given key.
+func (c *Cache) Delete(ns, coll, key string) {
+	cKey := cacheKey{
+		namespace:  ns,
+		collection: coll,
+		key:        key,
+	}
+	logger.Debugf("[%s] Removing key [%s]", c.channelID, cKey)
+	c.cache.Remove(cKey)
+}
+
 // Get returns the values for the given keys
 func (c *Cache) Get(ns, coll, key string) (*api.Value, error) {
 	cKey := cacheKey{
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore.go
index 9b0fe525..3c80ee40 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore.go
@@ -56,10 +56,9 @@ func newDBStore(db *couchdb.CouchDatabase, dbName string) *dbstore {
 //-----------------Interface implementation functions--------------------//
 // AddKey adds dataModel to db
 func (s *dbstore) Put(keyVal ...*api.KeyValue) error {
-	docs := make([]*couchdb.CouchDoc, 0)
+	var docs []*couchdb.CouchDoc
 	for _, kv := range keyVal {
-
-		dataDoc, err := createCouchDoc(string(encodeKey(kv.Key, time.Time{})), kv.Value)
+		dataDoc, err := s.createCouchDoc(string(encodeKey(kv.Key, time.Time{})), kv.Value)
 		if err != nil {
 			return err
 		}
@@ -68,6 +67,11 @@ func (s *dbstore) Put(keyVal ...*api.KeyValue) error {
 		}
 	}
 
+	if len(docs) == 0 {
+		logger.Debugf("[%s] Nothing to do", s.dbName)
+		return nil
+	}
+
 	_, err := s.db.BatchUpdateDocuments(docs)
 	if nil != err {
 		return errors.WithMessage(err, fmt.Sprintf("BatchUpdateDocuments failed for [%d] documents", len(docs)))
@@ -119,7 +123,7 @@ func (s *dbstore) DeleteExpiredKeys() error {
 	docs := make([]*couchdb.CouchDoc, 0)
 	docIDs := make([]string, 0)
 	for _, doc := range data {
-		updateDoc := &dataModel{ID: doc.ID, Data: doc.Data, TxnID: doc.TxnID, Expiry: doc.Expiry, Rev: doc.Rev, Deleted: true}
+		updateDoc := &dataModel{ID: doc.ID, Rev: doc.Rev, Deleted: true}
 		jsonBytes, err := json.Marshal(updateDoc)
 		if err != nil {
 			return err
@@ -175,8 +179,24 @@ func fetchData(db *couchdb.CouchDatabase, key string) (*dataModel, error) {
 	return &data, nil
 }
 
-func createCouchDoc(key string, value *api.Value) (*couchdb.CouchDoc, error) {
-	data := &dataModel{ID: key, Data: string(value.Value), TxnID: value.TxID, Expiry: value.ExpiryTime.UnixNano() / int64(time.Millisecond)}
+func (s *dbstore) createCouchDoc(key string, value *api.Value) (*couchdb.CouchDoc, error) {
+	var data *dataModel
+	if value == nil {
+		logger.Debugf("[%s] Deleting key [%s]", s.dbName, key)
+
+		// Get the revision on the current doc
+		current, err := fetchData(s.db, string(encodeKey(key, time.Time{})))
+		if err != nil {
+			return nil, errors.Wrapf(err, "Failed to load key [%s] from db", key)
+		}
+		if current == nil {
+			logger.Debugf("[%s] Current key not found to delete [%s]", s.dbName, key)
+			return nil, nil
+		}
+		data = &dataModel{ID: key, Rev: current.Rev, Deleted: true}
+	} else {
+		data = &dataModel{ID: key, Data: string(value.Value), TxnID: value.TxID, Expiry: value.ExpiryTime.UnixNano() / int64(time.Millisecond)}
+	}
 
 	jsonBytes, err := json.Marshal(data)
 	if err != nil {
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore_provider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore_provider.go
index bf4391ed..d7807a75 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore_provider.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/couchdbstore/dbstore_provider.go
@@ -7,11 +7,14 @@ package couchdbstore
 
 import (
 	"fmt"
+	"path/filepath"
 	"sync"
 	"time"
 
 	"github.com/hyperledger/fabric/common/metrics/disabled"
+	coreconfig "github.com/hyperledger/fabric/core/config"
 	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
+	"github.com/spf13/viper"
 	"github.com/trustbloc/fabric-peer-ext/pkg/collections/offledger/storeprovider/store/api"
 	"github.com/trustbloc/fabric-peer-ext/pkg/config"
 )
@@ -34,6 +37,7 @@ const (
 // CouchDBProvider provides an handle to a db
 type CouchDBProvider struct {
 	couchInstance *couchdb.CouchInstance
+	cimutex       sync.RWMutex
 	stores        map[string]*dbstore
 	mutex         sync.RWMutex
 	done          chan struct{}
@@ -42,24 +46,10 @@ type CouchDBProvider struct {
 
 // NewDBProvider creates a CouchDB Provider
 func NewDBProvider() *CouchDBProvider {
-	couchDBDef := couchdb.GetCouchDBDefinition()
-
-	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
-		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
-	if err != nil {
-		logger.Error(err)
-		return nil
-	}
-
-	p := &CouchDBProvider{
-		couchInstance: couchInstance,
-		done:          make(chan struct{}),
-		stores:        make(map[string]*dbstore),
+	return &CouchDBProvider{
+		done:   make(chan struct{}, 1),
+		stores: make(map[string]*dbstore),
 	}
-
-	p.periodicPurge()
-
-	return p
 }
 
 //GetDB based on ns%coll
@@ -78,7 +68,12 @@ func (p *CouchDBProvider) GetDB(ns, coll string) (api.DB, error) {
 	defer p.mutex.Unlock()
 
 	if !ok {
-		db, err := couchdb.CreateCouchDatabase(p.couchInstance, dbName)
+		ci, err := p.getCouchInstance()
+		if err != nil {
+			logger.Error(err)
+			return nil, err
+		}
+		db, err := couchdb.CreateCouchDatabase(ci, dbName)
 		if nil != err {
 			logger.Error(err)
 			return nil, nil
@@ -106,6 +101,37 @@ func (p *CouchDBProvider) Close() {
 	}
 }
 
+func (p *CouchDBProvider) getCouchInstance() (*couchdb.CouchInstance, error) {
+	p.cimutex.RLock()
+	ci := p.couchInstance
+	p.cimutex.RUnlock()
+
+	if ci != nil {
+		return ci, nil
+	}
+
+	return p.createCouchInstance()
+}
+
+func (p *CouchDBProvider) createCouchInstance() (*couchdb.CouchInstance, error) {
+	p.cimutex.Lock()
+	defer p.cimutex.Unlock()
+
+	if p.couchInstance != nil {
+		return p.couchInstance, nil
+	}
+
+	var err error
+	p.couchInstance, err = couchdb.CreateCouchInstance(getCouchDBConfig(), &disabled.Provider{})
+	if err != nil {
+		return nil, err
+	}
+
+	p.periodicPurge()
+
+	return p.couchInstance, nil
+}
+
 // periodicPurge goroutine to purge dataModel based on config interval time
 func (p *CouchDBProvider) periodicPurge() {
 	ticker := time.NewTicker(config.GetOLCollExpirationCheckInterval())
@@ -143,3 +169,39 @@ func (p *CouchDBProvider) getStores() []*dbstore {
 func dbName(ns, coll string) string {
 	return fmt.Sprintf("%s$%s", ns, coll)
 }
+
+// getCouchDBConfig return the couchdb config
+// TODO The ledgerconfig can't be passed to offledger provider as cscc calls the createChain which inturn initiates
+// CollectionDataStoreFactory(https://github.com/trustbloc/fabric-mod/blob/f195099d41db44623724131f2f487474707e84f2/core/peer/peer.go#L471).
+// More over this is using state couchdb configurations. Need to have configs specific to feature/functionality(blockstorage/offledger).
+// Created an issue https://github.com/trustbloc/fabric-peer-ext/issues/149. Also, added this as private function to avoid access from external packages.
+func getCouchDBConfig() *couchdb.Config {
+	// set defaults
+	warmAfterNBlocks := 1
+	if viper.IsSet("ledger.state.couchDBConfig.warmIndexesAfterNBlocks") {
+		warmAfterNBlocks = viper.GetInt("ledger.state.couchDBConfig.warmIndexesAfterNBlocks")
+	}
+	internalQueryLimit := 1000
+	if viper.IsSet("ledger.state.couchDBConfig.internalQueryLimit") {
+		internalQueryLimit = viper.GetInt("ledger.state.couchDBConfig.internalQueryLimit")
+	}
+	maxBatchUpdateSize := 500
+	if viper.IsSet("ledger.state.couchDBConfig.maxBatchUpdateSize") {
+		maxBatchUpdateSize = viper.GetInt("ledger.state.couchDBConfig.maxBatchUpdateSize")
+	}
+	rootFSPath := filepath.Join(coreconfig.GetPath("peer.fileSystemPath"), "ledgersData")
+
+	return &couchdb.Config{
+		Address:                 viper.GetString("ledger.state.couchDBConfig.couchDBAddress"),
+		Username:                viper.GetString("ledger.state.couchDBConfig.username"),
+		Password:                viper.GetString("ledger.state.couchDBConfig.password"),
+		MaxRetries:              viper.GetInt("ledger.state.couchDBConfig.maxRetries"),
+		MaxRetriesOnStartup:     viper.GetInt("ledger.state.couchDBConfig.maxRetriesOnStartup"),
+		RequestTimeout:          viper.GetDuration("ledger.state.couchDBConfig.requestTimeout"),
+		InternalQueryLimit:      internalQueryLimit,
+		MaxBatchUpdateSize:      maxBatchUpdateSize,
+		WarmIndexesAfterNBlocks: warmAfterNBlocks,
+		CreateGlobalChangesDB:   viper.GetBool("ledger.state.couchDBConfig.createGlobalChangesDB"),
+		RedoLogPath:             filepath.Join(rootFSPath, "couchdbRedoLogs"),
+	}
+}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/retriever.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/retriever.go
index 79d82e39..3272908c 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/retriever.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/retriever/retriever.go
@@ -119,5 +119,6 @@ var getTransientDataProvider = func(storeProvider func(channelID string) tdataap
 var getOffLedgerProvider = func(storeProvider func(channelID string) olapi.Store, support Support, gossipProvider func() supportapi.GossipAdapter) olapi.Provider {
 	return olretriever.NewProvider(storeProvider, support, gossipProvider,
 		olretriever.WithValidator(cb.CollectionType_COL_DCAS, dcas.Validator),
+		olretriever.WithKeyDecorator(cb.CollectionType_COL_DCAS, dcas.KeyDecorator),
 	)
 }
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/storeprovider.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/storeprovider.go
index e56824a3..cbfd826d 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/storeprovider.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/collections/storeprovider/storeprovider.go
@@ -86,7 +86,9 @@ var newTransientDataProvider = func() tdapi.StoreProvider {
 var newOffLedgerProvider = func() olapi.StoreProvider {
 	return olstoreprovider.New(
 		olstoreprovider.WithCollectionType(
-			cb.CollectionType_COL_DCAS, olstoreprovider.WithDecorator(dcas.Decorator),
+			cb.CollectionType_COL_DCAS,
+			olstoreprovider.WithDecorator(dcas.Decorator),
+			olstoreprovider.WithKeyDecorator(dcas.KeyDecorator),
 		),
 	)
 }
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/config/config.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/config/config.go
index 85d942a5..94b496f2 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/config/config.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/config/config.go
@@ -10,11 +10,15 @@ import (
 	"path/filepath"
 	"time"
 
-	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
+	"github.com/hyperledger/fabric/core/config"
+
 	"github.com/spf13/viper"
 )
 
 const (
+	confPeerFileSystemPath = "peer.fileSystemPath"
+	confLedgerDataPath     = "ledgersData"
+
 	confRoles            = "ledger.roles"
 	confPvtDataCacheSize = "ledger.blockchain.pvtDataStorage.cacheSize"
 
@@ -59,7 +63,7 @@ func GetPvtDataCacheSize() int {
 
 // GetTransientDataLevelDBPath returns the filesystem path that is used to maintain the transient data level db
 func GetTransientDataLevelDBPath() string {
-	return filepath.Join(ledgerconfig.GetRootPath(), confTransientDataLeveldb)
+	return filepath.Join(filepath.Clean(config.GetPath(confPeerFileSystemPath)), confTransientDataLeveldb)
 }
 
 // GetTransientDataExpiredIntervalTime is time when background routine check expired transient data in db to cleanup.
@@ -82,7 +86,7 @@ func GetTransientDataCacheSize() int {
 
 // GetOLCollLevelDBPath returns the filesystem path that is used to maintain the off-ledger level db
 func GetOLCollLevelDBPath() string {
-	return filepath.Join(ledgerconfig.GetRootPath(), confOLCollLeveldb)
+	return filepath.Join(filepath.Join(filepath.Clean(config.GetPath(confPeerFileSystemPath)), confLedgerDataPath), confOLCollLeveldb)
 }
 
 // GetOLCollExpirationCheckInterval is time when the background routine checks expired collection data in db to cleanup.
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/endorser/endorser.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/endorser/endorser.go
index db3a6056..c1428466 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/endorser/endorser.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/endorser/endorser.go
@@ -7,37 +7,43 @@ SPDX-License-Identifier: Apache-2.0
 package endorser
 
 import (
+	"github.com/bluele/gcache"
 	"github.com/hyperledger/fabric/common/flogging"
+	"github.com/hyperledger/fabric/extensions/endorser/api"
 	"github.com/hyperledger/fabric/protos/common"
 	"github.com/hyperledger/fabric/protos/ledger/rwset"
-	"github.com/pkg/errors"
+	"github.com/trustbloc/fabric-peer-ext/pkg/common/support"
 )
 
 var endorserLogger = flogging.MustGetLogger("ext_endorser")
 
-// FilterPubSimulationResults filters out all off-ledger (including transient data) read-write sets from the simulation results
-// so that they won't be included in the block.
-func FilterPubSimulationResults(collConfigs map[string]*common.CollectionConfigPackage, pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error) {
-	if collConfigs != nil {
-		// Filter out all off-ledger hashed read/write sets
-		return newFilter(collConfigs).filter(pubSimulationResults)
-	}
-
-	endorserLogger.Debugf("No collection r/w sets.")
-	return pubSimulationResults, nil
+type collConfigRetriever interface {
+	Config(ns, coll string) (*common.StaticCollectionConfig, error)
 }
 
-type collRWSetFilter struct {
-	collConfigs map[string]*common.CollectionConfigPackage
+// CollRWSetFilter filters out all off-ledger (including transient data) read-write sets from the simulation results
+// so that they won't be included in the block.
+type CollRWSetFilter struct {
+	qepf                     api.QueryExecutorProviderFactory
+	bpp                      api.BlockPublisherProvider
+	collConfigRetrieverCache gcache.Cache
 }
 
-func newFilter(collConfigs map[string]*common.CollectionConfigPackage) *collRWSetFilter {
-	return &collRWSetFilter{
-		collConfigs: collConfigs,
+// NewCollRWSetFilter returns a new collection RW set filter
+func NewCollRWSetFilter(qepf api.QueryExecutorProviderFactory, bpp api.BlockPublisherProvider) *CollRWSetFilter {
+	return &CollRWSetFilter{
+		qepf: qepf,
+		bpp:  bpp,
+		collConfigRetrieverCache: gcache.New(0).LoaderFunc(func(chID interface{}) (interface{}, error) {
+			channelID := chID.(string)
+			return support.NewCollectionConfigRetriever(channelID, qepf.GetQueryExecutorProvider(channelID), bpp.ForChannel(channelID)), nil
+		}).Build(),
 	}
 }
 
-func (f *collRWSetFilter) filter(pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error) {
+// Filter filters out all off-ledger (including transient data) read-write sets from the simulation results
+// so that they won't be included in the block.
+func (f *CollRWSetFilter) Filter(channelID string, pubSimulationResults *rwset.TxReadWriteSet) (*rwset.TxReadWriteSet, error) {
 	endorserLogger.Debugf("Filtering off-ledger collection types...")
 	filteredResults := &rwset.TxReadWriteSet{
 		DataModel: pubSimulationResults.DataModel,
@@ -47,7 +53,7 @@ func (f *collRWSetFilter) filter(pubSimulationResults *rwset.TxReadWriteSet) (*r
 	for _, rwSet := range pubSimulationResults.NsRwset {
 		endorserLogger.Debugf("Checking chaincode [%s] for off-ledger collection types...", rwSet.Namespace)
 
-		filteredRWSet, err := f.filterNamespace(rwSet)
+		filteredRWSet, err := f.filterNamespace(channelID, rwSet)
 		if err != nil {
 			return nil, err
 		}
@@ -63,19 +69,19 @@ func (f *collRWSetFilter) filter(pubSimulationResults *rwset.TxReadWriteSet) (*r
 	return filteredResults, nil
 }
 
-func (f *collRWSetFilter) filterNamespace(nsRWSet *rwset.NsReadWriteSet) (*rwset.NsReadWriteSet, error) {
+func (f *CollRWSetFilter) filterNamespace(channelID string, nsRWSet *rwset.NsReadWriteSet) (*rwset.NsReadWriteSet, error) {
 	var filteredCollRWSets []*rwset.CollectionHashedReadWriteSet
 	for _, collRWSet := range nsRWSet.CollectionHashedRwset {
-		endorserLogger.Debugf("Checking collection [%s:%s] to see if it is an off-ledger type...", nsRWSet.Namespace, collRWSet.CollectionName)
-		offLedger, err := f.isOffLedger(nsRWSet.Namespace, collRWSet.CollectionName)
+		endorserLogger.Debugf("[%s] Checking collection [%s:%s] to see if it is an off-ledger type...", channelID, nsRWSet.Namespace, collRWSet.CollectionName)
+		offLedger, err := f.isOffLedger(channelID, nsRWSet.Namespace, collRWSet.CollectionName)
 		if err != nil {
 			return nil, err
 		}
 		if !offLedger {
-			endorserLogger.Debugf("... adding hashed rw-set for collection [%s:%s] since it IS NOT an off-ledger type", nsRWSet.Namespace, collRWSet.CollectionName)
+			endorserLogger.Debugf("[%s] ... adding hashed rw-set for collection [%s:%s] since it IS NOT an off-ledger type", channelID, nsRWSet.Namespace, collRWSet.CollectionName)
 			filteredCollRWSets = append(filteredCollRWSets, collRWSet)
 		} else {
-			endorserLogger.Debugf("... removing hashed rw-set for collection [%s:%s] since it IS an off-ledger type", nsRWSet.Namespace, collRWSet.CollectionName)
+			endorserLogger.Debugf("[%s] ... removing hashed rw-set for collection [%s:%s] since it IS an off-ledger type", channelID, nsRWSet.Namespace, collRWSet.CollectionName)
 		}
 	}
 
@@ -86,23 +92,21 @@ func (f *collRWSetFilter) filterNamespace(nsRWSet *rwset.NsReadWriteSet) (*rwset
 	}, nil
 }
 
-func (f *collRWSetFilter) isOffLedger(ns, coll string) (bool, error) {
-	collConfig, ok := f.collConfigs[ns]
-	if !ok {
-		return false, errors.Errorf("config for collection [%s:%s] not found", ns, coll)
+func (f *CollRWSetFilter) isOffLedger(channelID, ns, coll string) (bool, error) {
+	staticConfig, err := f.getConfigRetriever(channelID).Config(ns, coll)
+	if err != nil {
+		return false, err
 	}
+	return isCollOffLedger(staticConfig), nil
+}
 
-	for _, config := range collConfig.Config {
-		staticConfig := config.GetStaticCollectionConfig()
-		if staticConfig == nil {
-			return false, errors.Errorf("config for collection [%s:%s] not found", ns, coll)
-		}
-		if staticConfig.Name == coll {
-			return isCollOffLedger(staticConfig), nil
-		}
+func (f *CollRWSetFilter) getConfigRetriever(channelID string) collConfigRetriever {
+	retriever, err := f.collConfigRetrieverCache.Get(channelID)
+	if err != nil {
+		// This should never happen
+		panic(err.Error())
 	}
-
-	return false, errors.Errorf("config for collection [%s:%s] not found", ns, coll)
+	return retriever.(collConfigRetriever)
 }
 
 func isCollOffLedger(collConfig *common.StaticCollectionConfig) bool {
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher/blockpublisher.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher/blockpublisher.go
index a9189e63..90940365 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher/blockpublisher.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/gossip/blockpublisher/blockpublisher.go
@@ -170,7 +170,7 @@ func (p *Publisher) AddCCEventHandler(handler api.ChaincodeEventHandler) {
 // AddCCUpgradeHandler adds a handler for chaincode upgrade events
 func (p *Publisher) AddCCUpgradeHandler(handler api.ChaincodeUpgradeHandler) {
 	logger.Debugf("[%s] Adding chaincode upgrade", p.channelID)
-	p.AddCCEventHandler(newChaincodeUpgradeHandler(p.channelID, handler))
+	p.AddCCEventHandler(newChaincodeUpgradeHandler(handler))
 }
 
 // Publish publishes a block
@@ -199,7 +199,7 @@ func (p *Publisher) listen() {
 func (p *Publisher) handleRead(r *read) {
 	logger.Debugf("[%s] Handling read: [%s]", p.channelID, r)
 	for _, handleRead := range p.getReadHandlers() {
-		if err := handleRead(r.blockNum, r.txID, r.namespace, r.r); err != nil {
+		if err := handleRead(r.blockNum, p.channelID, r.txID, r.namespace, r.r); err != nil {
 			logger.Warningf("[%s] Error returned from KV read handler: %s", p.channelID, err)
 		}
 	}
@@ -208,7 +208,7 @@ func (p *Publisher) handleRead(r *read) {
 func (p *Publisher) handleWrite(w *write) {
 	logger.Debugf("[%s] Handling write: [%s]", p.channelID, w)
 	for _, handleWrite := range p.getWriteHandlers() {
-		if err := handleWrite(w.blockNum, w.txID, w.namespace, w.w); err != nil {
+		if err := handleWrite(w.blockNum, p.channelID, w.txID, w.namespace, w.w); err != nil {
 			logger.Warningf("[%s] Error returned from KV write handler: %s", p.channelID, err)
 		}
 	}
@@ -217,7 +217,7 @@ func (p *Publisher) handleWrite(w *write) {
 func (p *Publisher) handleCCEvent(event *ccEvent) {
 	logger.Debugf("[%s] Handling chaincode event: [%s]", p.channelID, event)
 	for _, handleCCEvent := range p.getCCEventHandlers() {
-		if err := handleCCEvent(event.blockNum, event.txID, event.event); err != nil {
+		if err := handleCCEvent(event.blockNum, p.channelID, event.txID, event.event); err != nil {
 			logger.Warningf("[%s] Error returned from CC event handler: %s", p.channelID, err)
 		}
 	}
@@ -490,8 +490,8 @@ func (p *configUpdateEvent) publish() {
 	}
 }
 
-func newChaincodeUpgradeHandler(channelID string, handleUpgrade api.ChaincodeUpgradeHandler) api.ChaincodeEventHandler {
-	return func(blockNum uint64, txID string, event *pb.ChaincodeEvent) error {
+func newChaincodeUpgradeHandler(handleUpgrade api.ChaincodeUpgradeHandler) api.ChaincodeEventHandler {
+	return func(blockNum uint64, channelID string, txID string, event *pb.ChaincodeEvent) error {
 		logger.Debugf("[%s] Handling chaincode event: %s", channelID, event)
 		if event.ChaincodeId != lsccID {
 			logger.Debugf("[%s] Chaincode event is not from 'lscc'", channelID)
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/store_impl.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/store_impl.go
index 2cd4f6d0..36e70179 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/store_impl.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/store_impl.go
@@ -9,6 +9,8 @@ package idstore
 import (
 	"fmt"
 
+	"github.com/hyperledger/fabric/core/ledger"
+
 	"github.com/hyperledger/fabric/common/flogging"
 	"github.com/hyperledger/fabric/common/metrics/disabled"
 	"github.com/hyperledger/fabric/core/ledger/kvledger/idstore"
@@ -32,8 +34,8 @@ type Store struct {
 }
 
 //OpenIDStore return id store
-func OpenIDStore(path string) idstore.IDStore {
-	couchInstance, err := createCouchInstance()
+func OpenIDStore(path string, ledgerconfig *ledger.Config) idstore.IDStore {
+	couchInstance, err := createCouchInstance(ledgerconfig)
 	if err != nil {
 		logger.Errorf("create couchdb instance failed %s", err.Error())
 		return nil
@@ -104,11 +106,10 @@ func createIndices(db *couchdb.CouchDatabase) error {
 	return nil
 }
 
-func createCouchInstance() (*couchdb.CouchInstance, error) {
+func createCouchInstance(ledgerconfig *ledger.Config) (*couchdb.CouchInstance, error) {
 	logger.Debugf("constructing CouchDB block storage provider")
-	couchDBDef := couchdb.GetCouchDBDefinition()
-	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
-		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	couchDBConfig := ledgerconfig.StateDB.CouchDB
+	couchInstance, err := couchdb.CreateCouchInstance(couchDBConfig, &disabled.Provider{})
 	if err != nil {
 		return nil, errors.WithMessage(err, "obtaining CouchDB instance failed")
 	}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/test_exports.go
index e33be838..3b6a0694 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/test_exports.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/idstore/test_exports.go
@@ -10,33 +10,33 @@ import (
 	"os"
 	"testing"
 
+	"github.com/trustbloc/fabric-peer-ext/pkg/testutil"
+
 	"github.com/hyperledger/fabric/common/metrics/disabled"
 	"github.com/hyperledger/fabric/core/ledger/kvledger/idstore"
-	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
 	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
 )
 
 // StoreEnv provides the  store env for testing
 type StoreEnv struct {
-	t          testing.TB
-	TestStore  idstore.IDStore
-	ledgerid   string
-	couchDBDef *couchdb.CouchDBDef
+	t             testing.TB
+	TestStore     idstore.IDStore
+	ledgerid      string
+	couchDBConfig *couchdb.Config
 }
 
 // NewTestStoreEnv construct a StoreEnv for testing
-func NewTestStoreEnv(t *testing.T, ledgerid string, couchDBDef *couchdb.CouchDBDef) *StoreEnv {
+func NewTestStoreEnv(t *testing.T, ledgerid string, couchDBConfig *couchdb.Config) *StoreEnv {
 	removeStorePath()
-	testStore := OpenIDStore(ledgerid)
-	s := &StoreEnv{t, testStore, ledgerid, couchDBDef}
+	testStore := OpenIDStore(ledgerid, testutil.TestLedgerConf())
+	s := &StoreEnv{t, testStore, ledgerid, couchDBConfig}
 	return s
 }
 
 //Cleanup env test
 func (env *StoreEnv) Cleanup(ledgerid string) {
 	//create a new connection
-	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBDef.URL, env.couchDBDef.Username, env.couchDBDef.Password,
-		env.couchDBDef.MaxRetries, env.couchDBDef.MaxRetriesOnStartup, env.couchDBDef.RequestTimeout, env.couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBConfig, &disabled.Provider{})
 	if err != nil {
 		panic(err.Error())
 	}
@@ -52,7 +52,7 @@ func (env *StoreEnv) Cleanup(ledgerid string) {
 }
 
 func removeStorePath() {
-	dbPath := ledgerconfig.GetPvtdataStorePath()
+	dbPath := testutil.TestLedgerConf().PrivateData.StorePath
 	if err := os.RemoveAll(dbPath); err != nil {
 		panic(err.Error())
 	}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockhandler.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockhandler.go
index 29058842..b094acb7 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockhandler.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/mocks/mockblockhandler.go
@@ -61,19 +61,19 @@ func (m *MockBlockHandler) NumConfigUpdates() int {
 }
 
 // HandleRead handles a read event by incrementing the read counter
-func (m *MockBlockHandler) HandleRead(blockNum uint64, txID string, namespace string, kvRead *kvrwset.KVRead) error {
+func (m *MockBlockHandler) HandleRead(blockNum uint64, channelID string, txID string, namespace string, kvRead *kvrwset.KVRead) error {
 	atomic.AddInt32(&m.numReads, 1)
 	return m.err
 }
 
 // HandleWrite handles a write event by incrementing the write counter
-func (m *MockBlockHandler) HandleWrite(blockNum uint64, txID string, namespace string, kvWrite *kvrwset.KVWrite) error {
+func (m *MockBlockHandler) HandleWrite(blockNum uint64, channelID string, txID string, namespace string, kvWrite *kvrwset.KVWrite) error {
 	atomic.AddInt32(&m.numWrites, 1)
 	return m.err
 }
 
 // HandleChaincodeEvent handle a chaincode event by incrementing the CC event counter
-func (m *MockBlockHandler) HandleChaincodeEvent(blockNum uint64, txID string, event *pb.ChaincodeEvent) error {
+func (m *MockBlockHandler) HandleChaincodeEvent(blockNum uint64, channelID string, txID string, event *pb.ChaincodeEvent) error {
 	atomic.AddInt32(&m.numCCEvents, 1)
 	return m.err
 }
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/store_impl.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/store_impl.go
index 1309be6c..083e8705 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/store_impl.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/store_impl.go
@@ -19,7 +19,6 @@ import (
 	"github.com/hyperledger/fabric/common/ledger/util/leveldbhelper"
 	"github.com/hyperledger/fabric/common/metrics/disabled"
 	"github.com/hyperledger/fabric/core/ledger"
-	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
 	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
 	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
 	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
@@ -38,6 +37,7 @@ const (
 type provider struct {
 	couchInstance            *couchdb.CouchInstance
 	missingKeysIndexProvider *leveldbhelper.Provider
+	ledgerConfig             *ledger.Config
 }
 
 type store struct {
@@ -61,6 +61,7 @@ type store struct {
 	// in the stateDB needs to be updated before finishing the
 	// recovery operation.
 	isLastUpdatedOldBlocksSet bool
+	ledgerConfig              *ledger.Config
 }
 
 type pendingPvtData struct {
@@ -77,24 +78,23 @@ type lastUpdatedOldBlocksList []uint64
 //////////////////////////////////////////
 
 // NewProvider instantiates a private data storage provider backed by CouchDB
-func NewProvider() (pvtdatastorage.Provider, error) {
+func NewProvider(conf *ledger.PrivateData, ledgerconfig *ledger.Config) (pvtdatastorage.Provider, error) {
 	logger.Debugf("constructing CouchDB private data storage provider")
-	couchDBDef := couchdb.GetCouchDBDefinition()
+	couchDBConfig := ledgerconfig.StateDB.CouchDB
 
-	return newProviderWithDBDef(couchDBDef)
+	return newProviderWithDBDef(couchDBConfig, conf, ledgerconfig)
 }
 
-func newProviderWithDBDef(couchDBDef *couchdb.CouchDBDef) (pvtdatastorage.Provider, error) {
-	couchInstance, err := couchdb.CreateCouchInstance(couchDBDef.URL, couchDBDef.Username, couchDBDef.Password,
-		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+func newProviderWithDBDef(couchDBConfig *couchdb.Config, conf *ledger.PrivateData, ledgerconfig *ledger.Config) (pvtdatastorage.Provider, error) {
+	couchInstance, err := couchdb.CreateCouchInstance(couchDBConfig, &disabled.Provider{})
 	if err != nil {
 		return nil, errors.WithMessage(err, "obtaining CouchDB instance failed")
 	}
 
-	dbPath := ledgerconfig.GetPvtdataStorePath()
+	dbPath := conf.StorePath
 	missingKeysIndexProvider := leveldbhelper.NewProvider(&leveldbhelper.Conf{DBPath: dbPath})
 
-	return &provider{couchInstance, missingKeysIndexProvider}, nil
+	return &provider{couchInstance, missingKeysIndexProvider, ledgerconfig}, nil
 }
 
 // OpenStore returns a handle to a store
@@ -113,10 +113,11 @@ func (p *provider) OpenStore(ledgerid string) (pvtdatastorage.Store, error) {
 
 		purgerLock := &sync.Mutex{}
 		s := &store{db: db, ledgerid: ledgerid,
-			collElgProc:        common.NewCollElgProc(purgerLock, missingKeysIndexDB),
+			collElgProc:        common.NewCollElgProc(purgerLock, missingKeysIndexDB, p.ledgerConfig),
 			purgerLock:         purgerLock,
 			missingKeysIndexDB: missingKeysIndexDB,
 			pendingPvtData:     &pendingPvtData{BatchPending: false},
+			ledgerConfig:       p.ledgerConfig,
 		}
 
 		if errInitState := s.initState(); errInitState != nil {
@@ -765,7 +766,7 @@ func (s *store) nextBlockNum() uint64 {
 }
 
 func (s *store) performPurgeIfScheduled(latestCommittedBlk uint64) {
-	if latestCommittedBlk%ledgerconfig.GetPvtdataStorePurgeInterval() != 0 {
+	if latestCommittedBlk%uint64(s.ledgerConfig.PrivateData.PurgeInterval) != 0 {
 		return
 	}
 	go func() {
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/test_exports.go
index f7c230a9..86ffe459 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/test_exports.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/cdbpvtdatastore/test_exports.go
@@ -10,8 +10,9 @@ import (
 	"os"
 	"testing"
 
+	"github.com/trustbloc/fabric-peer-ext/pkg/testutil"
+
 	"github.com/hyperledger/fabric/common/metrics/disabled"
-	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
 	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
 	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
 	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
@@ -25,19 +26,20 @@ type StoreEnv struct {
 	TestStore         pvtdatastorage.Store
 	ledgerid          string
 	btlPolicy         pvtdatapolicy.BTLPolicy
-	couchDBDef        *couchdb.CouchDBDef
+	couchDBConfig     *couchdb.Config
 }
 
 // NewTestStoreEnv construct a StoreEnv for testing
-func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLPolicy, couchDBDef *couchdb.CouchDBDef) *StoreEnv {
+func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLPolicy, couchDBConfig *couchdb.Config) *StoreEnv {
 	removeStorePath()
 	req := require.New(t)
-	testStoreProvider, err := NewProvider()
+	conf := testutil.TestLedgerConf().PrivateData
+	testStoreProvider, err := NewProvider(conf, testutil.TestLedgerConf())
 	req.NoError(err)
 	testStore, err := testStoreProvider.OpenStore(ledgerid)
 	req.NoError(err)
 	testStore.Init(btlPolicy)
-	s := &StoreEnv{t, testStoreProvider, testStore, ledgerid, btlPolicy, couchDBDef}
+	s := &StoreEnv{t, testStoreProvider, testStore, ledgerid, btlPolicy, couchDBConfig}
 	return s
 }
 
@@ -45,7 +47,8 @@ func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLP
 func (env *StoreEnv) CloseAndReopen() {
 	var err error
 	env.TestStoreProvider.Close()
-	env.TestStoreProvider, err = NewProvider()
+	conf := testutil.TestLedgerConf().PrivateData
+	env.TestStoreProvider, err = NewProvider(conf, testutil.TestLedgerConf())
 	require.NoError(env.t, err)
 	env.TestStore, err = env.TestStoreProvider.OpenStore(env.ledgerid)
 	env.TestStore.Init(env.btlPolicy)
@@ -55,8 +58,7 @@ func (env *StoreEnv) CloseAndReopen() {
 //Cleanup env test
 func (env *StoreEnv) Cleanup(ledgerid string) {
 	//create a new connection
-	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBDef.URL, env.couchDBDef.Username, env.couchDBDef.Password,
-		env.couchDBDef.MaxRetries, env.couchDBDef.MaxRetriesOnStartup, env.couchDBDef.RequestTimeout, env.couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBConfig, &disabled.Provider{})
 	if err != nil {
 		panic(err.Error())
 	}
@@ -70,7 +72,7 @@ func (env *StoreEnv) Cleanup(ledgerid string) {
 }
 
 func removeStorePath() {
-	dbPath := ledgerconfig.GetPvtdataStorePath()
+	dbPath := testutil.TestLedgerConf().PrivateData.StorePath
 	if err := os.RemoveAll(dbPath); err != nil {
 		panic(err.Error())
 	}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/collelgproc.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/collelgproc.go
index 2c69b75c..24ac3a12 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/collelgproc.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/common/collelgproc.go
@@ -10,9 +10,10 @@ import (
 	"sync"
 	"time"
 
+	"github.com/hyperledger/fabric/core/ledger"
+
 	"github.com/hyperledger/fabric/common/flogging"
 	"github.com/hyperledger/fabric/common/ledger/util/leveldbhelper"
-	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
 )
 
 // todo add pinning script to include copied code into this file, original file from fabric is found in fabric/core/ledger/pvtdatastorage/store_imp.go
@@ -24,15 +25,17 @@ type CollElgProc struct {
 	notification, procComplete chan bool
 	purgerLock                 *sync.Mutex
 	db                         *leveldbhelper.DBHandle
+	ledgerconfig               *ledger.Config
 }
 
-func NewCollElgProc(purgerLock *sync.Mutex, missingKeysIndexDB *leveldbhelper.DBHandle) *CollElgProc {
+func NewCollElgProc(purgerLock *sync.Mutex, missingKeysIndexDB *leveldbhelper.DBHandle, ledgerconfig *ledger.Config) *CollElgProc {
 
 	return &CollElgProc{
 		notification: make(chan bool, 1),
 		procComplete: make(chan bool, 1),
 		purgerLock:   purgerLock,
 		db:           missingKeysIndexDB,
+		ledgerconfig: ledgerconfig,
 	}
 }
 
@@ -61,8 +64,8 @@ func (c *CollElgProc) WaitForDone() {
 }
 
 func (c *CollElgProc) LaunchCollElgProc() {
-	maxBatchSize := ledgerconfig.GetPvtdataStoreCollElgProcMaxDbBatchSize()
-	batchesInterval := ledgerconfig.GetPvtdataStoreCollElgProcDbBatchesInterval()
+	maxBatchSize := c.ledgerconfig.PrivateData.MaxBatchSize
+	batchesInterval := c.ledgerconfig.PrivateData.BatchesInterval
 	go func() {
 		c.processCollElgEvents(maxBatchSize, batchesInterval) // process collection eligibility events when store is opened - in case there is an unprocessed events from previous run
 		for {
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/store_impl.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/store_impl.go
index 1c02c63c..aea54516 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/store_impl.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/store_impl.go
@@ -25,9 +25,9 @@ type PvtDataProvider struct {
 }
 
 // NewProvider creates a new PvtDataStoreProvider that combines a cache provider and a backing storage provider
-func NewProvider() *PvtDataProvider {
+func NewProvider(conf *ledger.PrivateData, ledgerconfig *ledger.Config) *PvtDataProvider {
 	// create couchdb pvt date store provider
-	storageProvider, err := cdbpvtdatastore.NewProvider()
+	storageProvider, err := cdbpvtdatastore.NewProvider(conf, ledgerconfig)
 	if err != nil {
 		panic(err)
 	}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/test_exports.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/test_exports.go
index 364bb823..b8ce7c96 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/test_exports.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/pvtdatastorage/test_exports.go
@@ -10,8 +10,11 @@ import (
 	"os"
 	"testing"
 
+	"github.com/trustbloc/fabric-peer-ext/pkg/testutil"
+
+	"github.com/hyperledger/fabric/core/ledger"
+
 	"github.com/hyperledger/fabric/common/metrics/disabled"
-	"github.com/hyperledger/fabric/core/ledger/ledgerconfig"
 	"github.com/hyperledger/fabric/core/ledger/pvtdatapolicy"
 	"github.com/hyperledger/fabric/core/ledger/pvtdatastorage"
 	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
@@ -25,18 +28,19 @@ type StoreEnv struct {
 	TestStore         pvtdatastorage.Store
 	ledgerid          string
 	btlPolicy         pvtdatapolicy.BTLPolicy
-	couchDBDef        *couchdb.CouchDBDef
+	couchDBConfig     *couchdb.Config
 }
 
 // NewTestStoreEnv construct a StoreEnv for testing
-func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLPolicy, couchDBDef *couchdb.CouchDBDef) *StoreEnv {
+func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLPolicy, couchDBConfig *couchdb.Config) *StoreEnv {
 	removeStorePath()
 	req := require.New(t)
-	testStoreProvider := NewProvider()
+	conf := testutil.TestLedgerConf().PrivateData
+	testStoreProvider := NewProvider(conf, testutil.TestLedgerConf())
 	testStore, err := testStoreProvider.OpenStore(ledgerid)
 	req.NoError(err)
 	testStore.Init(btlPolicy)
-	s := &StoreEnv{t, testStoreProvider, testStore, ledgerid, btlPolicy, couchDBDef}
+	s := &StoreEnv{t, testStoreProvider, testStore, ledgerid, btlPolicy, couchDBConfig}
 	return s
 }
 
@@ -44,7 +48,11 @@ func NewTestStoreEnv(t *testing.T, ledgerid string, btlPolicy pvtdatapolicy.BTLP
 func (env *StoreEnv) CloseAndReopen() {
 	var err error
 	env.TestStoreProvider.Close()
-	env.TestStoreProvider = NewProvider()
+	conf := &ledger.PrivateData{
+		StorePath:     testutil.TestLedgerConf().PrivateData.StorePath,
+		PurgeInterval: 1,
+	}
+	env.TestStoreProvider = NewProvider(conf, testutil.TestLedgerConf())
 	env.TestStore, err = env.TestStoreProvider.OpenStore(env.ledgerid)
 	env.TestStore.Init(env.btlPolicy)
 	require.NoError(env.t, err)
@@ -53,8 +61,7 @@ func (env *StoreEnv) CloseAndReopen() {
 //Cleanup env test
 func (env *StoreEnv) Cleanup(ledgerid string) {
 	//create a new connection
-	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBDef.URL, env.couchDBDef.Username, env.couchDBDef.Password,
-		env.couchDBDef.MaxRetries, env.couchDBDef.MaxRetriesOnStartup, env.couchDBDef.RequestTimeout, env.couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+	couchInstance, err := couchdb.CreateCouchInstance(env.couchDBConfig, &disabled.Provider{})
 	if err != nil {
 		panic(err.Error())
 	}
@@ -70,7 +77,7 @@ func (env *StoreEnv) Cleanup(ledgerid string) {
 }
 
 func removeStorePath() {
-	dbPath := ledgerconfig.GetPvtdataStorePath()
+	dbPath := testutil.TestLedgerConf().PrivateData.StorePath
 	if err := os.RemoveAll(dbPath); err != nil {
 		panic(err.Error())
 	}
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/roles.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/roles.go
index a99b1004..fe540a44 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/roles.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/roles/roles.go
@@ -37,7 +37,7 @@ func New(r ...Role) Roles {
 func FromStrings(r ...string) Roles {
 	rls := make(Roles, len(r))
 	for i, s := range r {
-		rls[i] = Role(s)
+		rls[i] = Role(strings.ToLower(s))
 	}
 	return rls
 }
diff --git a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/testutil/ext_test_env.go b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/testutil/ext_test_env.go
index 5ee6f31f..c197fd0b 100644
--- a/vendor/github.com/trustbloc/fabric-peer-ext/pkg/testutil/ext_test_env.go
+++ b/vendor/github.com/trustbloc/fabric-peer-ext/pkg/testutil/ext_test_env.go
@@ -9,8 +9,12 @@ package testutil
 import (
 	"fmt"
 	"os"
+	"path/filepath"
 	"time"
 
+	coreconfig "github.com/hyperledger/fabric/core/config"
+	"github.com/hyperledger/fabric/core/ledger"
+
 	"github.com/hyperledger/fabric/common/flogging"
 	"github.com/hyperledger/fabric/common/metrics/disabled"
 	"github.com/hyperledger/fabric/core/ledger/util/couchdb"
@@ -41,7 +45,7 @@ func SetupExtTestEnv() (addr string, cleanup func(string), stop func()) {
 
 	return couchDB.Address(),
 		func(name string) {
-			cleanupCouchDB(name, couchDB)
+			cleanupCouchDB(name)
 		}, func() {
 			//reset viper cdb config
 			updateConfig(oldAddr)
@@ -51,10 +55,9 @@ func SetupExtTestEnv() (addr string, cleanup func(string), stop func()) {
 		}
 }
 
-func cleanupCouchDB(name string, couchDB *runner.CouchDB) {
-	couchDBDef := couchdb.GetCouchDBDefinition()
-	couchInstance, _ := couchdb.CreateCouchInstance(couchDB.Address(), couchDBDef.Username, couchDBDef.Password,
-		couchDBDef.MaxRetries, couchDBDef.MaxRetriesOnStartup, couchDBDef.RequestTimeout, couchDBDef.CreateGlobalChangesDB, &disabled.Provider{})
+func cleanupCouchDB(name string) {
+	couchDBConfig := TestLedgerConf().StateDB.CouchDB
+	couchInstance, _ := couchdb.CreateCouchInstance(couchDBConfig, &disabled.Provider{})
 
 	blkdb := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: fmt.Sprintf("%s$$blocks_", name)}
 	pvtdb := couchdb.CouchDatabase{CouchInstance: couchInstance, DBName: fmt.Sprintf("%s$$pvtdata_", name)}
@@ -78,6 +81,7 @@ func cleanupCouchDB(name string, couchDB *runner.CouchDB) {
 //updateConfig updates 'couchAddress' in config
 func updateConfig(couchAddress string) {
 
+	viper.Set("ledger.state.stateDatabase", "CouchDB")
 	viper.Set("ledger.state.couchDBConfig.couchDBAddress", couchAddress)
 	// Replace with correct username/password such as
 	// admin/admin if user security is enabled on couchdb.
@@ -89,3 +93,67 @@ func updateConfig(couchAddress string) {
 	viper.Set("ledger.state.couchDBConfig.createGlobalChangesDB", false)
 
 }
+
+// TestLedgerConf return the ledger configs
+func TestLedgerConf() *ledger.Config {
+	// set defaults
+	warmAfterNBlocks := 1
+	if viper.IsSet("ledger.state.couchDBConfig.warmIndexesAfterNBlocks") {
+		warmAfterNBlocks = viper.GetInt("ledger.state.couchDBConfig.warmIndexesAfterNBlocks")
+	}
+	internalQueryLimit := 1000
+	if viper.IsSet("ledger.state.couchDBConfig.internalQueryLimit") {
+		internalQueryLimit = viper.GetInt("ledger.state.couchDBConfig.internalQueryLimit")
+	}
+	maxBatchUpdateSize := 500
+	if viper.IsSet("ledger.state.couchDBConfig.maxBatchUpdateSize") {
+		maxBatchUpdateSize = viper.GetInt("ledger.state.couchDBConfig.maxBatchUpdateSize")
+	}
+	collElgProcMaxDbBatchSize := 5000
+	if viper.IsSet("ledger.pvtdataStore.collElgProcMaxDbBatchSize") {
+		collElgProcMaxDbBatchSize = viper.GetInt("ledger.pvtdataStore.collElgProcMaxDbBatchSize")
+	}
+	collElgProcDbBatchesInterval := 1000
+	if viper.IsSet("ledger.pvtdataStore.collElgProcDbBatchesInterval") {
+		collElgProcDbBatchesInterval = viper.GetInt("ledger.pvtdataStore.collElgProcDbBatchesInterval")
+	}
+	purgeInterval := 100
+	if viper.IsSet("ledger.pvtdataStore.purgeInterval") {
+		purgeInterval = viper.GetInt("ledger.pvtdataStore.purgeInterval")
+	}
+
+	rootFSPath := filepath.Join(coreconfig.GetPath("peer.fileSystemPath"), "ledgersData")
+	conf := &ledger.Config{
+		RootFSPath: rootFSPath,
+		StateDB: &ledger.StateDB{
+			StateDatabase: viper.GetString("ledger.state.stateDatabase"),
+			LevelDBPath:   filepath.Join(rootFSPath, "stateLeveldb"),
+			CouchDB:       &couchdb.Config{},
+		},
+		PrivateData: &ledger.PrivateData{
+			StorePath:       filepath.Join(rootFSPath, "pvtdataStore"),
+			MaxBatchSize:    collElgProcMaxDbBatchSize,
+			BatchesInterval: collElgProcDbBatchesInterval,
+			PurgeInterval:   purgeInterval,
+		},
+		HistoryDB: &ledger.HistoryDB{
+			Enabled: viper.GetBool("ledger.history.enableHistoryDatabase"),
+		},
+	}
+
+	conf.StateDB.CouchDB = &couchdb.Config{
+		Address:                 viper.GetString("ledger.state.couchDBConfig.couchDBAddress"),
+		Username:                viper.GetString("ledger.state.couchDBConfig.username"),
+		Password:                viper.GetString("ledger.state.couchDBConfig.password"),
+		MaxRetries:              viper.GetInt("ledger.state.couchDBConfig.maxRetries"),
+		MaxRetriesOnStartup:     viper.GetInt("ledger.state.couchDBConfig.maxRetriesOnStartup"),
+		RequestTimeout:          viper.GetDuration("ledger.state.couchDBConfig.requestTimeout"),
+		InternalQueryLimit:      internalQueryLimit,
+		MaxBatchUpdateSize:      maxBatchUpdateSize,
+		WarmIndexesAfterNBlocks: warmAfterNBlocks,
+		CreateGlobalChangesDB:   viper.GetBool("ledger.state.couchDBConfig.createGlobalChangesDB"),
+		RedoLogPath:             filepath.Join(rootFSPath, "couchdbRedoLogs"),
+	}
+
+	return conf
+}
-- 
2.21.0 (Apple Git-120)

